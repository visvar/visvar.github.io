@article{elmquist2025cosmic,
    title         = {A Cosmic View of Life on Earth: Hierarchical Visualization of Biological Data Using Astronomical Software},
    author        = {Wandrille Duchemin, Takanori Fujiwara, Hollister W. Herhold, Elias Elmquist, David S. Thaler, William Harcourt-Smith, Emma Broman, Alexander Bock, Brian P. Abbott, Jacqueline K. Faherty},
    year          = {2025},
    month         = {09},
    journal       = {IEEE Computer Graphics and Applications},
    publisher     = {IEEE},
    volume        = {45},
    number        = {5},
    pages         = {93-106},
    doi           = {https://doi.org/10.1109/MCG.2025.3591713},
    pdf           = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11090025},
    venue         = {CG&A},
    abstract      = {A goal of data visualization is to advance the understanding of multiparameter, large-scale datasets. In astrophysics, scientists map celestial objects to understand the hierarchical structure of the universe. In biology, genetic sequences and biological characteristics uncover evolutionary relationships and patterns (e.g., variation within species and ecological associations). Our highly interdisciplinary project entitled “A Cosmic View of Life on Earth” adapts an immersive astrophysics visualization platform called OpenSpace to contextualize diverse biological data. Dimensionality reduction techniques harmonize biological information to create spatial representations in which data are interactively explored on flat screens and planetarium domes. Visualizations are enriched with geographic metadata, 3-D scans of specimens, and species-specific sonifications (e.g., bird songs). The “Cosmic View” project eases the dissemination of stories related to biological domains (e.g., insects, birds, mammals, and human migrations) and facilitates scientific discovery.}
}
@inproceedings{elmquist2024towards,
    title           = {Towards a Systematic Scene Analysis Framework for Audiovisual Data Representations},
    author          = {Elias Elmquist, Alexander Bock, Anders Ynnerman, Niklas Rönnberg},
    year            = {2024},
    month           = {11},
    booktitle       = {Audiovisual Symposium},
    pages           = {},
    doi             = {https://audiovisualsymposium.github.io/symposiumnotes2024.html},
    organization    = {Dalarna University},
    pdf             = {https://audiovisualsymposium.github.io/symposiumnotes/2024/Elmquist_et_al_Towards_a_Systematic_Scene_Analysis_Framework_for_Audiovisual_Data_Representations.pdf},
    venue           = {AV},
    abstract        = {Considering the cognitive integration of auditory and visual scene analysis, and the resulting perceptual organization, this paper proposes a systematic conceptual framework for displaying the organization of an audiovisual representation, named Audiovisual Scene Graph. The framework illustrates and highlights how visual and auditory elements merge to become higher-level objects, and how they can also integrate to become audiovisual objects. Furthermore, the framework has the potential to assist in the design of an audiovisual representation, as well as in analyzing existing representations to better understand how they are perceived.}
}
@article{elmquist2024open,
    title           = {Open Your Ears and Take a Look: A State‐of‐the‐Art Report on the Integration of Sonification and Visualization},
    author          = {Kajetan Enge, Elias Elmquist, Valentina Caiola, Niklas Rönnberg, Alexander Rind, Michael Iber, Sara Lenzi, Fangfei Lan, Robert Höldrich, Wolfgang Aigner},
    year            = {2024},
    month           = {06},
    journal         = {Computer Graphics Forum},
    publisher       = {Computer Graphics Forum},
    volume          = {43},
    number          = {3},
    pages           = {},
    doi             = {https://doi.org/10.1111/cgf.15114},
    pdf             = {https://onlinelibrary.wiley.com/doi/epdf/10.1111/cgf.15114},
    venue           = {CGF},
    abstract        = {The research communities studying visualization and sonification for data display and analysis share exceptionally similar goals, essentially making data of any kind interpretable to humans. One community does so by using visual representations of data, and the other community employs auditory (non-speech) representations of data. While the two communities have a lot in common, they developed mostly in parallel over the course of the last few decades. With this STAR, we discuss a collection of work that bridges the borders of the two communities, hence a collection of work that aims to integrate the two techniques into one form of audiovisual display, which we argue to be “more than the sum of the two.” We introduce and motivate a classification system applicable to such audiovisual displays and categorize a corpus of 57 academic publications that appeared between 2011 and 2023 in categories such as reading level, dataset type, or evaluation system, to mention a few. The corpus also enables a meta-analysis of the field, including regularly occurring design patterns such as type of visualization and sonification techniques, or the use of visual and auditory channels, showing an overall diverse field with different designs. An analysis of a co-author network of the field shows individual teams without many interconnections. The body of work covered in this STAR also relates to three adjacent topics: audiovisual monitoring, accessibility, and audiovisual data art. These three topics are discussed individually in addition to the systematically conducted part of this research. The findings of this report may be used by researchers from both fields to understand the potentials and challenges of such integrated designs while hopefully inspiring them to collaborate with experts from the respective other field.}
}
@inproceedings{elmquist2024birdsongification,
    title           = {Birdsongification: Contextual and Complementary Sonification for Biology Visualization},
    author          = {Elias Elmquist, Malin Ejdbo, Alexander Bock, David S. Thaler, Anders Ynnerman, Niklas Rönnberg},
    year            = {2024},
    month           = {06},
    booktitle       = {International Conference on Auditory Display},
    pages           = {34--41},
    doi             = {https://doi.org/10.21785/icad2024.006},
    organization    = {International Community on Auditory Display},
    pdf             = {https://repository.gatech.edu/bitstreams/5eb4d7bb-9af8-496e-b24a-f50ab0e608cf/download},
    venue           = {ICAD},
    abstract        = {Choosing whether to represent data in an abstract or concrete manner through sonification is generally dependent on the applicability of the dataset and personal preference of the designer. For supporting a visualization with a high level of abstraction, a sonification can purposefully act as a complement by giving concrete contextual cues to the data representation with the use of auditory icons. This paper presents a case study of using bird songs as auditory icons to give context to a biology visualization, and explores how additional information of the bird species can be conveyed together with the auditory icons with parameter mapping sonification. The auditory icons are used as a foundation to convey additional information of the dataset, either by creating a parametric auditory icon, or by adding an additional sonification that accompanies the auditory icon. A user evaluation was conducted to validate and compare the different sonification mappings. The results show that there is a subjective difference of how participants perceived the sonifications, where the participants preferred sonifications that had a concrete mapping design. The sonification approaches that are explored in this study have the potential to be applied to more general sonification designs.}
}
@article{elmquist2024parallel,
    title           = {Parallel Chords: an audio-visual analytics design for parallel coordinates},
    author          = {Elias Elmquist, Kajetan Enge, Alexander Rind, Carlo Navarra, Robert Höldrich, Michael Iber, Alexamder Bock, Anders Ynnerman, Wolfgang Aigner, Niklas Rönnberg},
    year            = {2024},
    month           = {05},
    journal         = {Personal and Ubiquitous Computing},
    publisher       = {Springer},
    volume          = {28},
    number          = {01},
    pages           = {657--676},
    doi             = {https://doi.org/10.1007/s00779-024-01795-8},
    pdf             = {https://link.springer.com/content/pdf/10.1007/s00779-024-01795-8.pdf},
    venue           = {PUC},
    abstract        = {One of the commonly used visualization techniques for multivariate data is the parallel coordinates plot. It provides users with a visual overview of multivariate data and the possibility to interactively explore it. While pattern recognition is a strength of the human visual system, it is also a strength of the auditory system. Inspired by the integration of the visual and auditory perception in everyday life, we introduce an audio-visual analytics design named Parallel Chords combining both visual and auditory displays. Parallel Chords lets users explore multivariate data using both visualization and sonification through the interaction with the axes of a parallel coordinates plot. To illustrate the potential of the design, we present (1) prototypical data patterns where the sonification helps with the identification of correlations, clusters, and outliers, (2) a usage scenario showing the sonification of data from non-adjacent axes, and (3) a controlled experiment on the sensitivity thresholds of participants when distinguishing the strength of correlations. During this controlled experiment, 35 participants used three different display types, the visualization, the sonification, and the combination of these, to identify the strongest out of three correlations. The results show that all three display types enabled the participants to identify the strongest correlation — with visualization resulting in the best sensitivity. The sonification resulted in sensitivities that were independent from the type of displayed correlation, and the combination resulted in increased enjoyability during usage.},
    footnoteindices = {0,1},
    footnotetext    = {contributed equally}
}
@article{elmquist2023sonair,
    title           = {SonAir: the design of a sonification of radar data for air traffic control},
    author          = {Elias Elmquist, Alexander Bock, Jonas Lundberg, Anders Ynnerman, Niklas Rönnberg},
    year            = {2023},
    month           = {07},
    journal         = {Journal on Multimodal User Interfaces},
    publisher       = {Springer},
    volume          = {17},
    number          = {01},
    pages           = {137--149},
    doi             = {https://doi.org/10.1007/s12193-023-00404-x},
    pdf             = {https://link.springer.com/content/pdf/10.1007/s12193-023-00404-x.pdf},
    venue           = {JOMUI},
    badge           = {bestpaper},
    note            = {Received the Sonification Award in the analysis category in 2025.},
    abstract        = {Along with the increase of digitalization and automation, a new kind of working environment is emerging in the field of air traffic control. Instead of situating the control tower at the airport, it is now possible to remotely control the airport at any given location, i.e. in a remote tower center (RTC). However, by controlling the airport remotely, the situational awareness and sense of presence might be compromised. By using directional sound, a higher situational awareness could potentially be achieved while also offloading the visual perception which is heavily used in air traffic control. Suitable use cases for sonification in air traffic control were found through workshops with air traffic controllers. A sonification design named SonAir was developed based on the outcome of the workshops, and was integrated with an RTC simulator for evaluating to what degree SonAir could support air traffic controllers in their work. The results suggest that certain aspects of SonAir could be useful for air traffic controllers. A continuous sonification where the spatial positioning of aircraft were conveyed was experienced to be partially useful, but the intrusiveness of SonAir should be further considered to fit the air traffic controllers’ needs. An earcon that conveyed when an aircraft enters the airspace and from which direction was considered useful to support situational awareness.}
}
@inproceedings{elmquist2022towards,
    title           = {Towards the Combination of Visualization and Sonification for Cylindrical Displays},
    author          = {Elias Elmquist, Kajetan Enge},
    year            = {2022},
    month           = {05},
    booktitle       = {Advanced Visual Interfaces},
    pages           = {},
    doi             = {https://doi.org/10.5281/zenodo.6553825},
    organization    = {AVI Workshop on Audio-Visual Analytics},
    pdf             = {https://zenodo.org/records/6553825/files/Elmquist_Enge_2022.pdf?download=1},
    venue           = {AVI},
    abstract        = {Immersive environments provide a physical space for audio-visual data analysis. An example of such an environment is the Norrköping Decision Arena, which provides a cylindrical display together with a circular sound system. This paper sets recommendations on what kinds of visualization would benefit from being displayed in this kind of environment and how sonification could be used as a complement to enable exploratory data analysis. Three visualizations are presented as potentially interesting for the presentation on a cylindrical display: theme rivers, radial visualizations, and parallel coordinates.}
}
@misc{mazur2024augumented,
    author          = {Janet Mazur, Enes Yigitbas},
    title           = {Augmented Reality-Assisted Multi-Robot Programming with Collision Warning},
    year            = {2024},
    month           = {09},
    doi             = {https://doi.org/10.18420/muc2024-mci-ws11-186},
    venue           = {Mensch und Computer 2024 - Workshopband},
    abstract        = {Delivery tasks and environmental exploration commonly utilize multi-robot systems. However, programming robots still requires a high level of expertise and knowledge. Therefore, the application of Augmented Reality (AR) has shown promise in aiding robot programming, enabling the user to operate within the robot's space and view robot data and information. Most approaches focus on programming single-robot manipulators or mobile robots. To also offer the programming of multiple collaboratively working robots, we propose EURAPS*, an extension of the existing EURAPS framework. As a feature, we integrate a collision warning to assist the programmer in collision-free multi-robot programming. We conducted a user study to evaluate our system's effectiveness in detecting collisions among mobile robots. The results show that the collision warning assists the user in avoiding robot collisions. Further research is needed to focus on more reliable robot tracking for precise recognition and collision warning with other obstacles.},
    publisher       = {Gesellschaft für Informatik e.V."}
}
@inproceedings{yigitbas2024augumented,
    author          = {Enes Yigitbas, Janet Mazur},
    title           = {Augmented and Virtual Reality for Diet and Nutritional Education: A Systematic Literature Review},
    year            = {2024},
    month           = {06},
    isbn            = {9798400717604},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    doi             = {https://doi.org/10.1145/3652037.3652048},
    abstract        = {A healthy diet is becoming more difficult due to the increasing amount of processed foods, misinformation, or inadequate education about nutrition, which can lead to a variety of diseases in the long term. Supporting people with proper nutrition and diet education is therefore indispensable. As Augmented and Virtual Reality have become promising technologies for education, they are also becoming more common for diet and nutrition education and have been featured in several studies. Both technologies can display additional product information to the user or educate them through new learning applications to support healthy eating. As recent papers only address the use of AR or do not include current research findings, this paper provides a new systematic literature review with recent studies on AR/VR for nutrition and diet education. This paves the way for new research and approaches in this field and suggests future research directions. Overall, 41 out of 375 articles were extracted, categorized, and analyzed. The findings reveal that, especially for the nutritional education of children, AR games have a promising application. VR, on the other hand, is increasingly utilized for virtual supermarkets. The applications help users to better understand and memorize the educational materials about nutrition and expand their knowledge about their diet. In addition, the applications are usually easy to use and users want to continue using them in the future.},
    booktitle       = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
    pages           = {88–97},
    venue           = {PETRA '24}
}
@inproceedings{lienen2023autonomros,
    author          = {Christian Lienen, Mathis Brede, Daniel Karger, Kevin Koch, Dalisha Logan, Janet Mazur, Alexander Philipp Nowosad, Alexander Schnelle, Mohness Waizy, Marco Platzner},
    booktitle       = {2023 Seventh IEEE International Conference on Robotic Computing (IRC)}, 
    title           = {AutonomROS: A ReconROS-based Autonomous Driving Unit}, 
    year            = {2023},
    month           = {12},
    pages           = {297-304},
    keywords        = {Point cloud compression;Software architecture;Navigation;Lane detection;Heterogeneous networks;Middleware;Robots;Robotics;FPGA;ROS 2;ReconROS},
    abstract        = {Autonomous driving has become an important research area in recent years, and the corresponding system creates an enormous demand for computations. Heterogeneous computing platforms such as systems-on-chip that combine CPUs with reprogrammable hardware offer both computational performance and flexibility and are thus interesting targets for autonomous driving architectures. The de-facto software architecture standard in robotics, including autonomous driving systems, is ROS 2. ReconROS is a framework for creating robotics applications that extends ROS 2 with the possibility of mapping compute-intense functions to hardware. This paper presents AutonomROS, an autonomous driving unit based on the ReconROS framework. AutonomROS serves as a blueprint for a larger robotics application developed with ReconROS and demonstrates its suitability and extendability. The application integrates the ROS 2 package Navigation 2 with custom-developed software and hardware-accelerated functions for point cloud generation, obstacle detection, and lane detection. In addition, we detail a new communication middleware for shared memory communication between software and hardware functions. We evaluate AutonomROS and show the advantage of hardware acceleration and the new communication middleware for improving turnaround times, achievable frame rates, and, most importantly, reducing CPU load.},
    doi             = {https://doi.org/10.1109/IRC59093.2023.00056},
    venue           = {IRC}
}
@inproceedings{elmquist2021openspace,
    title           = {OpenSpace Sonification: Complementing Visualization of the Solar System with Sound},
    author          = {Elias Elmquist, Malin Ejdbo, Alexander Bock, Niklas Rönnberg},
    year            = {2021},
    month           = {06},
    booktitle       = {International Conference on Auditory Display},
    pages           = {135--142},
    doi             = {https://doi.org/10.21785/icad2021.018},
    organization    = {International Community on Auditory Display},
    pdf             = {https://repository.gatech.edu/bitstreams/b7c92059-16ac-48f4-8993-89540baa9b2f/download},
    venue           = {ICAD},
    badge           = {bestpaper},
    note            = {Received Best Student Paper award and Best Use of Academic Sound at the ICAD conference.},
    abstract        = {Data visualization software is commonly used to explore outer space in a planetarium environment, where the visuals of the software is typically accompanied with a narrator and supplementary background music. By letting sound take a bigger role in these kinds of presentations, a more informative and immersive experience can be achieved. The aim of the present study was to explore how sonification can be used as a complement to the visualization software OpenSpace to convey information about the Solar System, as well as increasing the perceived immersiveness for the audience in a planetarium environment. This was investigated by implementing a sonification that conveyed planetary properties, such as the size and orbital period of a planet, by mapping this data to sonification parameters. With a user-centered approach, the sonification was designed iteratively and evaluated in both an online and planetarium environment. The results of the evaluations show that the participants found the sonification informative and interesting, which suggest that sonification can be beneficially used as a complement to visualization in a planetarium environment}
}
@misc{park2024designing,
    title           = {Designing for Visual Thinkers: Overcoming Text-Centric Limitations in GenAI Tools},
    author          = {Hyerim Park, Malin Eiband},
    year            = {2024},
    month           = {10},
    publisher       = {Zenodo},
    doi             = {https://doi.org/10.5281/zenodo.14186390},
    venue           = {NordiCHI},
    abstract        = {This workshop paper examines the challenges of integrating generative AI (GenAI) into the design process, focusing on designers who are predominantly visual thinkers. Drawing from previous interviews with designers, we highlight challenges related to text-based inputs, difficulties in controlling prompts, and the lack of proper integration into design practices. Our paper explores ways to improve designers’ interaction with GenAI tools, enabling them to achieve desired outcomes with less effort. We propose two approaches: one that enhances the use of text-based inputs through improved prompt generation with multimodal Large Language Models (LLMs) and another that introduces more intuitive, visually-driven methods like sketch and doodle inputs, reducing reliance on text prompts. This paper aims to foster discussions on how GenAI tools can better align with the needs of design professionals. Our work thus focuses on addressing the limitations of text-centric GenAI interfaces, making these tools more accessible and effective for visual thinkers, and ultimately improving their ability to leverage GenAI in the creative process.}
}
@conference{franke2024twopoint,
    title           = {Two-point Equidistant Projection and Degree-of-interest Filtering for Smooth Exploration of Geo-referenced Networks},
    author          = {Max Franke, Samuel Beck, Steffen Koch},
    year            = {2024},
    month           = {10},
    booktitle       = {Proceedings 2024 IEEE Visualization Conference - Short Papers VIS 2024},
    publisher       = {IEEE},
    doi             = {https://doi.org/10.1109/VIS55277.2024.00023},
    pdf             = {https://arxiv.org/pdf/2406.11493},
    venue           = {VIS},
    abstract        = {The visualization and interactive exploration of geo-referenced networks poses challenges if the network’s nodes are not evenly distributed. Our approach proposes new ways of realizing animated transitions for exploring such networks from an ego-perspective. We aim to reduce the required screen estate while maintaining the viewers’ mental map of distances and directions. A preliminary study provides first insights of the comprehensiveness of animated geographic transitions regarding directional relationships between start and end point in different projections. Two use cases showcase how ego-perspective graph exploration can be supported using less screen space than previous approaches.}
}
@inproceedings{talsma2024towards,
    title           = {Towards a common understanding of Simulator Sickness},
    author          = {Tessa M. W. Talsma, Ksander N. de Winkel, Riender Happee},
    year            = {2024},
    month           = {09},
    booktitle       = {Driving Simulation Conference Europe VR},
    pdf             = {https://www.researchgate.net/profile/Tessa-Talsma/publication/384967034_Towards_a_common_understanding_of_Simulator_Sickness/links/6717977168ac304149aa5ca2/Towards-a-common-understanding-of-Simulator-Sickness.pdf},
    venue           = {Driving Simulation Conference},
    abstract        = {A limitation to the use of driving simulators is simulator sickness. Its discomforting symptoms frequently impact the quality of measurements and complicate interpretation of results obtained from simulator studies. With a yet unclear cause of motion sickness, ever-increasing technological advances in simulator development and the rising demand to study (automated) carsickness, there is a need to align on the definition of simulator sickness. As its exact representation is oftentimes unclear, we present a theoretical vision on the definition of motion sickness, visually induced motion sickness (cybersickness) and lastly simulator sickness and its possible causes.}
}
@article{kusnick2024every,
    title           = {Every Thing Can Be a Hero! Narrative Visualization of Person, Object, and Other Biographies},
    author          = {Jakob Kusnick, Eva Mayr, Kasra Seirafi, Samuel Beck, Johannes Liem, Florian Windhager},
    year            = {2024},
    month           = {04},
    journal         = {Informatics},
    volume          = {11},
    number          = {2},
    doi             = {https://doi.org/10.3390/informatics11020026},
    issn            = {2227-9709},
    url             = {https://www.mdpi.com/2227-9709/11/2/26},
    abstract        = {Knowledge communication in cultural heritage and digital humanities currently faces two challenges, which this paper addresses: On the one hand, data-driven storytelling in these fields has mainly focused on human protagonists, while other essential entities (such as artworks and artifacts, institutions, or places) have been neglected. On the other hand, storytelling tools rarely support the larger chains of data practices, which are required to generate and shape the data and visualizations needed for such stories. This paper introduces the InTaVia platform, which has been developed to bridge these gaps. It supports the practices of data retrieval, creation, curation, analysis, and communication with coherent visualization support for multiple types of entities. We illustrate the added value of this open platform for storytelling with four case studies, focusing on (a) the life of Albrecht Dürer (person biography), (b) the Saliera salt cellar by Benvenuto Cellini (object biography), (c) the artist community of Lake Tuusula (group biography), and (d) the history of the Hofburg building complex in Vienna (place biography). Numerous suggestions for future research arise from this undertaking.},
    venue           = {informatics}
}
@article{li2023seatmatevr,
    title           = {SeatmateVR: Proxemic Cues for Close Bystander-Awareness in Virtual Reality},
    author          = {Jingyi Li, Hyerim Park, Robin Welsch, Sven Mayer, Andreas Butz},
    year            = {2023},
    month           = {11},
    journal         = {Proc. ACM Hum.-Comput. Interact.},
    publisher       = {ACM},
    address         = {New York, NY, USA},
    volume          = {7},
    number          = {ISS},
    doi             = {https://doi.org/10.1145/3626474},
    abstract        = {Prior research explored ways to alert virtual reality users of bystanders entering the play area from afar. However, in confined social settings like sharing a couch with seatmates, bystanders’ proxemic cues, such as distance, are limited during interruptions, posing challenges for proxemic-aware systems. To address this, we investigated three visualizations, using a 2D animoji, a fully-rendered avatar, and their combination, to gradually share bystanders’ orientation and location during interruptions. In a user study (N=22), participants played virtual reality games while responding to questions from their seatmates. We found that the avatar preserved game experiences yet did not support the fast identification of seatmates as the animoji did. Instead, users preferred the mixed visualization, where they found the seatmate’s orientation cues instantly in their view and were gradually guided to the person’s actual location. We discuss implications for fine-grained proxemic-aware virtual reality systems to support interaction in constrained social spaces.},
    articleno       = {438},
    numpages        = {20},
    keywords        = {bystander awareness, constrained interaction space, proxemic-aware virtual reality},
    venue           = {ISS}
}
@misc{fan2023virtual,
    title           = {Virtual Reality Training for Nosocomial Infections Prevention},
    author          = {Mengjie Fan, Shaoxing Zhang, Xintian Zhao, Xingyao Yu, Liang Zhou},
    year            = {2023},
    month           = {10},
    url             = {https://virtual.ieeevis.org/year/2023/poster_v-vis-posters-1080.html},
    venue           = {VIS},
    abstract        = {Nosocomial infections (or healthcare-associated infections) can greatly affect public health. The prevention and control of nosocomial infections rely on effective training of medical personnel on the correct use of personal prevention equipment (PPE). We introduce a virtual reality (VR) method that simulates the real environment of a hospital and supports repeated immersive practice of PPE donning and doffing. A VR prototype is created and receives positive feedback from a domain expert. The effectiveness of our method will be evaluated in a comparative user study.}
}
@inproceedings{liem2023workflow,
    title           = {A Workflow Approach to Visualization-Based Storytelling with Cultural Heritage Data},
    author          = {Johannes Liem, Jakob Kusnick, Samuel Beck, Florian Windhager, Eva Mayr},
    year            = {2023},
    month           = {10},
    booktitle       = {2023 IEEE 8th Workshop on Visualization for the Digital Humanities (VIS4DH)},
    pages           = {13--17},
    doi             = {https://doi.org/10.1109/VIS4DH60378.2023.00008},
    abstract        = {Stories are as old as human history—and a powerful means for the engaging communication of information, especially in combination with visualizations. The InTaVia project is built on this intersection and has developed a platform which supports the workflow of cultural heritage experts to create compelling visualization-based stories: From the search for relevant cultural objects and actors in a cultural knowledge graph, to the curation and visual analysis of the selected information, and to the creation of stories based on these data and visualizations, which can be shared with the interested public.},
    venue           = {VIS4DH}
}
@inproceedings{sadler2023extrema,
    title           = {Extrema Graphs: Fitness Landscape Analysis to the Extreme!},
    author          = {Sophie Sadler, Alma Rahat, David J. Walker, Daniel Archambault},
    year            = {2023},
    month           = {07},
    booktitle       = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
    location        = {Lisbon, Portugal},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {GECCO '23 Companion},
    pages           = {2081–2089},
    doi             = {https://doi.org/10.1145/3583133.3596343},
    isbn            = {9798400701207},
    abstract        = {Fitness landscape analysis often relies on visual tools to provide insight to a search space, allowing for reasoning before optimisation. Currently, the dominant approach for visualisation is the local optima network, where the local structure around a potential global optimum is visualised using a network with the nodes as local minima and the edges as transitions between those minima through an optimiser. In this paper, we present an approach based on extrema graphs, originally used for isosurface extraction in volume visualisation, where transitions are captured between both maxima and minima embedded in two dimensions through dimensionality reduction techniques (multidimensional scaling in our prototype). These diagrams enable evolutionary computation practitioners to understand the entire search space by incorporating global information describing the spatial relationships between extrema. We demonstrate the approach on a number of continuous benchmark problems from the literature and highlight that the resulting visualisations enable the observation of known problem features, leading to the conclusion that extrema graphs are a suitable tool for extracting global information about problem landscapes.},
    numpages        = {9},
    pdf             = {https://dl.acm.org/doi/pdf/10.1145/3583133.3596343},
    venue           = {GECCO}
}
@inproceedings{krieglstein2023skill-based,
    title           = {Skill-based Robot Programming in Mixed Reality with Ad-hoc Validation Using a Force-enabled Digital Twin},
    author          = {Jan Krieglstein, Gesche Held, Balázs A. Bálint, Frank Nägele, Werner Kraus},
    year            = {2023},
    month           = {07},
    booktitle       = {2023 IEEE International Conference on Robotics and Automation (ICRA)},
    pages           = {11612--11618},
    doi             = {https://doi.org/10.1109/ICRA48891.2023.10161095},
    venue           = {ICRA},
    abstract        = {Skill-based programming has proven to be advantageous for assembly tasks, but still requires expert knowledge, especially for force-controlled applications. However, it is error-prone due to the multitude of parameters, e.g. different coordinate frames and either position-, velocity- or force-controlled motions on the axes of a frame. We propose a mixed reality based solution, which systematically visualizes the geometric constraints of advanced high-level skills directly in the real-world robotic environment and provides a user interface to create applications efficiently and safely in mixed reality. Therefore, state-machine information is also visualized, and a holographic digital twin allows the user to ad-hoc validate the program via force-enabled simulation. The approach is evaluated on a top hat rail mounting task, proving the capability of the system to handle advanced assembly programming tasks efficiently and tangibly.}
}
@inproceedings{yao2018modeling,
    title         = {Modeling and Sliding Mode Control of a Fully-actuated Multirotor with Tilted Propellers},
    author        = {Chao Yao, Jan Krieglstein, Klaus Janschek},
    booktitle     = {IFAC-PapersOnLine},
    volume        = {51},
    number        = {22},
    pages         = {115--120},
    year          = {2018},
    month         = {08},
    publisher     = {Elsevier},
    venue         = {SYROCO},
    doi           = {https://doi.org/10.1016/j.ifacol.2018.11.527},
    abstract      = {This paper presents modeling and control of a fully-actuated hexarotor. With tilted propellers, the full pose of the unmanned aerial vehicle (UAV) can be controlled independently, and the vehicle is able to exert full wrench on the environment for aerial manipulation tasks. Based on modeling of the propeller aerodynamics, the vehicle dynamics and the brushless DC-Motors, a robust integral sliding mode control including chattering avoidance is proposed. A detailed performance analysis of the integral sliding mode control is presented and compared with PID control with exact feedback linearization using numerical simulations. The performance assessment of step response, disturbance response and trajectory tracking has shown, that the proposed controller demonstrates robustness for a fully-actuated hexarotor with tilted propellers under realistic operational conditions with noisy state estimation and tolerating parameter uncertainties.}
}
@article{acemoglu20205g,
    title         = {5G Robotic Telesurgery: Remote Transoral Laser Microsurgeries on a Cadaver},
    author        = {Alperen Acemoglu, Jan Krieglstein, Darwin G Caldwell, Francesco Mora, Luca Guastini, Matteo Trimarchi, Alessandro Vinciguerra, Andrea Luigi Camillo Carobbio, Juljana Hysenbelli, Marco Delsanto, Ottavia Barboni, Sabrina Baggioni, Giorgio Peretti, Leonardo S Mattos},
    journal       = {IEEE Transactions on Medical Robotics and Bionics},
    volume        = {2},
    number        = {4},
    pages         = {511-518},
    year          = {2020},
    month         = {11},
    venue         = {IEEE Transactions on Medical Robotics and Bionics},
    doi           = {https://doi.org/10.1109/TMRB.2020.3033007},
    abstract      = {Robotic telesurgery is a new concept in surgical care that has gained relevance over the past two decades. Now, with the introduction of 5G mobile networks, this concept is becoming practical. Here, we report that surgeons successfully performed complex transoral laser microsurgeries on the vocal cords of an adult human cadaver located 15 km away from them. This was possible thanks to a high bandwidth and ultra-low latency 5G telecommunication system, which allowed for precise remote control of robotic instruments and full HD ( 1920x1280  pixels) 3D visualization of the surgical site. During the operation, the mean video transmission latency was 102±9 ms with the maximum latency being 140 ms, but this was observed during less than 1% of the operation time. This latency did not cause any deterioration in surgeons’ performance. Our results demonstrate that surgical expertise can be exploited and shared efficiently using the new 5G telecommunication standard. This is critical for highly specialized operations such as the microsurgeries demonstrated here, which require surgical expertise that are not widely available. Therefore, the possibility to operate from a distance can bring significant benefits to healthcare systems, reducing costs and enhancing treatment quality for patients. In addition, it makes telementoring a reality, allowing expert surgeons to be present virtually in multiple operating rooms to guide and train less experienced colleagues.}
}
@article{acemoglu2020operating,
    title         = {Operating From a Distance: Robotic Vocal Cord 5G Telesurgery on a Cadaver},
    author        = {Alperen Acemoglu, Giorgio Peretti, Matteo Trimarchi, Juljana Hysenbelli, Jan Krieglstein, Andre Geraldes, Nikhil Deshpande, Pierre Marie Vincent Ceysens, Darwin G Caldwell, Marco Delsanto, Ottavia Barboni, Tommaso Vio, Sabrina Baggioni, Alessandro Vinciguerra, Elettra Oleari, Alberto Sanna, Andrea Luigi Camillo Carobbio, Luca Guastini, Francesco Mora, Leonardo S Mattos},
    journal       = {Annals of Internal Medicine},
    volume        = {173},
    number        = {11},
    pages         = {940-941},
    year          = {2020},
    month         = {07},
    venue         = {Annals of Internal Medicine},
    abstract      = {Background: The first telesurgery involving a human patient was done in 2001 (1). The patient, located in Strasbourg, France, had a laparoscopic cholecystectomy done by a surgeon in New York. This pioneering experience showed the potential of telehealth technology, but safe, reliable reproduction of this feat proved problematic for many years because of the limited availability of surgical robots and the lack of fast and reliable network connections. Now, however, surgical robots are becoming increasingly common and accepted in operating rooms, and the next generation of mobile networks (5G) is quickly becoming a reality, bringing ultrafast, stable, and reliable …},
    doi           = {https://doi.org/10.7326/M20-0418}
}
@inproceedings{odabasi2025learning,
    title         = {Learning Machine Tending from Demonstration with Multimodal LLMs},
    author        = {Çağatay Odabaşı, Jochen Lindermayr, Jan Krieglstein, Kisa Predrag},
    booktitle     = {2025 IEEE International Conference on Automation Science and Engineering (CASE)},
    pages         = {1569--1576},
    year          = {2025},
    month         = {08},
    venue         = {CASE},
    doi           = {https://doi.org/10.1109/CASE58245.2025.11163852},
    abstract      = {Driven by the need for increased efficiency and flexibility in manufacturing, particularly in demanding sectors like semiconductor production, this paper presents a framework for intuitive robot programming using multimodal Large Language Models (mLLMs). Our methodology enables robot programming through human demonstration, using AR glasses to capture video, audio narration, and hand poses of an operator performing a machine tending task. This multimodal data is processed by an mLLM, which segments the demonstration temporally, transcribes narration, assigns low-level robot skills from a predefined library, provides reasoning for these assignments, and identifies interacted objects. Crucially, hand poses and pose of the robot according to the machine (via QR codes) are used to parameterize the selected skills, ensuring accurate translation to the robot’s workspace. These parameterized skills are then automatically compiled into executable programs for a UR5e robot on a mobile base. Experimental evaluation in a machine tending scenario demonstrated high accuracy, with a median positional error of less than 4 cm between the robot’s executed actions (e.g., Press Button) and the corresponding physical locations of those interaction points in the environment. Although the framework allows high level of automation, its transparent, multi-stage design also allows for operator corrections, further enhancing precision.}
}
@inproceedings{zhang20233d,
    title           = {3D Hapkit: A Low-Cost, Open-Source, 3-DOF Haptic Device Based on the Delta Parallel Mechanism},
    author          = {Han Zhang, Jan Ulrich Bartels, Jeremy Brown},
    year            = {2023},
    month           = {07},
    booktitle       = {World Haptics},
    publisher       = {IEEE},
    abstract        = {We present our work on an open-source, low-cost, 3-Degree Of Freedom (3-DOF) haptic device for use in haptic education. The device is based on three open-source 1-DOF haptic devices in a delta configuration and can be produced using commonly available rapid prototyping methodologies such as 3D printing and laser cutting. We also demonstrate a simple interaction with a virtual environment.},
    pdf             = {https://2023.worldhaptics.org/wp-content/uploads/2023/06/1070-doc.pdf},
    venue           = {IEEE World Haptics Conference}
}
@inproceedings{lee2023deimos,
    title           = {Deimos: A Grammar of Dynamic Embodied Immersive Visualisation Morphs and Transitions},
    author          = {Benjamin Lee, Arvind Satyanarayan, Maxime Cordeil, Arnaud Prouzeau, Bernhard Jenny, Tim Dwyer},
    year            = {2023},
    month           = {04},
    booktitle       = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
    location        = {Hamburg, Germany},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {CHI '23},
    doi             = {https://doi.org/10.1145/3544548.3580754},
    isbn            = {9781450394215},
    abstract        = {We present Deimos, a grammar for specifying dynamic embodied immersive visualisation morphs and transitions. A morph is a collection of animated transitions that are dynamically applied to immersive visualisations at runtime and is conceptually modelled as a state machine. It is comprised of state, transition, and signal specifications. States in a morph are used to generate animation keyframes, with transitions connecting two states together. A transition is controlled by signals, which are composable data streams that can be used to enable embodied interaction techniques. Morphs allow immersive representations of data to transform and change shape through user interaction, facilitating the embodied cognition process. We demonstrate the expressivity of Deimos in an example gallery and evaluate its usability in an expert user study of six immersive analytics researchers. Participants found the grammar to be powerful and expressive, and showed interest in drawing upon Deimos’ concepts and ideas in their own research.},
    articleno       = {810},
    numpages        = {18},
    keywords        = {grammar, user study, data visualisation, Immersive Analytics, embodied interaction, animated transitions},
    video           = {https://www.youtube.com/embed/L9Ngzh1w7nM?si=Pal7OjvpW1HnhEFv},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3544548.3580754},
    venue           = {CHI}
}
@inproceedings{windhager2023skalierbare,
    title           = {Skalierbare Blicke auf Leben und Werk: Visuelle Analyse und Kuratierung von kulturellen Objekten und Künstler*innen-Biographien},
    author          = {Florian Windhager, Johannes Liem, Eva Mayr, Matthias Schlögl, Carla Ebel, Stefan Probst, Samuel Beck, Steffen Koch},
    year            = {2023},
    month           = {03},
    booktitle       = {DHd 2023 Open Humanities Open Culture},
    doi             = {https://doi.org/10.5281/zenodo.7715542},
    venue           = {DHd},
    abstract        = {Als Early-Access-Workshop mit einer neuen Kulturdaten-Plattform zielt die Veranstaltung auf die Erprobung und Diskussion von State-of-the-Art-Methoden im Bereich der kulturellen Sammlungs- und Biografiedatenvisualisierung. Das H2020-Projekt 'InTaVia' (InTangible European Heritage Visual Analysis, Curation und Communication, https://intavia.eu) integriert kulturelle Objektdaten und strukturierte Biografiedaten-Bestände mehrerer Länder und führt sie in synoptischer Weise der Arbeit von Historiker*innen und kulturellen Praktiker*innen zu. Eine zentrale Rolle spielen dabei Methoden der Datenvisualisierung (inkl. Karten, Netzwerke, Mengendiagramme, oder Zeitstrahlen) welche die visuelle Analyse und Kommunikation von kleineren oder größeren Datensammlungen möglich machen. Der Workshop bietet eine praktische Einführung in die Arbeit mit diesen multiperspektivischen Werkzeugen, sowie eine Möglichkeit der Initiierung von kollaborativen Fallstudien. Ein Beitrag zur 9. Tagung des Verbands 'Digital Humanities im deutschsprachigen Raum' - DHd 2023 Open Humanities Open Culture.}
}
@article{talsma2023validation,
    title           = {Validation of a moving base driving simulator for motion sickness research},
    author          = {Tessa M. W. Talsma, Omar Hassanain, Riender Happee, Ksander N. de Winkel},
    year            = {2023},
    month           = {01},
    journal         = {Applied Ergonomics},
    volume          = {106},
    pages           = {103897},
    doi             = {https://doi.org/10.1016/j.apergo.2022.103897},
    issn            = {0003-6870},
    url             = {https://www.sciencedirect.com/science/article/pii/S0003687022002204},
    keywords        = {Motion, Sickness, Driving, Simulator, Comfort, Validation},
    abstract        = {Increasing levels of vehicle automation are envisioned to allow drivers to engage in other activities but are also likely to increase the incidence of Carsickness or Motion Sickness (MS). Ideally, MS is studied in a safe and controlled environment, such as a driving simulator. However, only few studies address the suitability of driving simulators to assess MS. In this study, we validate a moving base driving simulator for MS research by comparing the symptoms and time course of MS between a real-road driving scenario and a rendition of this scenario in a driving simulator, using a within-subjects design. 25 participants took part as passengers in an experiment with alternating sections (slaloming, stop-and-go) with normal and provocative driving styles. Participants performed Sudoku puzzles (eyes-off-road) during both scenarios and reported MIsery SCale (MISC) scores at 30 s intervals. Motion Sickness Assessment Questionnaire (MSAQ) scores were collected upon completion of either scenario. Overall, the results indicate that MS was more severe in the car than in the simulator. Nevertheless, significant correlations were found between individual MS in the car and simulator for 3 out of 4 MSAQ symptom categories (0.48 &lt; r &lt; 0.73, p &lt; 0.02), with a strong overall correlation (r = 0.57, p = 0.004). MS onset times were similar between the car and the simulator, and sickness fluctuations as a result of driving style showed a similar pattern between scenarios, albeit more pronounced in the car. Based on observed similarities in MS, we conclude these simulator results to have relative validity. We attribute the observed reduction of MS severity in the simulator to the downscaling of the motion by the Motion Cueing Algorithm (MCA). These results suggest that, at least in eyes-off-road conditions, findings on MS from simulator studies may generalize to real vehicles after application of a conversion factor. This conversion factor is likely to depend on simulator and MCA characteristics.},
    venue           = {Applied Ergonomics}
}
@article{sadler2022towards,
    title           = {Towards Explainable Community Finding},
    author          = {Sophie Sadler, Derek Greene, Daniel Archambault},
    year            = {2022},
    month           = {12},
    journal         = {Applied Network Science},
    publisher       = {Springer},
    volume          = {7},
    number          = {1},
    pages           = {81},
    doi             = {https://doi.org/10.1007/s41109-022-00515-6},
    pdf             = {http://derekgreene.com/papers/sadler22explainable.pdf},
    venue           = {Applied Network Science},
    abstract        = {The detection of communities of nodes is an important task in understanding the structure of networks. Multiple approaches have been developed to tackle this problem, many of which are in common usage in real-world applications, such as in public health networks. However, clear insight into the reasoning behind the community labels produced by these algorithms is rarely provided. Drawing inspiration from the machine learning literature, we aim to provide post-hoc explanations for the outputs of these algorithms using interpretable features of the network. In this paper, we propose a model-agnostic methodology that identifies a set of informative features to help explain the output of a community finding algorithm. We apply it to three well-known algorithms, though the methodology is designed to generalise to new approaches. As well as identifying important features for a post-hoc explanation system, we report on the common features found made by the different algorithms and the differences between the approaches.}
}
@article{zhang2022towards,
    title           = {Towards reducing visual workload in surgical navigation: proof-of-concept of an augmented reality haptic guidance system},
    author          = {Gesiren Zhang, Jan Ulrich Bartels, Alejandro Martin-Gomez, Mehran Armand},
    year            = {2022},
    month           = {12},
    journal         = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging \& Visualization},
    publisher       = {Taylor \& Francis},
    volume          = {11},
    number          = {4},
    pages           = {1073--1080},
    doi             = {https://doi.org/10.1080/21681163.2022.2152372},
    pdf             = {https://www.tandfonline.com/doi/pdf/10.1080/21681163.2022.2152372},
    venue           = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization},
    abstract        = {The integration of planning and navigation capabilities into the operating room has enabled surgeons take on more precise procedures. Traditionally, planning and navigation information is presented using monitors in the surgical theatre. But the monitors force the surgeon to frequently look away from the surgical area. Augmented reality technologies have enabled surgeons to visualise navigation information in-situ. However, burdening the visual field with additional information can be distracting. We propose integrating haptic feedback into a surgical tool handle to enable surgical guidance capabilities. This property reduces the amount of visual information, freeing surgeons to maintain visual attention over the patient and the surgical site. To investigate the feasibility of this guidance paradigm we conducted a pilot study with six subjects. Participants traced paths, pinpointed locations and matched alignments with a mock surgical tool featuring a novel haptic handle. We collected quantitative data, tracking user’s accuracy and time to completion as well as subjective cognitive load. Our results show that haptic feedback can guide participants using a tool to sub-millimetre and sub-degree accuracy with only little training. Participants were able to match a location with an average error of 0.82mm, desired pivot alignments with an average error of 0.83° and desired rotations to 0.46°.}
}
@article{yang2022collaborative,
    title           = {Towards Immersive Collaborative Sensemaking},
    author          = {Ying Yang, Tim Dwyer, Michael Wybrow, Benjamin Lee, Maxime Cordeil, Mark Billinghurst, Bruce H Thomas},
    year            = {2022},
    month           = {11},
    journal         = {Proc. ACM Hum.-Comput. Interact.},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    volume          = {6},
    number          = {ISS},
    doi             = {https://doi.org/10.1145/3567741},
    abstract        = {When collaborating face-to-face, people commonly use the surfaces and spaces around them to perform sensemaking tasks, such as spatially organising documents, notes or images. However, when people collaborate remotely using desktop interfaces they no longer feel like they are sharing the same space. This limitation may be overcome through collaboration in immersive environments, which simulate the physical in-person experience. In this paper, we report on a between-groups study comparing collaborations on image organisation tasks, in an immersive Virtual Reality (VR) environment to more conventional desktop conferencing. Collecting data from 40 subjects in groups of four, we measured task performance, user behaviours, collaboration engagement and awareness. Overall, the VR and desktop interface resulted in similar speed, accuracy and social presence rating, but we observed more conversations and interaction with objects, and more equal contributions to the interaction from participants within groups in VR. We also identified differences in coordination and collaborative awareness behaviours between VR and desktop platforms. We report on a set of systematic measures for assessing VR collaborative experience and a new analysis tool that we have developed to capture user behaviours in collaborative setting. Finally, we provide design considerations and directions for future work.},
    articleno       = {588},
    numpages        = {25},
    keywords        = {Virtual Reality, Collaborative Sensemaking},
    video           = {https://www.youtube.com/embed/8AxNxvPAdYk?si=HkqH_lbC1TrlBxtY},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3567741#sec-supp},
    venue           = {ISS}
}
@article{winkel2022a,
    title           = {A meta-analysis of simulator sickness as a function of simulator fidelity},
    author          = {Ksander N. de Winkel, Tessa M. W. Talsma, Riender Happee},
    year            = {2022},
    month           = {10},
    journal         = {Experimental Brain Research},
    publisher       = {Springer},
    volume          = {240},
    number          = {12},
    pages           = {3089--3105},
    doi             = {https://doi.org/10.1007/s00221-022-06485-6},
    pdf             = {https://link.springer.com/content/pdf/10.1007/s00221-022-06485-6.pdf},
    venue           = {Exp Brain Res},
    abstract        = {Driving simulators are an increasingly important tool to develop vehicle functionalities and to study driver or passenger responses. A major hindrance to the use and validity of such studies is Simulator Sickness (SS). Several studies have suggested a positive relation between improvements in simulator fidelity and the likelihood of sickness. We hypothesized that this relation only holds true for static (fixed-base) simulators, and that increased fidelity in fact reduces simulator sickness in dynamic (moving-base) simulators. We performed a meta-analysis investigating the relation between sickness and fidelity in static and dynamic systems. A literature search yielded a total of 41 simulator studies that varied aspects of mechanical and/or visual fidelity and assessed SS for the same driving conditions and the same or equivalent participant groups. Evaluation of a model synthesizing the findings of these studies indicates that SS decreases with visual fidelity, and suggests that this effect may be negated for static simulators. The results of the modeling efforts thereby provide some support for the hypothesis that increased fidelity can reduce SS in dynamic simulators. Based on the evaluation of the literature we also note particular shortcomings and gaps in available research. Finally, we make recommendations for specific experiments that may fill these gaps and allow definitive conclusions on the role of simulator fidelity in SS.}
}
@inproceedings{mayr2022multiple,
    title           = {The Multiple Faces of Cultural Heritage: Towards an Integrated Visualization Platform for Tangible and Intangible Cultural Assets},
    author          = {Eva Mayr, Florian Windhager, Johannes Liem, Samuel Beck, Steffen Koch, Jakob Kusnic},
    year            = {2022},
    month           = {10},
    booktitle       = {2022 IEEE 7th Workshop on Visualization for the Digital Humanities (VIS4DH)},
    pages           = {13--18},
    doi             = {https://doi.org/10.1109/VIS4DH57440.2022.00008},
    abstract        = {Linking and visualizing multiple types of entities in a DH knowledge graph generates the need to deal with multiple types of data and media modalities both on the designer and the user side. The InTaVia project develops synoptic visual representations for a multimodal historical knowledge graph which draws together transnational data about cultural objects and historical actors. In this paper we reflect on the question how to integrate and mediate the informational and visual affordances of both kinds of cultural data with hybrid designs and show how a user-centered design process can help to ground the required selections and design choices in an empirical procedure.},
    venue           = {VIS4DH}
}
@inproceedings{wieland2022towards,
    title           = {Towards Inclusive Conversations in Virtual Reality for People with Visual Impairments},
    author          = {Markus Wieland, Tonja Machulla},
    year            = {2022},
    month           = {09},
    booktitle       = {Mensch und Computer 2022 - Workshopband},
    publisher       = {Gesellschaft für Informatik e.V.},
    address         = {Bonn},
    doi             = {https://doi.org/10.18420/muc2022-mci-ws11-467},
    editor          = {Marky, Karola AND Grünefeld, Uwe AND Kosch, Thomas},
    venue           = {MuC},
    abstract        = {Current mainstream social Virtual Reality (VR) spaces pose barriers to the equal participation of people with visual impairments (PVI) in social interactions. At present, VR is first and primarily a visual medium with a strong emphasis on the visual design of the VR scene and the available avatars. If social communication cues, such as non-verbal communication, are available at all, they are often not provided in a form accessible to PVI. Such cues are essential in social interactions to successfully participate in social interactions and experience a conversation in VR as realistic. Here, we summarize previous research regarding specific requirements for social VR spaces to be accessible to PVIs. We describe how people with disabilities recognize and identify potential conversational partners and how non-verbal communication works between PVI and sighted people. Our goal was to provide an overview of valuable features that can be implemented for inclusive conversations in a social VR space.}
}
@inproceedings{beck2022transient,
    title           = {How is Transient Behavior Addressed in Practice? Insights from a Series of Expert Interviews},
    author          = {Samuel Beck, Sebastian Frank, Alireza Hakamian, André van Hoorn},
    year            = {2022},
    month           = {07},
    booktitle       = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
    location        = {Bejing, China},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {ICPE '22},
    pages           = {105–112},
    doi             = {https://doi.org/10.1145/3491204.3527483},
    isbn            = {9781450391597},
    abstract        = {Transient behavior occurs when a running software system changes from one steady-state to another. In microservice systems, such disruptions can, for example, be caused by continuous deployment, self-adaptation, and various failures. Although transient behavior could be captured in non-functional requirements, little is known of how that is handled in practice. Our objective was to study how architects and engineers approach runtime disruptions, which challenges they face, whether or not they specify transient behavior, and how currently employed tools and methods can be improved. To this end, we conducted semi-structured interviews with five experienced practitioners from major companies in Germany. We found that a big challenge in the industry is a lack of awareness of transient behavior by software stakeholders. Consequently, they often do not consider specifying it in non-functional requirements. Additionally, better tooling is needed to reduce the effort of analyzing transient behavior. We present two prototypes that we developed corresponding to these findings to improve the current situation. Beyond that, the insights we present can serve as pointers for interesting research directions for other researchers.},
    venue           = {ICPE}
}
@inproceedings{wieland2022nonverbal,
    title           = {Non-verbal Communication and Joint Attention Between People with and Without Visual Impairments: Deriving Guidelines for Inclusive Conversations in Virtual Realities},
    author          = {Markus Wieland, Lauren Thevin, Albrecht Schmidt, Tonja Machulla},
    year            = {2022},
    month           = {07},
    booktitle       = {Computers Helping People with Special Needs},
    publisher       = {Springer International Publishing},
    pages           = {295--304},
    doi             = {https://doi.org/10.1007/978-3-031-08648-9_34},
    isbn            = {978-3-031-08648-9},
    abstract        = {With the emergence of mainstream virtual reality (VR) platforms for social interactions, non-verbal communicative cues are increasingly being transmitted into the virtual environment. Since VR is primarily a visual medium, accessible VR solutions are required for people with visual impairments (PVI). However, existing propositions do not take into account social interactions, and therefore PVI are excluded from this type of experience. To address this issue, we conducted semi-structured interviews with eleven participants, seven of whom were PVI and four of whom were partners or close friends without visual impairments, to explore how non-verbal cues and joint attention are used and perceived in everyday social situations and conversations. Our goal was to provide guidelines for inclusive conversations in virtual environments for PVI. Our findings suggest that gaze, head direction, head movements, and facial expressions are important for both groups in conversations but often difficult to identify visually for PVI. From our findings, we provide concrete suggestions for the design of social VR spaces, inclusive to PVI.},
    venue           = {Lecture Notes in Computer Science}
}
@inproceedings{frey2022parameter,
    title           = {Parameter Adaptation In Situ: Design Impacts and Trade-Offs},
    author          = {Steffen Frey, Valentin Bruder, Florian Frieß, Patrick Gralka, Tobias Rau, Thomas Ertl, Guido Reina},
    year            = {2022},
    month           = {05},
    booktitle       = {In Situ Visualization for Computational Science},
    publisher       = {Springer International Publishing},
    pages           = {159--182},
    doi             = {https://doi.org/10.1007/978-3-030-81627-8_8},
    isbn            = {978-3-030-81627-8},
    venue           = {In Situ Visualization for Computational Science},
    abstract        = {This chapter presents a study of parameter adaptation in situ, exploring the resulting trade-offs in rendering quality and workload distribution. Four different use cases are analyzed with respect to configuration changes. First, the performance impact of load balancing and resource allocation variants on both simulation and visualization is investigated using the MegaMol framework. Its loose coupling scheme and architecture enable minimally invasive in situ operation without impacting the stability of the simulation with (potentially) experimental visualization code. Second, Volumetric Depth Images (VDIs) are considered: a compact, view-dependent intermediate representation that can efficiently be generated and used for post hoc exploration. A study of their inherent trade-offs regarding size, quality, and generation time provides the basis for parameter optimization. Third, streaming for remote visualization allows a user to monitor the progress of a simulation and to steer visualization parameters. Compression settings are adapted dynamically based on predictions via convolutional neural networks across different parts of images to achieve high frame rates for high-resolution displays like powerwalls. Fourth, different performance prediction models for volume rendering address offline scenarios (like hardware acquisition planning) as well as dynamic adaptation of parameters and load balancing. Finally, the chapter concludes by summarizing overarching approaches and challenges, discussing the potential role that adaptive approaches can play in increasing the efficiency of in situ visualization.}
}
@inproceedings{satriadi2022tangible,
    title           = {Tangible Globes for Data Visualisation in Augmented Reality},
    author          = {Kadek Satriadi, Jim Smiley, Barrett Ens, Maxime Cordeil, Tobias Czauderna, Benjamin Lee, Ying Yang, Tim Dwyer, Bernhard Jenny},
    year            = {2022},
    month           = {04},
    booktitle       = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
    location        = {New Orleans, LA, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {CHI '22},
    doi             = {https://doi.org/10.1145/3491102.3517715},
    isbn            = {9781450391573},
    abstract        = {Head-mounted augmented reality (AR) displays allow for the seamless integration of virtual visualisation with contextual tangible references, such as physical (tangible) globes. We explore the design of immersive geospatial data visualisation with AR and tangible globes. We investigate the “tangible-virtual interplay” of tangible globes with virtual data visualisation, and propose a conceptual approach for designing immersive geospatial globes. We demonstrate a set of use cases, such as augmenting a tangible globe with virtual overlays, using a physical globe as a tangible input device for interacting with virtual globes and maps, and linking an augmented globe to an abstract data visualisation. We gathered qualitative feedback from experts about our use case visualisations, and compiled a summary of key takeaways as well as ideas for envisioned future improvements. The proposed design space, example visualisations and lessons learned aim to guide the design of tangible globes for data visualisation in AR.},
    articleno       = {505},
    numpages        = {16},
    keywords        = {immersive analytics, augmented reality, geographic visualisation, tangible user interface},
    video           = {https://www.youtube.com/embed/QwlpML4D9lo?si=520UqiOvwHTLRLXQ},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3491102.3517715#sec-supp},
    venue           = {CHI}
}
@inproceedings{lee2022design,
    title           = {A Design Space For Data Visualisation Transformations Between 2D And 3D In Mixed-Reality Environments},
    author          = {Benjamin Lee, Maxime Cordeil, Arnaud Prouzeau, Bernhard Jenny, Tim Dwyer},
    year            = {2022},
    month           = {04},
    booktitle       = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
    location        = {New Orleans, LA, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {CHI '22},
    doi             = {https://doi.org/10.1145/3491102.3501859},
    isbn            = {9781450391573},
    note            = {Received an honorable mention award},
    badge           = {honorablemention},
    abstract        = {As mixed-reality (MR) technologies become more mainstream, the delineation between data visualisations displayed on screens or other surfaces and those floating in space becomes increasingly blurred. Rather than the choice of using either a 2D surface or the 3D space for visualising data being a dichotomy, we argue that users should have the freedom to transform visualisations seamlessly between the two as needed. However, the design space for such transformations is large, and practically uncharted. To explore this, we first establish an overview of the different states that a data visualisation can take in MR, followed by how transformations between these states can facilitate common visualisation tasks. We then describe a design space of how these transformations function, in terms of the different stages throughout the transformation, and the user interactions and input parameters that affect it. This design space is then demonstrated with multiple exemplary techniques based in MR.},
    articleno       = {25},
    numpages        = {14},
    keywords        = {animated transitions, mixed reality, Immersive Analytics, direct manipulation, visualisation},
    video           = {https://www.youtube.com/embed/jjB99Ruc5gY?si=9ErTft9MsLf9zVTo},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3491102.3501859#sec-supp},
    venue           = {CHI}
}
@inproceedings{sadler2022selecting,
    title           = {Selecting Informative Features for Post-hoc Community Explanation},
    author          = {Sophie Sadler, Derek Greene, Daniel Archambault},
    year            = {2022},
    month           = {01},
    booktitle       = {International conference on complex networks and their applications},
    pages           = {297--308},
    doi             = {https://doi.org/10.1007/978-3-030-93409-5_25},
    organization    = {Springer},
    pdf             = {http://derekgreene.com/papers/sadler21community.pdf},
    venue           = {COMPLEX NETWORKS},
    abstract        = {Community finding algorithms are complex, often stochastic algorithms used to detect highly-connected groups of nodes in a graph. As with “black-box” machine learning models, these algorithms typically provide little in the way of explanation or insight into their outputs. In this research paper, inspired by recent work in explainable artificial intelligence (XAI), we look to develop post-hoc explanations for community finding, which are agnostic of the choice of algorithm. Specifically, we propose a new approach to identify features that indicate whether a set of nodes comprises a coherent community or not. We evaluate our methodology, which selects interpretable features from a longlist of candidates, in the context of three well-known community finding algorithms.}
}
@article{smiley2021madeaxis,
    title           = {The MADE-Axis: A Modular Actuated Device to Embody the Axis of a Data Dimension},
    author          = {Jim Smiley, Benjamin Lee, Siddhant Tandon, Maxime Cordeil, Lonni Besançon, Jarrod Knibbe, Bernhard Jenny, Tim Dwyer},
    year            = {2021},
    month           = {11},
    journal         = {Proc. ACM Hum.-Comput. Interact.},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    volume          = {5},
    number          = {ISS},
    doi             = {https://doi.org/10.1145/3488546},
    note            = {Received an honorable mention award},
    badge           = {honorablemention},
    abstract        = {Tangible controls-especially sliders and rotary knobs-have been explored in a wide range of interactive applications for desktop and immersive environments. Studies have shown that they support greater precision and provide proprioceptive benefits, such as support for eyes-free interaction. However, such controls tend to be expressly designed for specific applications. We draw inspiration from a bespoke controller for immersive data visualisation, but decompose this design into a simple, wireless, composable unit featuring two actuated sliders and a rotary encoder. Through these controller units, we explore the interaction opportunities around actuated sliders; supporting precise selection, infinite scrolling, adaptive data representations, and rich haptic feedback; all within a mode-less interaction space. We demonstrate the controllers' use for simple, ad hoc desktop interaction,before moving on to more complex, multi-dimensional interactions in VR and AR. We show that the flexibility and composability of these actuated controllers provides an emergent design space which covers the range of interactive dynamics for visual analysis. In a user study involving pairs performing collaborative visual analysis tasks in mixed-reality, our participants were able to easily compose rich visualisations, make insights and discuss their findings.},
    articleno       = {501},
    numpages        = {23},
    keywords        = {data visualization, embodied interfaces},
    video           = {https://www.youtube.com/embed/ILZlecsvUbw?si=J0MLhhvmzZBXf70D},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3488546#sec-supp},
    venue           = {ISS}
}
@proceedings{beck2021transvis,
    title           = {TransVis: Using Visualizations and Chatbots for Supporting Transient Behavior in Microservice Systems},
    author          = {Samuel Beck, Sebastian Frank, Alireza Hakamian, Leonel Merino, André van Hoorn},
    year            = {2021},
    month           = {09},
    booktitle       = {2021 Working Conference on Software Visualization (VISSOFT)},
    pages           = {65--75},
    doi             = {https://doi.org/10.1109/VISSOFT52517.2021.00016},
    isbn            = {978-1-6654-3144-6},
    abstract        = {In a microservice system, runtime changes such as failures, deployments, or self-adaptation can trigger the system to transition from one steady state to another, i.e., exhibiting transient behavior. To assess a system's quality, it is imperative that this transient behavior is specified in non-functional requirements and that stakeholders can analyze whether these requirements are met. Yet, there is little support for either specifying transient behavior as a non-functional requirement or analyzing how such a requirement is met in production. We aim to make these two tasks more accessible by utilizing novel human-computer interaction methods. To this end, we developed TransVis, an approach for specifying and analyzing transient behavior based on chatbot interactions and visualizations of the systems' resilience. We examined the effectiveness of our approach by conducting an exploratory expert study on a prototypical implementation. The study revealed that the developed visualizations are effective for specifying and exploring transient behavior. Participants found especially helpful the feature to compare specifications with the actual behavior. However, the integration of a chatbot did not prove effective for our use cases. In conclusion, our approach is capable of supporting stakeholders in the exploration and specification of transient behavior.},
    venue           = {VISSOFT}
}
@inproceedings{vogelsang2021a,
    title           = {A Design Space for User Interface Elements using Finger Orientation Input},
    author          = {Jonas Vogelsang, Francisco Kiss, Sven Mayer},
    year            = {2021},
    month           = {09},
    booktitle       = {Proceedings of Mensch Und Computer 2021},
    location        = {Ingolstadt, Germany},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {MuC '21},
    pages           = {1–10},
    doi             = {https://doi.org/10.1145/3473856.3473862},
    isbn            = {9781450386456},
    abstract        = {Despite touchscreens being used by billions of people every day, today’s touch-based interactions are limited in their expressiveness as they mostly reduce the rich information of the finger down to a single 2D point. Researchers have proposed using finger orientation as input to overcome these limitations, adding two extra dimensions – the finger’s pitch and yaw angles. While finger orientation has been studied in-depth over the last decade, we describe an updated design space. Therefore, we present expert interviews combined with a literature review to describe the wide range of finger orientation input opportunities. First, we present a comprehensive set of finger orientation input enhanced user interface elements supported by expert interviews. Second, we extract design implications as a result of the additional input parameters. Finally, we introduce a design space for finger orientation input.},
    numpages        = {10},
    keywords        = {finger orientation, touch devices, interaction, design space, touchscreen, interfaces, expert interviews},
    pdf             = {https://dl.acm.org/doi/pdf/10.1145/3473856.3473862},
    venue           = {MuC}
}
@misc{spyrison2021is,
    title           = {Is IEEE VIS *that* good? On key factors in the initial assessment of manuscript and venue quality},
    author          = {Nicholas Spyrison, Benjamin Lee, Lonni Besançon},
    year            = {2021},
    month           = {07},
    publisher       = {OSF Preprints},
    doi             = {https://doi.org/10.31219/osf.io/65wm7},
    url             = {osf.io/65wm7},
    suppl           = {https://osf.io/ch6p4/},
    venue           = {alt.VIS},
    abstract        = {Background: Academic performance is at the heart of hiring decisions and funding applications. It is based on a combination of qualitative and quantitative metrics. One of those is the venue in which scholarly publications are published. Depending on the perceived (qualitative) or measured (quantitative) prestige associated with a venue, a specific publication will have more or less weight. Objectives: We want to understand how visualization researchers consider the prestige of a venue when looking for papers that they could use in their own manuscripts, and how they determine the prestige of any given venue. Method: We ran an online survey open for 10 days that we sent out to visualization researchers. Results: We gathered 46 responses from a sample of convenience. We found that publication venue plays the biggest part in how visualization researchers assess research articles. Interestingly, rating systems and metrics are least important criteria for researchers when assessing the quality of a venue. Conclusion: We highlight the potential risks around focusing on venue when assessing research articles. We further underline the necessity to discuss with the community on strategies to switch the focus to robustness and reliability to foster better practices and less stressful publishing expectations. Reproducibility: Data, materials and preregistration available on osf.io/ch6p4/}
}
@article{machicao2021a,
    title           = {A Visual Analysis Method of Randomness for Classifying and Ranking Pseudo-Random Number Generators},
    author          = {Jeaneth Machicao, Quynh Quang Ngo, Vladimir Molchanov, Lars Linsen, Odemir M Bruno},
    year            = {2021},
    month           = {04},
    journal         = {Inf. Sci.},
    volume          = {558},
    pages           = {1--20},
    doi             = {https://doi.org/10.1016/j.ins.2020.10.041},
    venue           = {IS},
    abstract        = {The development of new pseudo-random number generators (PRNGs) has steadily increased over the years. Commonly, PRNGs’ randomness is “measured” by using statistical pass/fail suite tests, but the question remains, which PRNG is the best when compared to others. Existing randomness tests lack means for comparisons between PRNGs, since they are not quantitatively analysing. It is, therefore, an important task to analyze the quality of randomness for each PRNG, or, in general, comparing the randomness property among PRNGs. In this paper, we propose a novel visual approach to analyze PRNGs randomness allowing for a ranking comparison concerning the PRNGs’ quality. Our analysis approach is applied to ensembles of time series which are outcomes of different PRNG runs. The ensembles are generated by using a single PRNG method with different parameter settings or by using different PRNG methods. We propose a similarity metric for PRNG time series for randomness and apply it within an interactive visual approach for analyzing similarities of PRNG time series and relating them to an optimal result of perfect randomness. The interactive analysis leads to an unsupervised classification, from which respective conclusions about the impact of the PRNGs’ parameters or rankings of PRNGs on randomness are derived. We report new findings using our approach in a study of randomness for state-of-the-art numerical PRNGs such as LCG, PCG, SplitMix, Mersenne Twister, and RANDU as well as chaos-based PRNG families such as K-Logistic map and K-Tent map with varying parameter K.}
}
@article{lee2020data,
    title           = {Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality},
    author          = {Benjamin Lee, Dave Brown, Bongshin Lee, Christophe Hurter, Steven Drucker, Tim Dwyer},
    year            = {2020},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {27},
    number          = {2},
    pages           = {1095--1105},
    doi             = {https://doi.org/10.1109/TVCG.2020.3030435},
    issn            = {1941-0506},
    note            = {Received an honorable mention award},
    badge           = {honorablemention},
    abstract        = {A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.},
    video           = {https://www.youtube.com/embed/XmYNISBjL_Q?si=vG5h--hQ--0BFaJl},
    venue           = {VIS}
}
@article{lee2020shared,
    title           = {Shared Surfaces and Spaces: Collaborative Data Visualisation in a Co-located Immersive Environment},
    author          = {Benjamin Lee, Xiaoyun Hu, Maxime Cordeil, Arnaud Prouzeau, Bernhard Jenny, Tim Dwyer},
    year            = {2020},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {27},
    number          = {2},
    pages           = {1171--1181},
    doi             = {https://doi.org/10.1109/TVCG.2020.3030450},
    issn            = {1941-0506},
    abstract        = {Immersive technologies offer new opportunities to support collaborative visual data analysis by providing each collaborator a personal, high-resolution view of a flexible shared visualisation space through a head mounted display. However, most prior studies of collaborative immersive analytics have focused on how groups interact with surface interfaces such as tabletops and wall displays. This paper reports on a study in which teams of three co-located participants are given flexible visualisation authoring tools to allow a great deal of control in how they structure their shared workspace. They do so using a prototype system we call FIESTA: the Free-roaming Immersive Environment to Support Team-based Analysis. Unlike traditional visualisation tools, FIESTA allows users to freely position authoring interfaces and visualisation artefacts anywhere in the virtual environment, either on virtual surfaces or suspended within the interaction space. Our participants solved visual analytics tasks on a multivariate data set, doing so individually and collaboratively by creating a large number of 2D and 3D visualisations. Their behaviours suggest that the usage of surfaces is coupled with the type of visualisation used, often using walls to organise 2D visualisations, but positioning 3D visualisations in the space around them. Outside of tightly-coupled collaboration, participants followed social protocols and did not interact with visualisations that did not belong to them even if outside of its owner's personal workspace.},
    video           = {https://www.youtube.com/embed/0ksaAnu9kog?si=APzzazMVKom2ZsLW},
    suppl           = {https://sites.google.com/monash.edu/shared-surfaces-and-spaces},
    venue           = {VIS}
}
@inproceedings{ngo2020interactive,
    title           = {Interactive Generation of 1D Emeddings from 2D Multi-dimensional Data Projections},
    author          = {Quynh Quang Ngo, Lars Linsen},
    year            = {2020},
    month           = {10},
    booktitle       = {25th International Symposium on Vision, Modeling and Visualization, VMV 2020, Tübingen, Germany, September 28 - October 1, 2020},
    publisher       = {Eurographics Association},
    pages           = {79--87},
    doi             = {https://doi.org/10.2312/vmv.20201190},
    editor          = {Jens H. Krüger and Matthias Nießner and Jörg Stückler},
    venue           = {VMV},
    abstract        = {Visual analysis of multi-dimensional data is commonly supported by mapping the data to a 2D embedding. When analyzing a sequence of multi-dimensional data, e.g., in case of temporal data, the usage of 1D embeddings allows for plotting the entire sequence in a 2D layout. Despite the good performance in generating 2D embeddings, 1D embeddings often exhibit a much lower quality for pattern recognition tasks. We propose to overcome the issue by involving the user to generate 1D embeddings of multi-dimensional data in a two-step procedure: We first generate a 2D embedding and then leave the task of reducing the 2D to a 1D embedding to the user. We demonstrate that an interactive generation of 1D embeddings from 2D projected views can be performed efficiently, effectively, and targeted towards an analysis task. We compare the performance of our approach against automatically generated 1D and 2D embeddings involving a user study for our interactive approach. We test the 1D approaches when being applied to time-varying multi-dimensional data.}
}
@article{le2020shortcut,
    title           = {Shortcut Gestures for Mobile Text Editing on Fully Touch Sensitive Smartphones},
    author          = {Huy Viet Le, Sven Mayer, Maximilian Weiß, Jonas Vogelsang, Henrike Weingärtner, Niels Henze},
    year            = {2020},
    month           = {08},
    journal         = {ACM Trans. Comput.-Hum. Interact.},
    publisher       = {ACM},
    volume          = {27},
    number          = {5},
    doi             = {https://doi.org/10.1145/3396233},
    issn            = {1073-0516},
    abstract        = {While advances in mobile text entry enable smartphone users to type almost as fast as on hardware keyboards, text-heavy activities are still not widely adopted. One reason is the lack of shortcut mechanisms. In this article, we determine shortcuts for text-heavy activities, elicit shortcut gestures, implement them for a fully touch-sensitive smartphone, and conduct an evaluation with potential users. We found that experts perform around 800 keyboard shortcuts per day, which are not available on smartphones. Interviews revealed the lack of shortcuts as a major limitation that prevents mobile text editing. Therefore, we elicited gestures for the 22 most important shortcuts for smartphones that are touch-sensitive on the whole device surface. We implemented the gestures for a fully touch-sensitive smartphone using deep learning and evaluated them in realistic scenarios to gather feedback. We show that the developed prototype is perceived as intuitive and faster than recent commercial approaches.},
    articleno       = {33},
    numpages        = {38},
    keywords        = {Shortcuts, text editing, gestures, smartphone, keyboard},
    pdf             = {https://dl.acm.org/doi/pdf/10.1145/3396233},
    venue           = {TOCHI}
}
@article{hube2020mixed,
    title           = {Mixed Reality based Collaboration for Design Processes},
    author          = {Natalie Hube, Mathias Müller, Esther Lapczyna, Jan Wojdziak},
    year            = {2020},
    month           = {08},
    journal         = {i-com},
    publisher       = {De Gruyter Oldenbourg},
    volume          = {19},
    number          = {2},
    pages           = {123--137},
    doi             = {https://doi.org/10.1515/icom-2020-0012},
    venue           = {i-com},
    abstract        = {Due to constantly and rapidly growing digitization, requirements for international cooperation are changing. Tools for collaborative work such as video telephony are already an integral part of today’s communication across companies. However, these tools are not sufficient to represent the full physical presence of an employee or a product as well as its components in another location, since the representation of information in a two-dimensional way and the resulting limited communication loses concrete objectivity. Thus, we present a novel object-centered approach that compromises of Augmented and Virtual Reality technology as well as design suggestions for remote collaboration. Furthermore, we identify current key areas for future research and specify a design space for the use of Augmented and Virtual Reality remote collaboration in the manufacturing process in the automotive industry.}
}
@inproceedings{okanovic2020chatbot,
    title           = {Can a Chatbot Support Software Engineers with Load Testing? Approach and Experiences},
    author          = {Dusan Okanovic, Samuel Beck, Lasse Merz, Christoph Zorn, Leonel Merino, Andre van Hoorn, Fabian Beck},
    year            = {2020},
    month           = {04},
    booktitle       = {Proceedings of the ACM/SPEC International Conference on Performance Engineering (ICPE)},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {ICPE '20},
    pages           = {120--129},
    doi             = {https://doi.org/10.1145/3358960.3375792},
    abstract        = {Even though load testing is an established technique to assess load-related quality properties of software systems, it is applied only seldom and with questionable results. Indeed, configuring, executing, and interpreting results of a load test require high effort and expertise. Since chatbots have shown promising results for interactively supporting complex tasks in various domains (including software engineering), we hypothesize that chatbots can provide developers suitable support for load testing. In this paper, we present PerformoBot, our chatbot for configuring and running load tests. In a natural language conversation, PerformoBot guides developers through the process of properly specifying the parameters of a load test, which is then automatically executed by PerformoBot using a state-of-the-art load testing tool. After the execution, PerformoBot provides developers a report that answers the respective concern. We report on results of a user study that involved 47 participants, in which we assessed our tool's acceptance and effectiveness. We found that participants in the study, particularly those with a lower level of expertise in performance engineering, had a mostly positive view of PerformoBot.},
    venue           = {ICPE}
}
@inproceedings{boshe-plois2020visual,
    title           = {Visual Analysis of Billiard Dynamics Simulation Ensembles},
    author          = {Stefan Boshe-Plois, Quynh Quang Ngo, Peter Albers, Lars Linsen},
    year            = {2020},
    month           = {02},
    booktitle       = {Proc. Int. Joint Conf. Computer Vision, Imaging and Computer Graphics Theory and Applications},
    publisher       = {SCITEPRESS},
    pages           = {185--192},
    doi             = {https://doi.org/10.5220/0008956201850192},
    venue           = {VISIGRAPP},
    editor          = {Andreas Kerren and Christophe Hurter and José Braz},
    pdf             = {https://www.scitepress.org/Papers/2020/89562/89562.pdf},
    abstract        = {Mathematical billiards assume a table of a certain shape and dynamical rules for handling collisions. Some trajectories exhibit distinguished patterns. Detecting such trajectories manually for a given billiard is cumbersome, especially, when assuming an ensemble of billiards with different parameter settings. We propose a visual analysis approach for simulation ensembles of billiard dynamics based on phase-space visualizations and multi-dimensional scaling. We apply our methods to the well-studied approach of dynamical billiards for validation and to the novel approach of symplectic billiards for new observations.}
}
@inproceedings{rau2019the,
    title           = {The Impact of Work Distribution on in Situ Visualization: A Case Study},
    author          = {Tobias Rau, Patrick Gralka, Oliver Fernandes, Guido Reina, Steffen Frey, Thomas Ertl},
    year            = {2019},
    month           = {11},
    booktitle       = {Proceedings of the Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization},
    location        = {Denver, Colorado, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {ISAV '19},
    pages           = {17–22},
    doi             = {https://doi.org/10.1145/3364228.3364233},
    note            = {Received an honorable mention award},
    badge           = {honorablemention},
    isbn            = {9781450377232},
    abstract        = {Large-scale computer simulations generate data at rates that necessitate visual analysis tools to run in situ. The distribution of work on and across nodes of a supercomputer is crucial to utilize compute resources as efficiently as possible. In this paper, we study two work distribution problems in the context of in situ visualization and jointly assess the performance impact of different variants. First, especially for simulations involving heterogeneous loads across their domain, dynamic load balancing can significantly reduce simulation run times. However, the adjustment of the domain partitioning associated with this also has a direct impact on visualization performance. The exact impact of this side effect is largely unclear a priori as generally different criteria are used for balancing simulation and visualization load. Second, on node level, the adequate allocation of threads to simulation or visualization tasks minimizes the performance drain of the simulation while also enabling timely visualization results. In our case study, we jointly study both work distribution aspects with the visualization framework MegaMol coupled in situ on node level to the molecular dynamics simulation ls1 Mardyn on Stampede2 at TACC.},
    numpages        = {6},
    keywords        = {visualization, load balancing, distributed rendering, HPC},
    venue           = {ISAV}
}
@inproceedings{lee2019fiesta,
    title           = {FIESTA: A Free Roaming Collaborative Immersive Analytics System},
    author          = {Benjamin Lee, Maxime Cordeil, Arnaud Prouzeau, Tim Dwyer},
    year            = {2019},
    month           = {11},
    booktitle       = {Proceedings of the 2019 ACM International Conference on Interactive Surfaces and Spaces},
    location        = {Daejeon, Republic of Korea},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {ISS '19},
    pages           = {335--338},
    doi             = {https://doi.org/10.1145/3343055.3360746},
    isbn            = {9781450368919},
    abstract        = {We present FIESTA, a prototype system for collaborative immersive analytics (CIA). In contrast to many existing CIA prototypes, FIESTA allows users to collaboratively work together wherever and however they wish-untethered from mandatory physical display devices. Users can freely move around in a shared room-sized environment, author and generate immersive data visualisations, position them in the space around them, and share and communicate their insights to one another. Certain visualisation tasks are also supported to facilitate this process, such as details on demand and brushing and linking.},
    numpages        = {4},
    keywords        = {virtual reality, collaborative immersive analytics, immersive analytics, collaboration, data visualisation},
    video           = {https://dl.acm.org/doi/abs/10.1145/3343055.3360746#sec-supp},
    venue           = {ISS}
}
@inproceedings{schatz2019visual,
    title           = {Visual Analysis of Structure Formation in Cosmic Evolution},
    author          = {Karsten Schatz, Christoph Müller, Patrick Gralka, Moritz Heinemann, Alexander Straub, Christoph Schulz, Matthias Braun, Tobias Rau, Michael Becher, Patrick Diehl, Dominic Marcello, Juhan Frank, Thomas Müller, Steffen Frey, Guido Reina, Daniel Weiskopf, Thomas Ertl},
    year            = {2019},
    month           = {10},
    booktitle       = {2019 IEEE Scientific Visualization Conference (SciVis)},
    pages           = {33--41},
    doi             = {https://doi.org/10.1109/scivis47405.2019.8968855},
    abstract        = {The IEEE SciVis 2019 Contest targets the visual analysis of structure formation in the cosmic evolution of the universe from when the universe was five million years old up to now. In our submission, we analyze high-dimensional data to get an overview, then investigate the impact of Active Galactic Nuclei (AGNs) using various visualization techniques, for instance, an adapted filament filtering method for detailed analysis and particle flow in the vicinity of filaments. Based on feedback from domain scientists on these initial visualizations, we also analyzed X-ray emissions and star formation areas. The conversion of star-forming gas to stars and the resulting increasing molecular weight of the particles could be observed.},
    venue           = {SciVis}
}
@inproceedings{rzayev2019notification,
    title           = {Notification in VR: The Effect of Notification Placement, Task, and Environment},
    shorttitle      = {Notification in VR},
    author          = {Rufat Rzayev, Sven Mayer, Christian Krauter, Niels Henze},
    year            = {2019},
    month           = {10},
    booktitle       = {Proc. Symp. Computer-Human Interaction in Play},
    publisher       = {ACM},
    series          = {CHI Play},
    pages           = {199--211},
    doi             = {https://doi.org/10.1145/3311350.3347190},
    isbn            = {978-1-4503-6688-5},
    abstract        = {Virtual reality (VR) is commonly used for entertainment applications but is also increasingly employed for a large number of use cases such as digital prototyping or training workers. Here, VR is key to present an immersive secondary world. VR enables experiences that are close to reality, regardless of time and place. However, highly immersive VR can result in missing digital information from the real world, such as important notifications. For efficient notification presentation in VR, it is necessary to understand how notifications should be integrated in VR without breaking the immersion. Thus, we conducted a study with 24 participants to investigate notification placement in VR while playing games, learning, and solving problems. We compared placing notifications using a Head-Up Display, On-Body, Floating, and In-Situ in open, semi-open, and closed VR environments. We found significant effects of notification placement and task on how notifications are perceived in VR. Insights from our study inform the design of VR applications that support digital notifications.},
    video           = {https://www.youtube.com/embed/DTK-17OwZrc?si=faOyxTJW8lxhV7mo},
    video2          = {https://www.youtube.com/embed/UDuGSMygP94?si=2rd0TuhduWU8TjV0},
    venue           = {CHI PLAY}
}
@inproceedings{ngo2019visual,
    title           = {Visual Analytics of Simulation Ensembles for Network Dynamics},
    author          = {Quynh Quang Ngo, Marc-Thorsten Hütt, Lars Linsen},
    year            = {2019},
    month           = {10},
    booktitle       = {24th International Symposium on Vision, Modeling, and Visualization, VMV 2019, Rostock, Germany, September 30 - October 2, 2019},
    publisher       = {Eurographics Association},
    pages           = {89--97},
    doi             = {https://doi.org/10.2312/vmv.20191322},
    editor          = {Hans-Jörg Schulz and Matthias Teschner and Michael Wimmer},
    venue           = {VMV},
    abstract        = {A central question in the field of Network Science is to analyze the role of a given network topology on the dynamical behavior captured by time-varying simulations executed on the network. These dynamical systems are also influenced by global simulation parameters. We present a visual analytics approach that supports the investigation of the impact of the parameter settings, i.e., how parameter choices change the role of network topology on the simulations' dynamics. To answer this question, we are analyzing ensembles of simulation runs with different parameter settings executed on a given network topology. We relate the nodes' topological structures to their dynamical similarity in a 2D plot based on an interactively defined hierarchy of topological properties and a 1D embedding for the dynamical similarity. We evaluate interactively defined topological groups with respect to matching dynamical behavior, which we visually encode as graphs of the function of the considered simulation parameter. Interactive filtering and coordinated views allow for a detailed analysis of the parameter space with respect to topology-dynamics relations. Our visual analytics approach is applied to scenarios for excitable dynamics on synthetic and real brain connectome networks.}
}
@inproceedings{angerbauer2019interspeech,
    title           = {Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience},
    author          = {Katrin Angerbauer, Heike Adel, Ngoc Thang Vu},
    year            = {2019},
    month           = {09},
    booktitle       = {Proc. Interspeech 2019},
    pages           = {594--598},
    doi             = {https://doi.org/10.21437/Interspeech.2019-1750},
    pdf             = {https://www.isca-speech.org/archive/pdfs/interspeech_2019/angerbauer19_interspeech.pdf},
    venue           = {INTERSPEECH},
    abstract        = {Understanding spoken language can be impeded through factors like noisy environments, hearing impairments or lack of proficiency. Subtitles can help in those cases. However, for fast speech or limited screen size, it might be advantageous to compress the subtitles to their most relevant content. Therefore, we address automatic sentence compression in this paper. We propose a neural network model based on an encoder-decoder approach with the possibility of integrating the desired compression ratio. Using this model, we conduct a user study to investigate the effects of compressed subtitles on user experience. Our results show that compressed subtitles can suffice for comprehension but may pose additional cognitive load.}
}
@inproceedings{bruder2019voronoi-based,
    title           = {Voronoi-Based Foveated Volume Rendering},
    author          = {Valentin Bruder, Christoph Schulz, Ruben Bauer, Steffen Frey, Daniel Weiskopf, Thomas Ertl},
    year            = {2019},
    month           = {07},
    booktitle       = {EuroVis 2019 - Short Papers},
    publisher       = {The Eurographics Association},
    doi             = {https://doi.org/10.2312/evs.20191172},
    isbn            = {978-3-03868-090-1},
    editor          = {Johansson, Jimmy and Sadlo, Filip and Marai, G. Elisabeta},
    pdf             = {https://diglib.eg.org/bitstream/handle/10.2312/evs20191172/067-071.pdf?sequence=1&isAllowed=y},
    venue           = {EuroVis},
    abstract        = {Foveal vision is located in the center of the field of view with a rich impression of detail and color, whereas peripheral vision occurs on the side with more fuzzy and colorless perception. This visual acuity fall-off can be used to achieve higher frame rates by adapting rendering quality to the human visual system. Volume raycasting has unique characteristics, preventing a direct transfer of many traditional foveated rendering techniques. We present an approach that utilizes the visual acuity fall-off to accelerate volume rendering based on Linde-Buzo-Gray sampling and natural neighbor interpolation. First, we measure gaze using a stationary 1200 Hz eye-tracking system. Then, we adapt our sampling and reconstruction strategy to that gaze. Finally, we apply a temporal smoothing filter to attenuate undersampling artifacts since peripheral vision is particularly sensitive to contrast changes and movement. Our approach substantially improves rendering performance with barely perceptible changes in visual quality. We demonstrate the usefulness of our approach through performance measurements on various data sets.}
}
@inproceedings{hamid2019visual,
    title           = {Visual Ensemble Analysis to Study the Influence of Hyper-parameters on Training Deep Neural Networks},
    author          = {Sagad Hamid, Adrian Derstroff, Sören Klemm, Quynh Quang Ngo, Xiaoyi Jiang, Lars Linsen},
    year            = {2019},
    month           = {06},
    booktitle       = {2nd Workshop on Machine Learning Methods in Visualisation for Big Data, MLVis@EuroVis 2019, Porto, Portugal, June 3, 2019},
    publisher       = {Eurographics Association},
    pages           = {19--23},
    doi             = {https://doi.org/10.2312/mlvis.20191160},
    editor          = {Daniel Archambault and Ian T. Nabney and Jaakko Peltonen},
    venue           = {EuroVis},
    abstract        = {A good deep neural network design allows for efficient training and high accuracy. The training step requires a suitable choice of several hyper-parameters. Limited knowledge exists on how the hyper-parameters impact the training process, what is the interplay of multiple hyper-parameters, and what is the interrelation of hyper-parameters and network topology. In this paper, we present a structured analysis towards these goals by investigating an ensemble of training runs.We propose a visual ensemble analysis based on hyper-parameter space visualizations, performance visualizations, and visualizing correlations of topological structures. As a proof of concept, we apply our approach to deep convolutional neural networks.}
}
@inproceedings{mayer2019effect,
    title           = {Effect of Orientation on Unistroke Touch Gestures},
    author          = {Sven Mayer, Valentin Schwind, Huy Viet Le, Dominik Weber, Jonas Vogelsang, Johannes Wolf, Niels Henze},
    year            = {2019},
    month           = {05},
    booktitle       = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
    location        = {Glasgow, Scotland Uk},
    publisher       = {ACM},
    address         = {New York, NY, USA},
    series          = {CHI '19},
    pages           = {1–9},
    doi             = {https://doi.org/10.1145/3290605.3300928},
    isbn            = {9781450359702},
    abstract        = {As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures.},
    numpages        = {9},
    keywords        = {touch unistroke gestures, mobile device, user study, gesture set, orientation, design guidelines, touch input},
    video           = {https://www.youtube.com/embed/Ev30no1uSUU?si=UJfDnHBvwix43wW5},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3290605.3300928},
    pdf             = {https://dl.acm.org/doi/pdf/10.1145/3290605.3300928},
    venue           = {CHI}
}
@article{gralka2019megamol,
    title           = {MegaMol - a comprehensive prototyping framework for visualizations},
    author          = {Patrick Gralka, Michael Becher, Matthias Braun, Florian Frieß, Christoph Müller, Tobias Rau, Karsten Schatz, Christoph Schulz, Michael Krone, Guido Reina, Thomas Ertl},
    year            = {2019},
    month           = {03},
    journal         = {The European Physical Journal (Special Topics)},
    volume          = {227: Particle Methods in Natural Science and Engineering},
    number          = {14},
    pages           = {1817--1829},
    doi             = {https://doi.org/10.1140/epjst/e2019-800167-5},
    issn            = {1951-6401},
    abstract        = {We present MegaMol, a low-overhead prototyping framework for interactive visualization of large scientific data sets. We give a brief summary of related work for context and then focus on a comprehensive overview of the core architecture of the framework. This is followed by the existing and novel features and techniques in MegaMol that define its current functionality. MegaMol has originally been developed to support the visualization and analysis of particle-based data sets that, for instance, come from molecular dynamics simulations. Meanwhile, the software has evolved beyond that. New algorithms and techniques have been implemented to handle many diverse tasks, including information visualization. Additionally, improvements have been made on the software engineering side to make MegaMol more accessible for domain scientists, like an easy-to-handle scripting interface.},
    venue           = {The European Physical Journal (Special Topics)}
}
@inproceedings{kern2019lessons,
    title           = {Lessons Learned from Users Reading Highlighted Abstracts in a Digital Library},
    author          = {Dagmar Kern, Daniel Hienert, Katrin Angerbauer, Tilman Dingler, Pia Borlund},
    year            = {2019},
    month           = {03},
    booktitle       = {Proceedings of the 2019 Conference on Human Information Interaction and Retrieval},
    location        = {Glasgow, Scotland UK},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {CHIIR '19},
    pages           = {271–275},
    doi             = {https://doi.org/10.1145/3295750.3298950},
    isbn            = {9781450360258},
    abstract        = {Finding relevant documents is essential for researchers of all disciplines. We investigated an approach for supporting searchers in their relevance decision in a digital library by automatically highlighting the most important keywords in abstracts. We conducted an eye-tracking study with 25 subjects and observed very different search and reading behavior which lead to diverse results. Some of the participants liked that highlighted abstracts accelerate their relevance decision, while others found that they disturb the reading flow. What many agree on is that the quality of highlighting is crucial for trust and system credibility.},
    numpages        = {5},
    keywords        = {user study, highlighting, reading behavior, relevance judgment},
    venue           = {CHIIR}
}
@inproceedings{rau2019interactive,
    title           = {Interactive CPU-based Ray Tracing of Solvent Excluded Surfaces},
    author          = {Tobias Rau, Sebastian Zahn, Michael Krone, Guido Reina, Thomas Ertl},
    year            = {2019},
    month           = {01},
    booktitle       = {Eurographics Workshop on Visual Computing for Biology and Medicine},
    publisher       = {The Eurographics Association},
    doi             = {https://doi.org/10.2312/vcbm.20191249},
    isbn            = {978-3-03868-081-9},
    issn            = {2070-5786},
    editor          = {Kozlíková, Barbora and Linsen, Lars and Vázquez, Pere-Pau and Lawonn, Kai and Raidou, Renata Georgia},
    video           = {https://diglib.eg.org/bitstreams/80ff1321-d705-4e1d-b442-b2e06fdc1662/download},
    pdf             = {https://diglib.eg.org/bitstreams/9ccb687b-d219-463f-ac21-8591239a18c1/download},
    venue           = {VCBM 19: Eurographics Workshop on Visual Computing for Biology and Medicine},
    abstract        = {Depictions of molecular surfaces such as the Solvent Excluded Surface (SES) can provide crucial insight into functional molecular properties, such as the molecule's potential to react. The interactive visualization of single and multiple molecule surfaces is essential for the data analysis by domain experts. Nowadays, the SES can be rendered at high frame rates using shader-based ray casting on the GPU. However, rendering large molecules or larger molecule complexes requires large amounts of memory that has the potential to exceed the memory limitations of current hardware. Here we show that rendering using CPU ray tracing also reaches interactive frame rates without hard limitations to memory. In our results large molecule complexes can be rendered with only the precomputation of each individual SES, and no further involved representation or transformation. Additionally, we provide advanced visualization techniques like ambient occlusion opacity mapping (AOOM) to enhance the comprehensibility of the molecular structure. CPU ray tracing not only provides very high image quality and global illumination, which is beneficial for the perception of spatial structures, it also opens up the possibility to visualize larger data sets and to render on any HPC cluster. Our results demonstrate that simple instancing of geometry keeps the memory consumption for rendering large molecule complexes low, so the examination of much larger data is also possible.}
}
@inproceedings{yu2018effect,
    title           = {Effect of Using HMDs for One Hour on Preteens Visual Fatigue},
    author          = {Xingyao Yu, Dongdong Weng, Jie Guo, Haiyan Jiang, Yihua Bao},
    year            = {2018},
    month           = {10},
    booktitle       = {2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
    pages           = {93--96},
    doi             = {https://doi.org/10.1109/ISMAR-Adjunct.2018.00042},
    venue           = {ISMAR},
    abstract        = {We designed a within-subject experiment to compare visual discomfort to preteen users caused by using head-mounted displays (HMD) and tablet computers for an hour. 18 participants younger than 13 years old were recruited to fulfill a series of similar painting tasks under both display conditions. Visual fatigue was measured with visual analog scale before and after experiment and during the break of experiment. The results indicated that HMD had a trend to bring higher visual fatigue than tablet computer during the exposure of 1 hour. Although the symptoms of visual discomfort disappeared after resting, there is need for preteen-specific head-mounted displays.}
}
@inproceedings{engeln2018immersive,
    title           = {Immersive VisualAudioDesign: Spectral Editing in VR},
    author          = {Lars Engeln, Natalie Hube, Rainer Groh},
    year            = {2018},
    month           = {09},
    booktitle       = {Proceedings of the Audio Mostly 2018 on Sound in Immersion and Emotion},
    location        = {Wrexham, United Kingdom},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {AM'18},
    doi             = {https://doi.org/10.1145/3243274.3243279},
    isbn            = {9781450366090},
    abstract        = {VisualAudioDesign (VAD) is an attempt to design audio in a visual way. The frequency-domain visualized as a spectrogram construed as pixel data can be manipulated with image filters. Thereby, an approach is described to get away from direct DSP parameter manipulation to a more comprehensible sound design. Virtual Reality (VR) offers immersive insights into data and embodied interaction in the virtual environment. VAD and VR combined enrich spectral editing with a natural work-flow. Therefore, a design paper prototype for interaction with audio data in an virtual environment was used and examined.},
    articleno       = {38},
    numpages        = {4},
    keywords        = {Immersive Analytics, VisualAudioDesign, Virtual Reality, Paper Prototype, Spectral Editing, Immersive Audio},
    venue           = {Audio Mostly}
}
@article{bradley2018enabling,
    title           = {Enabling Detailed, Biophysics-Based Skeletal Muscle Models on HPC Systems},
    author          = {Chris P. Bradley, Nehzat Emamy, Thomas Ertl, Dominik Göddeke, Andreas Hessenthaler, Thomas Klotz, Aaron Krämer, Michael Krone, Benjamin Maier, Miriam Mehl, Tobias Rau, Oliver Röhrle},
    year            = {2018},
    month           = {07},
    journal         = {Frontiers in Physiology},
    volume          = {9},
    doi             = {https://doi.org/10.3389/fphys.2018.00816},
    issn            = {1664-042X},
    url             = {https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2018.00816},
    abstract        = {Realistic simulations of detailed, biophysics-based, multi-scale models often require very high resolution and, thus, large-scale compute facilities. Existing simulation environments, especially for biomedical applications, are typically designed to allow for high flexibility and generality in model development. Flexibility and model development, however, are often a limiting factor for large-scale simulations. Therefore, new models are typically tested and run on small-scale compute facilities. By using a detailed biophysics-based, chemo-electromechanical skeletal muscle model and the international open-source software library OpenCMISS as an example, we present an approach to upgrade an existing muscle simulation framework from a moderately parallel version toward a massively parallel one that scales both in terms of problem size and in terms of the number of parallel processes. For this purpose, we investigate different modeling, algorithmic and implementational aspects. We present improvements addressing both numerical and parallel scalability. In addition, our approach includes a novel visualization environment which is based on the MegaMol framework and is capable of handling large amounts of simulated data. We present the results of a number of scaling studies at the Tier-1 supercomputer HazelHen at the High Performance Computing Center Stuttgart (HLRS). We improve the overall runtime by a factor of up to 2.6 and achieve good scalability on up to 768 cores.},
    pdf             = {https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2018.00816/pdf},
    venue           = {Frontiers in Physiology}
}
@inproceedings{hube2018towards,
    title           = {Towards augmented reality in quality assurance processes},
    author          = {Natalie Hube, Mathias Müller, Jan Wojdziak, Franziska Hannß, Rainer Groh},
    year            = {2018},
    month           = {06},
    booktitle       = {Proceedings of the 10th International Workshop on Immersive Mixed and Virtual Environment Systems},
    location        = {Amsterdam, Netherlands},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {MMVE '18},
    pages           = {16–21},
    doi             = {https://doi.org/10.1145/3210438.3210442},
    isbn            = {9781450357715},
    abstract        = {Augmented reality (AR) has gained exceptional importance in supporting task performance. Particularly, in quality assurance (QA) processes in the automotive sector AR offers a diversity of use cases. In this paper we propose an interface design which projects information as a digital canvas on the surface of vehicle components. Based on a requirement analysis, we discuss design aspects and describe our application in applying the quality assurance process of a luxury automaker. The application includes a personal view on spatial information embedded in a guided interaction process as a design solution that can be applied to enhance QA processes.},
    numpages        = {6},
    keywords        = {Hand-held Devices, Augmented Reality, Design Decisions, Concept and Implementation},
    venue           = {MMSys}
}
@inproceedings{ballte2018hilda,
    title           = {Evaluating Visual Data Analysis Systems: A Discussion Report},
    author          = {Leilani Battle, Marco Angelini, Carsten Binnig, Tiziana Catarci, Philipp Eichmann, Jean-Daniel Fekete, Giuseppe Santucci, Michael Sedlmair, Wesley Willett},
    year            = {2018},
    month           = {06},
    booktitle       = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
    location        = {Houston, TX, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {HILDA'18},
    doi             = {https://doi.org/10.1145/3209900.3209901},
    isbn            = {9781450358279},
    abstract        = {Visual data analysis is a key tool for helping people to make sense of and interact with massive data sets. However, existing evaluation methods (e.g., database benchmarks, individual user studies) fail to capture the key points that make systems for visual data analysis (or visual data systems) challenging to design. In November 2017, members of both the Database and Visualization communities came together in a Dagstuhl seminar to discuss the grand challenges in the intersection of data analysis and interactive visualization. In this paper, we report on the discussions of the working group on the evaluation of visual data systems, which addressed questions centered around developing better evaluation methods, such as 'How do the different communities evaluate visual data systems?' and 'What we could learn from each other to develop evaluation techniques that cut across areas?'. In their discussions, the group brainstormed initial steps towards new joint evaluation methods and developed a first concrete initiative - a trace repository of various real-world workloads and visual data systems - that enables researchers to derive evaluation setups (e.g., performance benchmarks, user studies) under more realistic assumptions, and enables new evaluation perspectives (e.g., broader meta analysis across analysis contexts, reproducibility and comparability across systems).},
    articleno       = {4},
    numpages        = {6},
    venue           = {HILDA}
}
@inproceedings{bernard2018eurovis_short,
    title           = {Learning from the Best – Visual Analysis of a Quasi-Optimal Data Labeling Strategy},
    author          = {Jürgen Bernard, Marco Hutter, Markus Lehmann, Martin Müller, Matthias Zeppelzauer, Michael Sedlmair},
    year            = {2018},
    month           = {06},
    booktitle       = {Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short Papers},
    publisher       = {Eurographics Association},
    series          = {EuroVis '18},
    pages           = {95–99},
    doi             = {https://dl.acm.org/doi/abs/10.5555/3290776.3290797},
    abstract        = {An overarching goal of active learning strategies is to reduce the human effort when labeling datasets and training machine learning methods. In this work, we focus on the analysis of a (theoretical) quasi-optimal, ground-truth-based strategy for labeling instances, which we refer to as the upper limit of performance (ULoP). Our long-term goal is to improve existing active learning strategies and to narrow the gap between current strategies and the outstanding performance of ULoP. In an observational study conducted on five datasets, we leverage visualization methods to better understand how and why ULoP selects instances. Results show that the strategy of ULoP is not constant (as in most state-of-the-art active learning strategies) but changes within the labeling process. We identify three phases that are common to most observed labeling processes, partitioning the labeling process into (1) a Discovery Phase, (2) a Consolidation Phase, and (3) a Fine Tuning Phase.},
    numpages        = {5},
    pdf             = {https://www.vis.uni-stuttgart.de/documentcenter/staff/sedlmaml/papers/bernard2018eurovis_short_suppl.pdf},
    venue           = {EuroVis}
}
@inproceedings{torsneyweir2018eurovis_short,
    title           = {Risk Fixers and Sweet Spotters: A Study of the Different Approaches to Using Visual Sensitivity Analysis in an Investment Scenario},
    author          = {Thomas Torsney-Weir, Shahrzad Afroozeh, Michael Sedlmair, and Torsten Möller},
    year            = {2018},
    month           = {06},
    booktitle       = {EuroVis 2018 - Short Papers},
    publisher       = {The Eurographics Association},
    doi             = {https://dl.acm.org/doi/abs/10.5555/3290776.3290801},
    url             = {http://eprints.cs.univie.ac.at/5649/},
    abstract        = {We present an empirical study that illustrates how individual users' decision making preferences and biases influence visualization design choices. Twenty-three participants, in a lab study, were shown two interactive financial portfolio optimization interfaces which allowed them to adjust the return for the portfolio and view how the risk changes. One interface showed the sensitivity of the risk to changes in the return and one did not have this feature. Our study highlights two classes of users. One which preferred the interface with the sensitivity feature and one group that does not prefer the sensitivity feature. We named these two groups the 'risk fixers' and the 'sweet spotters' due to the analysis method they used. The 'risk fixers' selected a level of risk which they were comfortable with while the 'sweet spotters' tried to find a point right before the risk increased greatly. Our study shows that exposing the sensitivity of investment parameters will impact the investment decision process and increase confidence for these 'sweet spotters.' We also discuss the implications for design.},
    venue           = {EuroVis}
}
@inproceedings{bejan2018a,
    title           = {A Virtual Environment Gesture Interaction System for People with Dementia},
    author          = {Alexander Bejan, Markus Wieland, Patrizia Murko, Christophe Kunze},
    year            = {2018},
    month           = {05},
    booktitle       = {Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems},
    publisher       = {ACM},
    series          = {DIS '18 Companion},
    pages           = {225–230},
    doi             = {https://doi.org/10.1145/3197391.3205440},
    isbn            = {9781450356312},
    abstract        = {As dementia will most likely become an impactful challenge for our future society, it is imperative to maintain the well-being of the diverse group of people with dementia (PwD). Thus, appropriate interventions that effectively trigger identity-stabilizing memories, and at the same time encourage sensorimotor activities, have to be designed and implemented. To that end, we present a novel natural user interface (NUI) system combined with a reminiscence-provoking virtual 3D environment (VE). With it, PwD can delve into memories while interacting with the VE over dementia-fitted gestures. The results of the preliminary evaluations are promising, as they show that most PwD get immersed and cheerfully engage in gesture interactions after a short settling-in period.},
    numpages        = {6},
    keywords        = {reminiscence therapy, joyful, dementia, natural user interfaces, virtual environment, fun moments, memory triggering, gesture interaction, virtual reality},
    venue           = {DIS}
}
@inproceedings{hube2018facilitating,
    title           = {Facilitating exploration on exhibitions with augmented reality},
    author          = {Natalie Hube, Mathias Müller, Rainer Groh},
    year            = {2018},
    month           = {05},
    booktitle       = {Proceedings of the 2018 International Conference on Advanced Visual Interfaces},
    location        = {Castiglione della Pescaia, Grosseto, Italy},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {AVI '18},
    doi             = {https://doi.org/10.1145/3206505.3206585},
    isbn            = {9781450356169},
    abstract        = {At exhibitions, visitors are usually in a completely unknown environment. Although visitors generally are informed about the topic before a visit, interests are still difficult to extract from the mass of exhibition stands and offers. In this paper we describe a concept using head-coupled AR together with recommender mechanisms for exhibitions. We present a conceptual development for a first prototype with focus on navigational aspects as well as explicit and implicit recommendations to generate input data for visually displayed recommendations.},
    articleno       = {64},
    numpages        = {3},
    keywords        = {information visualization, human computer interaction, augmented reality, recommender systems},
    venue           = {AVI}
}
@misc{hube2018the,
    title           = {The Data in Your Hands: Exploring Novel Interaction Techniques and Data Visualization Approaches for Immersive Data Analytics},
    author          = {Natalie Hube, Mathias Müller},
    year            = {2018},
    month           = {05},
    abstract        = {In this paper, we describe a concept for visualization and interaction with a large data set in an virtual environment. The core idea uses the traditional flat 2D representation as a base visualization but lets the user transform it into a spatial 3D visualizations on demand. Our visualization and interaction concept targets data analysts to use it for exploration and analysis, utilizing virtual reality to gain insight into complex data sets. The concept is based on the use of Parallel Sets for the representation of categorical data. By extending the conventional 2D Parallel Sets with a third dimension, correlations between path variables and the related number of items belonging to a specific node can be visualized. Furthermore, the concept uses virtual reality controllers in combination with a head-mounted display to control additional views. The purpose of the paper is to describe the core concepts and challenges for this type of spatial visualization and the related interaction design, including the use of gestures for direct manuipulation and a hand-attached menu for complex actions},
    pdf             = {http://ceur-ws.org/Vol-2108/paper2.pdf},
    venue           = {AVI}
}
@inproceedings{cutura2018viscoder,
    title           = {VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms},
    author          = {Rene Cutura, Stefan Holzer, Michaël Aupetit, Michael Sedlmair},
    year            = {2018},
    month           = {04},
    booktitle       = {Euro. Symp. on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)},
    pages           = {641--646},
    video           = {https://www.youtube.com/embed/gg2pgv0xwmc?si=wZRxwbdyRWz6ElPc},
    pdf             = {https://www.esann.org/sites/default/files/proceedings/legacy/es2018-74.pdf},
    venue           = {ESANN},
    abstract        = {We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows qualitatively comparing several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms.}
}
@inproceedings{mayer2018pac-many,
    title           = {Pac-Many: Movement Behavior when Playing Collaborative and Competitive Games on Large Displays},
    author          = {Sven Mayer, Lars Lischke, Jens Emil Grønbæk, Zhanna Sarsenbayeva, Jonas Vogelsang, Paweł W. Woźniak, Niels Henze, Giulio Jacucci},
    year            = {2018},
    month           = {04},
    booktitle       = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
    location        = {Montreal QC, Canada},
    publisher       = {ACM},
    address         = {New York, NY, USA},
    series          = {CHI '18},
    pages           = {1–10},
    doi             = {https://doi.org/10.1145/3173574.3174113},
    isbn            = {9781450356206},
    abstract        = {Previous work has shown that large high resolution displays (LHRDs) can enhance collaboration between users. As LHRDs allow free movement in front of the screen, an understanding of movement behavior is required to build successful interfaces for these devices. This paper presents Pac-Many; a multiplayer version of the classical computer game Pac-Man to study group dynamics when using LHRDs. We utilized smartphones as game controllers to enable free movement while playing the game. In a lab study, using a 4m × 1m LHRD, 24 participants (12 pairs) played Pac-Many in collaborative and competitive conditions. The results show that players in the collaborative condition divided screen space evenly. In contrast, competing players stood closer together to avoid benefits for the other player. We discuss how the nature of the task is important when designing and analyzing collaborative interfaces for LHRDs. Our work shows how to account for the spatial aspects of interaction with LHRDs to build immersive experiences.},
    numpages        = {10},
    keywords        = {large high resolution displays, gaming, co-located, multiplayer, large tiled display, collaborative},
    video           = {https://www.youtube.com/embed/rRGdP6JV0Ug?si=mSO1sVWkNW8Qj21M},
    suppl           = {https://dl.acm.org/doi/abs/10.1145/3173574.3174113},
    venue           = {CHI}
}
@article{rudkowsky2018cmm,
    title           = {More than Bags of Words: Sentiment Analysis with Word Embeddings},
    author          = {Elena Rudkowsky, Martin Haselmayer, Matthias Wastian, Marcelo Jenny, Stefan Emrich, Michael Sedlmair},
    year            = {2018},
    month           = {04},
    journal         = {Communication Methods and Measures},
    publisher       = {Routledge},
    volume          = {12},
    number          = {2-3},
    pages           = {140--157},
    doi             = {https://doi.org/10.1080/19312458.2018.1455817},
    venue           = {CMM},
    abstract        = {Moving beyond the dominant bag-of-words approach to sentiment analysis we introduce an alternative procedure based on distributed word embeddings. The strength of word embeddings is the ability to capture similarities in word meaning. We use word embeddings as part of a supervised machine learning procedure which estimates levels of negativity in parliamentary speeches. The procedure’s accuracy is evaluated with crowdcoded training sentences; its external validity through a study of patterns of negativity in Austrian parliamentary speeches. The results show the potential of the word embeddings approach for sentiment analysis in the social sciences.}
}
@article{bernard2018vial,
    title           = {VIAL – A Unified Process for Visual-Interactive Labeling},
    author          = {Jürgen Bernard, Matthias Zeppelzauer, Michael Sedlmair, Wolfgang Aigner},
    year            = {2018},
    month           = {03},
    journal         = {The Visual Computer},
    publisher       = {Springer},
    volume          = {34},
    number          = {9},
    pages           = {1189--1207},
    doi             = {https://doi.org/10.1007/s00371-018-1500-3},
    venue           = {EuroVA},
    abstract        = {The assignment of labels to data instances is a fundamental prerequisite for many machine learning tasks. Moreover, labeling is a frequently applied process in visual interactive analysis approaches and visual analytics. However, the strategies for creating labels usually differ between these two fields. This raises the question whether synergies between the different approaches can be attained. In this paper, we study the process of labeling data instances with the user in the loop, from both the machine learning and visual interactive perspective. Based on a review of differences and commonalities, we propose the “visual interactive labeling” (VIAL) process that unifies both approaches. We describe the six major steps of the process and discuss their specific challenges. Additionally, we present two heterogeneous usage scenarios from the novel VIAL perspective, one on metric distance learning and one on object detection in videos. Finally, we discuss general challenges to VIAL and point out necessary work for the realization of future VIAL approaches.}
}
@misc{aigner2018valid,
    title           = {Data Journalism - Guidelines and Best Practices for Getting Started},
    author          = {Wolfgang Aigner, Eva Goldgruber, Florian Grassinger, Robert Gutounig, Alexander Rind, Michael Sedlmair, Christina Stoiber},
    year            = {2018},
    month           = {01},
    url             = {http://www.validproject.at},
    abstract        = {This document represents a practical summary from experiences and results gained during the research project “VALiD - Visual Analytics in Data-Driven Journalism”. It addresses some of the major issues around data journalism practice. A large part is taken from a review of the research literature review on this topic. You can find the references for this review and links to other project-related resources at the end of this document. This document addresses journalists and communicators who have little to no experience in the field of data-intensive newswork.},
    suppl           = {https://github.com/VALIDproject/ddj-booklet},
    venue           = {Booklet, FFG VALiD (project no. 845598)}
}
@article{oppermann2017bikesharingatlas,
    title           = {Bike Sharing Atlas: Visual Analysis of Bike-Sharing Networks},
    author          = {Michael Oppermann, Torsten Möller, Michael Sedlmair},
    year            = {2018},
    month           = {01},
    journal         = {International Journal of Transportation},
    issn            = {2207-6433},
    url             = {http://eprints.cs.univie.ac.at/5855/},
    venue           = {IJT},
    abstract        = {In this paper, we introduce an interactive visualization system, bikesharingatlas.org, that supports the explorative data analysis of more than 468 bike-sharing networks worldwide. The system leverages a multi-coordinated view approach and innovative interaction techniques can help, for instance, to expose capacity bottlenecks, commuting patterns, and other network characteristics. Our broader goal is to illustrate how visual analysis can be used for exploring distributed, heterogeneous data from smart cities. Based on our collaboration with different target users, we present usage scenarios that show the potential of our approach to understanding bike-sharing and urban commuting behaviors.}
}
@article{sacha2017b,
    title           = {What You See Is What You Can Change: Human-Centered Machine Learning By Interactive Visualization},
    author          = {Dominik Sacha, Michael Sedlmair, Leishi Zhang, John A Lee, Jaakko Peltonen, Daniel Weiskopf, Stephen C North, Daniel A Keim},
    year            = {2017},
    month           = {12},
    journal         = {Neurocomputing},
    volume          = {268},
    pages           = {164--175},
    doi             = {https://doi.org/10.1016/j.neucom.2017.01.105},
    issn            = {0925-2312},
    url             = {https://www.sciencedirect.com/science/article/pii/S0925231217307609},
    note            = {Advances in artificial neural networks, machine learning and computational intelligence},
    keywords        = {Machine learning, Information visualization, Interaction, Visual analytics},
    venue           = {Neurocomputing},
    abstract        = {Visual analytics (VA) systems help data analysts solve complex problems interactively, by integrating automated data analysis and mining, such as machine learning (ML) based methods, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and that puts the central relationship between automated algorithms and interactive visualizations into sharp focus. The framework is illustrated with several examples and we further elaborate on the interactive ML process by identifying key scenarios where ML methods are combined with human feedback through interactive visualization. We derive five open research challenges at the intersection of ML and visualization research, whose solution should lead to more effective data analysis.}
}
@inproceedings{angerbauer2017valuetools,
    title           = {The Back End is Only One Part of the Picture: Mobile-Aware Application Performance Monitoring and Problem Diagnosis},
    author          = {Katrin Angerbauer, Dušan Okanović,  André van Hoorn, Christoph Heger},
    year            = {2017},
    month           = {12},
    booktitle       = {Proceedings of the 11th EAI International Conference on Performance Evaluation Methodologies and Tools},
    location        = {Venice, Italy},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {VALUETOOLS 2017},
    pages           = {82–89},
    doi             = {https://doi.org/10.1145/3150928.3150939},
    isbn            = {9781450363464},
    abstract        = {The success of modern businesses relies on the quality of their supporting application systems. Continuous application performance management is mandatory to enable efficient problem detection, diagnosis, and resolution during production. In today's age of ubiquitous computing, large fractions of users access application systems from mobile devices, such as phones and tablets. For detecting, diagnosing, and resolving performance and availability problems, an end-to-end view, i.e., traceability of requests starting on the (mobile) clients' devices, is becoming increasingly important. In this paper, we propose an approach for end-to-end monitoring of applications from the users' mobile devices to the back end, and diagnosing root-causes of detected performance problems. We extend our previous work on diagnosing performance anti-patterns from execution traces by new metrics and rules. The evaluation of this work shows that our approach successfully detects and diagnoses performance anti-patterns in applications with iOS-based mobile clients. While there are threats to validity to our experiment, our research is a promising starting point for future work.},
    numpages        = {8},
    keywords        = {performance anti-patterns, application performance monitoring, iOS},
    venue           = {VALUETOOLS}
}
@inproceedings{calero-valdez2017framework,
    title           = {A Framework for Studying Biases in Visualization Research},
    author          = {André Calero Valdez, Martina Ziefle, Michael Sedlmair},
    year            = {2017},
    month           = {10},
    booktitle       = {DECISIVe 2017},
    url             = {http://eprints.cs.univie.ac.at/5258/},
    venue           = {DECISIVe},
    abstract        = {In this position paper, we propose and discuss a lightweight framework to help organize research questions that arise around biases in visualization and visual analysis. We contrast our framework against cognitive bias codex by Buster Benson. The framework is inspired by Norman’s Human Action Cycle [23] and classifies biases into three levels: perceptual biases, action biases, and social biases. For each of the levels of cognitive processing, we discuss examples of biases from the cognitive science literature, and speculate how they might also be important to the area of visualization. In addition, we put forward a methodological discussion on how biases might be studied on all three levels, and which pitfalls and threats to validity exist. We hope that the framework will help spark new ideas and discussions on how to proceed studying the important topic of biases in visualization.}
}
@inproceedings{dingler2017text,
    title           = {Text Priming-Effects of Text Visualizations on Readers Prior to Reading},
    author          = {Tilman Dingler, Dagmar Kern, Katrin Angerbauer, Albrecht Schmidt},
    year            = {2017},
    month           = {09},
    booktitle       = {Human-Computer Interaction -- INTERACT 2017},
    publisher       = {Springer International Publishing},
    address         = {Cham},
    pages           = {345--365},
    doi             = {https://doi.org/10.1007/978-3-319-67687-6_23},
    isbn            = {978-3-319-67687-6},
    editor          = {Bernhaupt, Regina and Dalvi, Girish and Joshi, Anirudha and K. Balkrishan, Devanuj and O'Neill, Jacki and Winckler, Marco},
    abstract        = {Living in our information society poses the challenge of having to deal with a plethora of information. While most content is represented through text, keyword extraction and visualization techniques allow the processing and adjustment of text presentation to the readers’ individual requirements and preferences. In this paper, we investigate four types of text visualizations and their feasibility to give readers an overview before they actually engage with a text: word clouds, highlighting, mind maps, and image collages. In a user study with 50 participants, we assessed the effects of such visualizations on reading comprehension, reading time, and subjective impressions. Results show that (1) mind maps best support readers in getting the gist of a text, (2) they also give better subjective impressions on text content and structure, and (3) highlighting keywords in a text before reading helps to reduce reading time. We discuss a set of guidelines to inform the design of automated systems for creating text visualizations for reader support.},
    pdf             = {https://hal.inria.fr/hal-01717225/document},
    venue           = {INTERACT}
}
@article{calero-valdez2017priming,
    title           = {Priming and Anchoring Effects in Visualization},
    author          = {André Calero Valdez, Martina Ziefle, Michael Sedlmair},
    year            = {2017},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {24},
    number          = {1},
    pages           = {584--594},
    doi             = {https://doi.org/10.1109/TVCG.2017.2744138},
    venue           = {TVCG},
    abstract        = {We investigate priming and anchoring effects on perceptual tasks in visualization. Priming or anchoring effects depict the phenomena that a stimulus might influence subsequent human judgments on a perceptual level, or on a cognitive level by providing a frame of reference. Using visual class separability in scatterplots as an example task, we performed a set of five studies to investigate the potential existence of priming and anchoring effects. Our findings show that - under certain circumstances - such effects indeed exist. In other words, humans judge class separability of the same scatterplot differently depending on the scatterplot(s) they have seen before. These findings inform future work on better understanding and more accurately modeling human perception of visual patterns.}
}
@article{bernard2017labeling,
    title           = {Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study},
    author          = {Jürgen Bernard, Marco Hutter, Matthias Zeppelzauer, Dieter Fellner, Michael Sedlmair},
    year            = {2017},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {24},
    number          = {1},
    pages           = {298--308},
    doi             = {https://doi.org/10.1109/TVCG.2017.2744818},
    venue           = {TVCG},
    abstract        = {Labeling data instances is an important task in machine learning and visual analytics. Both fields provide a broad set of labeling strategies, whereby machine learning (and in particular active learning) follows a rather model-centered approach and visual analytics employs rather user-centered approaches (visual-interactive labeling). Both approaches have individual strengths and weaknesses. In this work, we conduct an experiment with three parts to assess and compare the performance of these different labeling strategies. In our study, we (1) identify different visual labeling strategies for user-centered labeling, (2) investigate strengths and weaknesses of labeling strategies for different labeling tasks and task complexities, and (3) shed light on the effect of using different visual encodings to guide the visual-interactive labeling process. We further compare labeling of single versus multiple instances at a time, and quantify the impact on efficiency. We systematically compare the performance of visual interactive labeling with that of active learning. Our main findings are that visual-interactive labeling can outperform active learning, given the condition that dimension reduction separates well the class distributions. Moreover, using dimension reduction in combination with additional visual encodings that expose the internal state of the learning model turns out to improve the performance of visual-interactive labeling.}
}
@article{wang2017edwordle,
    title           = {EdWordle: Consistency-preserving Word Cloud Editing},
    author          = {Yunhai Wang, Xiaowei Chu, Chen Bao, Lifeng Zhu, Oliver Deussen, Baoquan Chen, Michael Sedlmair},
    year            = {2017},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {24},
    number          = {1},
    pages           = {647--656},
    doi             = {https://doi.org/10.1109/TVCG.2017.2745859},
    venue           = {TVCG},
    abstract        = {We present EdWordle, a method for consistently editing word clouds. At its heart, EdWordle allows users to move and edit words while preserving the neighborhoods of other words. To do so, we combine a constrained rigid body simulation with a neighborhood-aware local Wordle algorithm to update the cloud and to create very compact layouts. The consistent and stable behavior of EdWordle enables users to create new forms of word clouds such as storytelling clouds in which the position of words is carefully edited. We compare our approach with state-of-the-art methods and show that we can improve user performance, user satisfaction, as well as the layout itself.}
}
@article{wang2017graph,
    title           = {Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization},
    author          = {Yunhai Wang, Yanyan Wang,  Yinqi Sun, Lifeng Zhu, Kecheng Lu, Chi-Wing Fu, Michael Sedlmair, Oliver Deussen, Baoquan Chen},
    year            = {2017},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {24},
    number          = {1},
    pages           = {489--499},
    doi             = {https://doi.org/10.1109/TVCG.2017.2745919},
    venue           = {TVCG},
    abstract        = {We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes - an approach which previous methods cannot support.}
}
@inproceedings{müller2017a,
    title           = {A zoomable product browser for elastic displays},
    author          = {Mathias Müller, Mandy Keck, Thomas Gründer, Natalie Hube, Rainer Groh},
    year            = {2017},
    month           = {07},
    booktitle       = {Proceedings xCoAx 2017},
    publisher       = {5th Conference on Computation, Communication, Aesthetics & X},
    address         = {Lisbon, Portugal},
    pages           = {10},
    abstract        = {In this paper, we present an interaction and visualization concept for elastic displays. The interaction concept was inspired by the search process of a rummage table to explore a large set of product data. The basic approach uses a similarity-based search pattern—based on a small set of items, the user refines the search result by examining similar items and exchanging them with items from the current result. A physically-based approach is used to interact with the data by deforming the surface of the elastic display. The presented visualization concept uses glyphs to directly compare items at a glance. Zoomable UI techniques controlled by the deformation of the elastic surface allow to display different levels of detail for each item.},
    keywords        = {Glyphs, Interface Design},
    pdf             = {http://2017.xcoax.org/pdf/xcoax2017-Muller.pdf},
    venue           = {xCoAX}
}
@inproceedings{bernard2017a,
    title           = {Combining Cluster and Outlier Analysis with Visual Analytics},
    author          = {Jürgen Bernard, Eduard Dobermann, Michael Sedlmair, Dieter Fellner},
    year            = {2017},
    month           = {06},
    booktitle       = {Proceedings of the EuroVis Workshop on Visual Analytics},
    location        = {Barcelona, Spain},
    publisher       = {Eurographics Association},
    address         = {Goslar, DEU},
    series          = {EuroVA '17},
    pages           = {19–23},
    doi             = {https://doi.org/10.2312/eurova.20171114},
    abstract        = {Cluster and outlier analysis are two important tasks. Due to their nature these tasks seem to be opposed to each other, i.e., data objects either belong to a cluster structure or a sparsely populated outlier region. In this work, we present a visual analytics tool that allows the combined analysis of clusters and outliers. Users can add multiple clustering and outlier analysis algorithms, compare results visually, and combine the algorithms’ results. The usefulness of the combined analysis is demonstrated using the example of labeling unknown data sets. The usage scenario also shows that identified clusters and outliers can share joint areas of the data space.},
    numpages        = {5},
    venue           = {EuroVA}
}
@inproceedings{bernard2017b,
    title           = {A Unified Process for Visual-Interactive Labeling},
    author          = {Jürgen Bernard, Matthias Zeppelzauer, Michael Sedlmair, Wolfgang Aigner},
    year            = {2017},
    month           = {06},
    booktitle       = {Proceedings of the EuroVis Workshop on Visual Analytics},
    location        = {Barcelona, Spain},
    publisher       = {Eurographics Association},
    address         = {Goslar, DEU},
    series          = {EuroVA '17},
    pages           = {73–77},
    doi             = {https://doi.org/10.2312/eurova.20171123},
    abstract        = {Assigning labels to data instances is a prerequisite for many machine learning tasks. Similarly, labeling is applied in visual-interactive analysis approaches. However, the strategies for creating labels often differ in the two fields. In this paper, we study the process of labeling data instances with the user in the loop, from both the machine learning and visual-interactive perspective. Based on a review of differences and commonalities, we propose the 'Visual-Interactive Labeling' (VIAL) process, conflating the strengths of both. We describe the six major steps of the process and highlight their related challenges.},
    numpages        = {5},
    venue           = {EuroVA}
}
@inproceedings{hube2017additional,
    title           = {Additional On-Demand Dimension for Data Visualization},
    author          = {Natalie Hube, Mathias Müller, Rainer Groh},
    year            = {2017},
    month           = {06},
    booktitle       = {EuroVis 2017 - Short Papers},
    publisher       = {The Eurographics Association},
    doi             = {https://doi.org/10.2312/eurovisshort.20171151},
    isbn            = {978-3-03868-043-7},
    editor          = {Barbora Kozlikova and Tobias Schreck and Thomas Wischgoll},
    pdf             = {https://diglib.eg.org/bitstream/handle/10.2312/eurovisshort20171151/163-167.pdf},
    venue           = {EuroVis},
    abstract        = {In this paper, we present a concept to interactively extend an 2d visualization by an additional on-demand dimension. We use categorical data in a multidimensional information space applied in a travel search scenario. Parallel sets are used as the basis for the visualization concept, since this is particularly suitable for the visualization of categorical data. The on-demand dimension expands the vertical axis of a parallel coordinate graph into depth axis and is intended to increase comparability of path variables with respect to the number of elements belonging to the respective parameter axis instead of direct comparability of individual paths and keep relations between the parallel sets. The presented implementation suits as foundation for further studies about the usefulness of a dynamic, on demand extension a of 2d visualizations into spatial visualizations. Furthermore, we present some additional approaches about the usage of the increased visualization space.}
}
@inproceedings{ngo2017visual,
    title           = {Visual Analytics of Global Parameters in Simulation Ensembles of ODE-based Excitable Network Dynamics},
    author          = {Quynh Quang Ngo, Marc-Thorsten Hütt, Lars Linsen},
    year            = {2017},
    month           = {06},
    booktitle       = {19th Eurographics Conference on Visualization, EuroVis 2017 - Posters, Barcelona, Spain, June 12-16, 2017},
    publisher       = {Eurographics Association},
    pages           = {101--103},
    doi             = {https://doi.org/10.2312/eurp.20171179},
    editor          = {Anna Puig and Tobias Isenberg},
    venue           = {EuroVis},
    abstract        = {The role of network topology on the dynamics in simulations that are executed on the network is a central question in the field of network science. However, the influence of the topology is affected by the global dynamical simulation parameters. To investigate this impact of the parameter settings, multiple simulation runs are executed with different settings. Moreover, since the outcome of a single simulation run also depends on the randomly chosen start configurations, multiple runs with the same settings are carried out, as well. We present a visual approach to analyze the role of topology in such an ensemble of simulation ensembles. We use the dynamics of an excitable network implemented in the form of a coupled ordinary differential equation (ODE) following the FitzHugh-Nagumo (FHN) model and modular network topologies.}
}
@article{torsneyweir2017sliceplorer,
    title           = {Sliceplorer: 1D Slices for Multi-dimensional Continuous Functions},
    author          = {Thomas Torsney-Weir, Michael Sedlmair, Torsten Möller},
    year            = {2017},
    month           = {06},
    journal         = {Comput. Graph. Forum},
    publisher       = {The Eurographs Association &amp; John Wiley &amp; Sons, Ltd.},
    address         = {Chichester, GBR},
    volume          = {36},
    number          = {3},
    pages           = {167–177},
    doi             = {https://doi.org/10.1111/cgf.13177},
    issn            = {0167-7055},
    abstract        = {Multi-dimensional continuous functions are commonly visualized with 2D slices or topological views. Here, we explore 1D slices as an alternative approach to show such functions. Our goal with 1D slices is to combine the benefits of topological views, that is, screen space efficiency, with those of slices, that is a close resemblance of the underlying function. We compare 1D slices to 2D slices and topological views, first, by looking at their performance with respect to common function analysis tasks. We also demonstrate 3 usage scenarios: the 2D sinc function, neural network regression, and optimization traces. Based on this evaluation, we characterize the advantages and drawbacks of each of these approaches, and show how interaction can be used to overcome some of the shortcomings.},
    numpages        = {11},
    keywords        = {Categories and Subject Descriptors according to ACM CCS, I.3.3 [Computer Graphics]: Picture/Image Generation-Line and curve generation},
    video           = {https://www.youtube.com/embed/VSHadt-jB-s?si=EpMsxv3rJiPBd-zB},
    suppl           = {http://sliceplorer.cs.univie.ac.at/evaluation/index.html},
    venue           = {CGF}
}
@misc{rudkowsy2017sentiment,
    title           = {Supervised Sentiment Analysis of Parliamentary Speeches and News Reports},
    author          = {Elena Rudkowsky, Martin Haselmayer, Matthias Wastian, Marcelo Jenny, Stefan Emrich, Michael Sedlmair},
    year            = {2017},
    month           = {05},
    venue           = {ICA},
    abstract        = {In this paper, we use several supervised machine learning approaches and compare their success in predicting the sentiment of Austrian parliamentary speeches and news reports (German language). Prediction results in learning- based sentiment analysis vary strongly. They depend on the choice of algorithm and its parameterization, the quality and quantity of available training data as well as the selection of appropriate input feature representations. Our training data contains human-annotated sentiment scores at the phrase and sentence level. Going beyond the dominant bag-of-words modeling approach in traditional natural language processing, we also test sentiment analysis for neural network-based distributed representations of words. The latter reflect syntactic as well as semantic relatedness, but require huge amounts of training examples. We test both approaches with heterogeneous textual data, compare their success rates and provide conclusions on how to improve the sentiment analysis of political communication.}
}
@article{rau2017a,
    title           = {A dsDNA model optimized for electrokinetic applications},
    author          = {Tobias Rau, Florian Weik, Christian Holm},
    year            = {2017},
    month           = {05},
    journal         = {Soft Matter},
    publisher       = {Royal Society of Chemistry},
    volume          = {13},
    number          = {21},
    pages           = {3918--3926},
    doi             = {https://doi.org/10.1039/C7SM00270J},
    pdf             = {https://pubs.rsc.org/en/content/articlepdf/2017/sm/c7sm00270j},
    venue           = {Soft Matter},
    abstract        = {We present a coarse-grained (CG) model of a charged double-stranded DNA immersed in an electrolyte solution that can be used for a variety of electrokinetic applications. The model is based on an earlier rigid and immobile model of Weik et al. and includes now semi-flexibility and mobility, so that DNA dynamics can be sufficiently captured to simulate a full nanopore translocation process. To this end we couple the DNA hydrodynamically via a raspberry approach to a lattice-Boltzmann fluid and parametrize the counterions with a distant dependent friction. The electrokinetic properties of the CG DNA model inside an infinite cylinder is fitted against experimental data from Smeets et al. and all-atom simulation data from Kesselheim et al. The stiffness of our CG DNA is modeled via a harmonic angle potential fitted against experimental data of Brunet et al. Finally, the quality of our tuned parameters is tested by measuring the electrophoretic mobility of our DNA model for various numbers of base pairs and salt concentrations. Our results compare excellently with the experimental data sets of Stellwagen et al. and Hoagland et al.}
}
@article{wang2017tvcg,
    title           = {A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization},
    author          = {Yunhai Wang, Kang Feng, Xiaowei Chu, Jian Zhang, Chi-Wing Fu, Michael Sedlmair, Xiaohui Yu, Baoquan Chen},
    year            = {2017},
    month           = {05},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {24},
    number          = {5},
    pages           = {1828--1840},
    doi             = {https://doi.org/10.1109/TVCG.2017.2701829},
    venue           = {TVCG},
    abstract        = {Dimensionality reduction (DR) is a common strategy for visual analysis of labeled high-dimensional data. Low-dimensional representations of the data help, for instance, to explore the class separability and the spatial distribution of the data. Widely-used unsupervised DR methods like PCA do not aim to maximize the class separation, while supervised DR methods like LDA often assume certain spatial distributions and do not take perceptual capabilities of humans into account. These issues make them ineffective for complicated class structures. Towards filling this gap, we present a perception-driven linear dimensionality reduction approach that maximizes the perceived class separation in projections. Our approach builds on recent developments in perception-based separation measures that have achieved good results in imitating human perception. We extend these measures to be density-aware and incorporate them into a customized simulated annealing algorithm, which can rapidly generate a near optimal DR projection. We demonstrate the effectiveness of our approach by comparing it to state-of-the-art DR methods on 93 datasets, using both quantitative measure and human judgments. We also provide case studies with class-imbalanced and unlabeled data.}
}
@inproceedings{jenny2017incivility,
    title           = {Incivility in Austrian parliamentary debates: A supervised sentiment analysis of parliamentary speeches},
    author          = {Marcelo Jenny, Martin Haselmayer, Elena Rudkowsky, Matthias Wastian, Stefan Emrich, Michael Sedlmair},
    year            = {2017},
    month           = {04},
    booktitle       = {European Consortium for Political Research Joint Workshops, Nottingham, UK},
    url             = {https://ecpr.eu/Events/Event/PaperDetails/34083},
    venue           = {ECPR},
    abstract        = {Incivility of political communication has become a major topic in public and scientific discourse (e.g. Herbst 2010; Berry and Sobieraj 2013), and it is often seen as a cause of increasing political polarization, lower electoral turnout and voter disaffection with politics and democracy in general (Jamieson 1992; Kahn and Kenny 1999; Mutz and Reeves 2005, Mutz 2007; Brooks and Geer 2007; Lau and Rovner 2009; Harcourt 2012). However, there is no agreement on the definition or measurement of incivility. Our paper presents an automated sentiment analysis to identify uncivil language and to measure the level of (in)civility in parliamentary speeches. Substantively, we study incivility in the Austrian national parliament during the last two decades (1996-2013) and explore some of the political, institutional and individual factors that affect the level of incivility shown in parliamentary debates. We check whether government/opposition status, the parliamentary role, the type of debate and closeness to the next election has an effect on the level of civility observed in parliament.}
}
@inproceedings{krone2017from,
    title           = {From Visualization Research to Public Presentation - Design and Realization of a Scientific Exhibition},
    author          = {Michael Krone, Karsten Schatz, Nora Hieronymus, Christoph Müller, Michael Becher, Tina Barthelmes, April Cooper, Steffen Currle, Patrick Gralka, Marcel Hlawatsch, Lisa Pietrzyk, Tobias Rau, Guido Reina, Rene Trefft, Thomas Ertl},
    year            = {2017},
    month           = {01},
    booktitle       = {Proceedings of SIGRAD 2017},
    url             = {https://ep.liu.se/en/conference-article.aspx?series=ecp&issue=143&Article_No=3},
    venue           = {SIGRAD},
    abstract        = {In this paper, we present the design considerations of a scientific exhibition we recently realized. The exhibition presented the work of two large research projects related to computer simulations, which include scientific visualization as an essential part of the involved research. Consequently, visualization was also of central importance for our exhibition. It was not only used to illustrate the complex simulation data to convey information about the results from the application domains, but we also wanted to teach visitors about visualization itself. Therefore, explaining the purpose and the challenges of visualization research was a significant part of the exhibition. We describe how we developed an engaging experience of a highly theoretic topic using the same visualization tools we developed for the application scientists and how we integrated the venue into our design. Finally, we discuss our insights from the project as well as visitor feedback.}
}
@inproceedings{rau2017challenges,
    title           = {Challenges and Opportunities using Software-defined Visualization in MegaMol},
    author          = {Tobias Rau, Michael Krone, Guido Reina, Thomas Ertl},
    year            = {2017},
    month           = {01},
    booktitle       = {7th Workshop on Visual Analytics, Information Visualization and Scientific Visualization},
    pdf             = {https://www.ixpug.org/images/docs/IXPUG_Annual_Spring_Conference_2018/intel_ixpug_spring_2018_sdvis_megamol.pdf},
    venue           = {IXPUG},
    abstract        = {In this paper we describe how we integrated the OSPRay ray tracing engine into the traditionally GPU-centric MegaMol visualization framework. Since OSPRay is purely CPU-based, this adds software-defined visualization to MegaMol. This enables us to use MegaMol for in-situ rendering on HPC systems that lack GPUs. Furthermore, we designed the integration so that the new OSPRay rendering can be used alongside the classical OpenGL-based rendering. We describe how the ray tracing paradigm, where the whole scene has to be available during rendering, changes the module graph of MegaMol. The performance of the OSPRay ray tracing is shown to be at least competitive with classical GPU-accelerated rendering methods for particle rendering available in MegaMol.}
}
@inproceedings{motschnig2016fie,
    title           = {A Team-Approach to Putting Learner-Centered Principles to Practice in a Large Course on Human-Computer Interaction},
    author          = {Renate Motschnig, Michael Sedlmair, Svenja Schröder, Torsten Möller},
    year            = {2016},
    month           = {12},
    booktitle       = {2016 IEEE Frontiers in Education Conference (FIE)},
    pages           = {1--9},
    doi             = {https://doi.org/10.1109/FIE.2016.7757576},
    venue           = {FIE},
    abstract        = {We present a case study on how a team of instructors put learner-centered principles into practice in a large undergraduate course on Human-Computer Interaction (HCI) that was run in 4 parallel groups of about 50 students. The course stands on the crossroads between software engineering, business, and research in so far as student-teams apply human-centered design techniques to develop mobile apps, test them with real end-users, read research papers and regularly reflect upon their experience. As a proof of the course-concept, selected results from formative and summative assessments are presented. The summative results show that students rated the course as one of the best of the 87 computer science courses run in the summer term of 2015 at the University of Vienna. The primary goal of this paper is to provide instructors intrigued by learner-centered approaches with ideas for their own practice. In particular, this paper is of interest to those who teach Human-Computer Interaction and to those who seek inspiration on mapping their course to the 14 learner-centered principles.}
}
@inproceedings{sacha2016esann,
    title           = {Human-Centered Machine Learning Through Interactive Visualization: Review and Open Challenges},
    author          = {Dominik Sacha, Michael Sedlmair, Leishi Zhang, John Lee, Daniel Weiskopf, Stephen North, Daniel A Keim},
    year            = {2016},
    month           = {10},
    booktitle       = {European Symp. on Artificial Neural Networks},
    publisher       = {6doc.com publ.},
    series          = {ESANN},
    pages           = {641--646},
    pdf             = {https://www.esann.org/sites/default/files/proceedings/legacy/es2016-166.pdf},
    venue           = {ESANN},
    abstract        = {The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.}
}
@inproceedings{sedlmair2016beliv,
    title           = {Design Study Contributions Come in Different Guises: Seven Guiding Scenarios},
    author          = {Michael Sedlmair},
    year            = {2016},
    month           = {10},
    booktitle       = {Proceedings of the Sixth Workshop on Beyond Time and Errors on Novel Evaluation Methods for Visualization},
    location        = {Baltimore, MD, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {BELIV '16},
    pages           = {152–161},
    doi             = {https://doi.org/10.1145/2993901.2993913},
    isbn            = {9781450348188},
    abstract        = {Design studies are projects in which visualization researchers seek to design visualization tools that help solving challenging real-world problems faced by domain experts. While design studies have become a vital component of visualization research, reflecting on actionable contributions from them often poses challenges. The goal of this paper is to better characterize different contributions that can result from design study projects. Towards this goal, a set of seven guiding scenarios for characterizing design study contributions is proposed. The scenarios are meant to help authors identify and depict design study contributions that are interesting and actionable for other visualization researchers. They are also meant to provide better guidance in evaluating design study contributions in the reviewing process.},
    numpages        = {10},
    keywords        = {visualization, contribution, position paper, Design study},
    venue           = {VIS}
}
@article{isenberg2017tvcg,
    title           = {vispubdata.org: A Metadata Collection about IEEE Visualization (VIS) Publications},
    author          = {Petra Isenberg, Florian Heimerl, Steffen Koch, Tobias Isenberg, Panpan Xu, Chad Stolper, Michael Sedlmair, Jian Chen, Torsten Möller, John Stasko},
    year            = {2016},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {23},
    number          = {9},
    pages           = {2199--2206},
    doi             = {https://doi.org/10.1109/TVCG.2016.2615308},
    suppl           = {https://vispubdata.org},
    venue           = {TVCG},
    abstract        = {We have created and made available to all a dataset with information about every paper that has appeared at the IEEE Visualization (VIS) set of conferences: InfoVis, SciVis, VAST, and Vis. The information about each paper includes its title, abstract, authors, and citations to other papers in the conference series, among many other attributes. This article describes the motivation for creating the dataset, as well as our process of coalescing and cleaning the data, and a set of three visualizations we created to facilitate exploration of the data. This data is meant to be useful to the broad data visualization community to help understand the evolution of the field and as an example document collection for text data visualization research.}
}
@inproceedings{yu2016reduce,
    title           = {Reduce Simulator Sickness by Overwritten Symbol in Smartphone-Based VR System},
    author          = {Xingyao Yu, Dongdong Weng, Li Cai},
    year            = {2016},
    month           = {09},
    booktitle       = {2016 International Conference on Virtual Reality and Visualization (ICVRV)},
    pages           = {426--429},
    doi             = {https://doi.org/10.1109/ICVRV.2016.78},
    pdf             = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7938233},
    venue           = {IEEE ICVRV},
    abstract        = {The aim of this paper is to reduce simulator sickness caused by the low refresh rate of display in smartphone-based VR system. Without regard to the improvement of hardware, the method proposed in this paper reduces simulator sickness by adding static symbol on the screen of the smartphone. A series of user-participation experiments were done to validate the effectiveness of the method. Participants' responses to the symbol with different textures (cross or Minion logo) and in different positions (the center or near the corners) were assessed by Simulator Sickness Questionnaire (SSQ). The preliminary results demonstrate that the existence, the position and complexity of the symbols can be factors in relieving symptoms of simulator sickness.}
}
@article{isenberg2016tvcg,
    title           = {Visualization as Seen Through its Research Paper Keywords},
    author          = {Petra Isenberg, Tobias Isenberg, Michael Sedlmair, Jian Chen, Torsten Möller},
    year            = {2016},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {23},
    number          = {1},
    pages           = {771--780},
    doi             = {https://doi.org/10.1109/TVCG.2016.2598827},
    suppl           = {http://tobias.isenberg.cc/uploads/VideosAndDemos/Isenberg_2017_VST_additional.zip},
    venue           = {TVCG},
    abstract        = {We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.}
}
@article{sacha2016vast,
    title           = {Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis},
    author          = {Dominik Sacha, Leishi Zhang, Michael Sedlmair, John Aldo Lee, Jaakko Peltonen, Daniel Weiskopf, Stephen North, Daniel A Keim},
    year            = {2016},
    month           = {08},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {23},
    number          = {1},
    pages           = {241--250},
    doi             = {https://doi.org/10.1109/TVCG.2016.2598495},
    venue           = {TVCG},
    abstract        = {Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop” process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.}
}
@inproceedings{hube2016virtual,
    title           = {Virtual UNREALity: Exploring Alternative Visualization Techniques for Virtual Reality},
    author          = {Natalie Hube, Hannes Grusla, Mathias Müller, Ingmar S. Franke, Tobias Günther, Rainer Groh},
    year            = {2016},
    month           = {07},
    booktitle       = {Proceedings xCoAx},
    series          = {xCoAX},
    url             = {http://2016.xcoax.org/pdf/xcoax2016-Hube.pdf},
    abstract        = {Virtual Reality (VR) offers new ways to perceive and interact with virtual content. Apart from photo-realism, VR can be used to explore new ways of visualization and interaction. In this contribution, we describe two student projects, which focused on creating innovative concepts for an artistic VR experience. We provide a review of sources of inspiration ranging from standard NPR-techniques through movies, interactive artworks and games to phenomena of human perception. Based on this wide collection of material we describe the prototypes, and discuss observations during implementation and from user feedback. Finally, possible future directions to use the potential of VR as a tool for novel, artful and unconventional experiences are discussed.},
    pdf             = {http://2016.xcoax.org/pdf/xcoax2016-Hube.pdf},
    venue           = {xCoAX}
}
@article{ngo2016visual,
    title           = {Visual Analysis of Governing Topological Structures in Excitable Network Dynamics},
    author          = {Quynh Quang Ngo, Marc-Thorsten Hütt, Lars Linsen},
    year            = {2016},
    month           = {07},
    journal         = {Comput. Graph. Forum},
    volume          = {35},
    number          = {3},
    pages           = {301--310},
    doi             = {https://doi.org/10.1111/cgf.12906},
    pdf             = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12906},
    venue           = {CGF},
    abstract        = {To understand how topology shapes the dynamics in excitable networks is one of the fundamental problems in network science when applied to computational systems biology and neuroscience. Recent advances in the field discovered the influential role of two macroscopic topological structures, namely hubs and modules. We propose a visual analytics approach that allows for a systematic exploration of the role of those macroscopic topological structures on the dynamics in excitable networks. Dynamical patterns are discovered using the dynamical features of excitation ratio and co-activation. Our approach is based on the interactive analysis of the correlation of topological and dynamical features using coordinated views. We designed suitable visual encodings for both the topological and the dynamical features. A degree map and an adjacency matrix visualization allow for the interaction with hubs and modules, respectively. A barycentric-coordinates layout and a multi-dimensional scaling approach allow for the analysis of excitation ratio and co-activation, respectively. We demonstrate how the interplay of the visual encodings allows us to quickly reconstruct recent findings in the field within an interactive analysis and even discovered new patterns. We apply our approach to network models of commonly investigated topologies as well as to the structural networks representing the connectomes of different species. We evaluate our approach with domain experts in terms of its intuitiveness, expressiveness, and usefulness.}
}
@inproceedings{aupetit2016sepme,
    title           = {SepMe: 2002 New Visual Separation Measures},
    author          = {Michael Aupetit, Michael Sedlmair},
    year            = {2016},
    month           = {05},
    booktitle       = {2016 IEEE Pacific Visualization Symposium (PacificVis)},
    pages           = {1--8},
    doi             = {https://doi.org/10.1109/PACIFICVIS.2016.7465244},
    venue           = {PacificVis},
    abstract        = {Our goal is to accurately model human class separation judgements in color-coded scatterplots. Towards this goal, we propose a set of 2002 visual separation measures, by systematically combining 17 neighborhood graphs and 14 class purity functions, with different parameterizations. Using a Machine Learning framework, we evaluate these measures based on how well they predict human separation judgements. We found that more than 58% of the 2002 new measures outperform the best state-of-the-art Distance Consistency (DSC) measure. Among the 2002, the best measure is the average proportion of same-class neighbors among the 0.35-Observable Neighbors of each point of the target class (short GONG 0.35 DIR CPT), with a prediction accuracy of 92.9%, which is 11.7% better than DSC. We also discuss alternative, well-performing measures and give guidelines when to use which.}
}
@article{hund2016brain,
    title           = {Visual Analytics for Concept Exploration in Subspaces of Patient Groups: Making Sense of Complex Datasets with the Doctor-in-the-Loop},
    author          = {Michael Hund, Dominic Böhm, Werner Sturm, Michael Sedlmair, Tobias Schreck, Torsten Ullrich, Daniel A. Keim, Ljiljana Majnaric, Andreas Holzinger},
    year            = {2016},
    month           = {03},
    journal         = {Brain Informatics},
    publisher       = {SpringerOpen},
    volume          = {3},
    number          = {4},
    pages           = {233--247},
    doi             = {https://doi.org/10.1007/s40708-016-0043-5},
    venue           = {Brain Informatics},
    abstract        = {Medical doctors and researchers in bio-medicine are increasingly confronted with complex patient data, posing new and difficult analysis challenges. These data are often comprising high-dimensional descriptions of patient conditions and measurements on the success of certain therapies. An important analysis question in such data is to compare and correlate patient conditions and therapy results along with combinations of dimensions. As the number of dimensions is often very large, one needs to map them to a smaller number of relevant dimensions to be more amenable for expert analysis. This is because irrelevant, redundant, and conflicting dimensions can negatively affect effectiveness and efficiency of the analytic process (the so-called curse of dimensionality). However, the possible mappings from high- to low-dimensional spaces are ambiguous. For example, the similarity between patients may change by considering different combinations of relevant dimensions (subspaces). We demonstrate the potential of subspace analysis for the interpretation of high-dimensional medical data. Specifically, we present SubVIS, an interactive tool to visually explore subspace clusters from different perspectives, introduce a novel analysis workflow, and discuss future directions for high-dimensional (medical) data analysis and its visual exploration. We apply the presented workflow to a real-world dataset from the medical domain and show its usefulness with a domain expert evaluation.}
}
@inproceedings{kamalzadeh2016tagflip,
    title           = {TagFlip: Active Mobile Music Discovery with Social Tags},
    author          = {Mohsen Kamalzadeh, Christoph Kralj, Torsten Möller, Michael Sedlmair},
    year            = {2016},
    month           = {03},
    booktitle       = {Proceedings of the 21st International Conference on Intelligent User Interfaces},
    location        = {Sonoma, California, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {IUI '16},
    pages           = {19–30},
    doi             = {https://doi.org/10.1145/2856767.2856780},
    isbn            = {9781450341370},
    abstract        = {We report on the design and evaluation of TagFlip, a novel interface for active music discovery based on social tags of music. The tool, which was built for phone-sized screens, couples high user control on the recommended music with minimal interaction effort. Contrary to conventional recommenders, which only allow the specification of seed attributes and the subsequent like/dislike of songs, we put the users in the centre of the recommendation process. With a library of 100,000 songs, TagFlip describes each played song to the user through its most popular tags on Last.fm and allows the user to easily specify which of the tags should be considered for the next song, or the next stream of songs. In a lab user study where we compared it to Spotify's mobile application, TagFlip came out on top in both subjective user experience (control, transparency, and trust) and our objective measure of number of interactions per liked song. Our users found TagFlip to be an important complementary experience to that of Spotify, enabling more active and directed discovery sessions as opposed to the mostly passive experience that traditional recommenders offer.},
    numpages        = {12},
    keywords        = {transparency, folksonomies, music discovery, fine tuning, social tags, minimal effort, user controlled, user-centred design, recommendation, user interface, exploration},
    venue           = {IUI}
}
@inproceedings{niederer2016ffh,
    title           = {Visual Exploration of Media Transparency for Data Journalists: Problem Characterization and Abstraction},
    author          = {Christina Niederer, Alexander Rind, Wolfgang Aigner, Julian Ausserhofer, Robert Gutounig, Michael Sedlmair},
    year            = {2016},
    month           = {01},
    booktitle       = {Forschungsforum der österreichischen Fachhochschulen},
    pdf             = {http://ffhoarep.fh-ooe.at/bitstream/123456789/542/1/109_305_Niederer_FullPaper_en_Final.pdf},
    venue           = {FFH},
    abstract        = {Today, journalists increasingly deal with complex, large, and heterogeneous datasets and, thus, face challenges in integration, wrangling, analysis, and reporting these data. Besides, the lack of money, time, and skills influence their journalistic work. Information visualization and visual analytics offer possibilities to support data journalists. This paper contributes to an overview of a possible characterization and abstraction of certain aspects of data-driven journalism in Austria. A case study was conducted based on the dataset of media transparency in Austria. We conducted four semi- structured interviews with Austrian data journalists, as well as an exploratory data analysis of the media transparency dataset. To categorize our findings we used Munzner ́s analytical framework and the Data-User-Task Design Triangle by Miksch and Aigner.}
}
@inproceedings{torsneyweir2015decision,
    title           = {Decision Making in Uncertainty Visualization},
    author          = {Thomas Torsney-Weir, Michael Sedlmair, Torsten Möller},
    year            = {2015},
    month           = {10},
    booktitle       = {VDMU Workshop on Visualization for Decision Making under Uncertainty 2015},
    url             = {http://eprints.cs.univie.ac.at/4598/},
    abstract        = {In this position paper we investigate the role of decision making in uncertainty visualization. We introduce common decision making strategies identified by the cognitive science community [22]. These strategies are then used to reanalyze 21 design study papers that have previously been used as a foundation for defining visual parameter space analysis [26]. We found that current strategies in these tools relied mostly on one parameter at a time and are about filtering alternatives. Based on these results, we propose three questions for further discussion and research.},
    venue           = {VDMU}
}
@inproceedings{hund2015snns,
    title           = {Subspace Nearest Neighbor Search - Problem Statement, Approaches, and Discussion},
    author          = {Michael Hund, Michael Behrisch, Ines Färber, Michael Sedlmair, Tobias Schreck, Thomas Seidl, Daniel A Keim},
    year            = {2015},
    month           = {10},
    booktitle       = {Similarity Search and Applications},
    publisher       = {Springer International Publishing},
    address         = {Cham},
    pages           = {307--313},
    doi             = {https://doi.org/10.1007/978-3-319-25087-8_29},
    isbn            = {978-3-319-25087-8},
    editor          = {Amato, Giuseppe and Connor, Richard and Falchi, Fabrizio and Gennaro, Claudio},
    abstract        = {Computing the similarity between objects is a central task for many applications in the field of information retrieval and data mining. For finding k-nearest neighbors, typically a ranking is computed based on a predetermined set of data dimensions and a distance function, constant over all possible queries. However, many high-dimensional feature spaces contain a large number of dimensions, many of which may contain noise, irrelevant, redundant, or contradicting information. More specifically, the relevance of dimensions may depend on the query object itself, and in general, different dimension sets (subspaces) may be appropriate for a query. Approaches for feature selection or -weighting typically provide a global subspace selection, which may not be suitable for all possibly queries. In this position paper, we frame a new research problem, called subspace nearest neighbor search, aiming at multiple query-dependent subspaces for nearest neighbor search. We describe relevant problem characteristics, relate to existing approaches, and outline potential research directions.},
    venue           = {SISAP}
}
@article{sedlmair2015ddeval,
    title           = {Data-driven Evaluation of Visual Quality Measures},
    author          = {Michael Sedlmair, Michael Aupetit},
    year            = {2015},
    month           = {07},
    journal         = {Computer Graphics Forum},
    volume          = {34},
    number          = {3},
    pages           = {201--210},
    doi             = {https://doi.org/10.1111/cgf.12632},
    keywords        = {Categories and Subject Descriptors (according to ACM CCS), H.5.0 Information Interfaces and Presentation: General},
    eprint          = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12632},
    abstract        = {Visual quality measures seek to algorithmically imitate human judgments of patterns such as class separability, correlation, or outliers. In this paper, we propose a novel data-driven framework for evaluating such measures. The basic idea is to take a large set of visually encoded data, such as scatterplots, with reliable human “ground truth” judgements, and to use this human-labeled data to learn how well a measure would predict human judgements on previously unseen data. Measures can then be evaluated based on predictive performance—an approach that is crucial for generalizing across datasets but has gained little attention so far. To illustrate our framework, we use it to evaluate 15 state-of-the-art class separation measures, using human ground truth data from 828 class separation judgments on color-coded 2D scatterplots.},
    venue           = {CGF}
}
@inproceedings{simon2015liaison,
    title           = {Bridging the Gap of Domain and Visualization Experts with a Liaison},
    author          = {Svenja Simon, Sebastian Mittelstädt, Daniel A Keim, Michael Sedlmair},
    year            = {2015},
    month           = {05},
    booktitle       = {Eurographics Conference on Visualization (EuroVis) - Short Papers},
    publisher       = {The Eurographics Association},
    volume          = {2015},
    doi             = {https://doi.org/10.2312/eurovisshort.20151137},
    url             = {http://eprints.cs.univie.ac.at/4550/},
    abstract        = {We introduce the role Liaison for design study projects. With considerable expertise in visualization and the application domain, a Liaison can help to foster richer and more effective interdisciplinary communication in problem characterization, design, and evaluation processes. We characterize this role, provide a list of tasks of Liaison and visualization experts, and discuss concrete benefits and potential limitations based on our experience from multiple design studies. To illustrate our contributions we use as an example a molecular biology design study.},
    venue           = {EuroVis}
}
@inproceedings{angerbauer2015chi,
    title           = {Utilizing the Effects of Priming to Facilitate Text Comprehension},
    author          = {Katrin Angerbauer, Tilman Dingler, Dagmar Kern, Albrecht Schmidt},
    year            = {2015},
    month           = {04},
    booktitle       = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
    location        = {Seoul, Republic of Korea},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA,doi = 10.1145/2702613.2732914},
    series          = {CHI EA '15},
    pages           = {1043–1048},
    doi             = {https://doi.org/10.1145/2702613.2732914},
    isbn            = {9781450331463},
    abstract        = {Due to the ever-growing amount of textual information we face in our everyday life, the skill of scanning and absorbing the essence of a piece of text is crucial. We cannot afford to read every text in detail, hence we need to acquire strategies to quickly decide on the importance of a text and how to grasp its content. Additionally, the sheer amount of daily reading makes it hard to remember the gist of every text encountered. Research in psychology has proposed priming as an implicit memory effect where exposure to one stimulus influences the response to a subsequent stimulus. Hence, exposure to contextual information can influence comprehension and recall. In our work we investigate the feasibility of using such an effect to visually present text summaries that are quick to understand and deliver the essence of a text in order to help readers not only make informed decisions about whether to read the text or not, but also to build out more cognitive associations that help to remember the content of the text afterward. In two focus groups we discussed our approach by providing four different visualizations representing the gist and important details of the text. In this paper we introduce the visualizations as well as results of the focus groups.},
    numpages        = {6},
    keywords        = {comprehension, reading interfaces, priming},
    venue           = {CHI}
}
@inproceedings{brehmer2014drtasks,
    title           = {Visualizing Dimensionally-Reduced Data: Interviews with Analysts and a Characterization of Task Sequences},
    author          = {Matthew Brehmer, Michael Sedlmair, Stephen Ingram, Tamara Munzner},
    year            = {2014},
    month           = {11},
    booktitle       = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization},
    location        = {Paris, France},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {BELIV '14},
    pages           = {1–8},
    doi             = {https://doi.org/10.1145/2669557.2669559},
    isbn            = {9781450332095},
    abstract        = {We characterize five task sequences related to visualizing dimensionally-reduced data, drawing from data collected from interviews with ten data analysts spanning six application domains, and from our understanding of the technique literature. Our characterization of visualization task sequences for dimensionally-reduced data fills a gap created by the abundance of proposed techniques and tools that combine high-dimensional data analysis, dimensionality reduction, and visualization, and is intended to be used in the design and evaluation of future techniques and tools. We discuss implications for the evaluation of existing work practices, for the design of controlled experiments, and for the analysis of post-deployment field observations.},
    numpages        = {8},
    keywords        = {tasks, dimensionally-reduced data, interview study},
    venue           = {CHI BELIV}
}
@article{muhlbacher2014tui,
    title           = {Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations},
    author          = {Thomas Mühlbacher, Harald Piringer, Samuel Gratzl, Michael Sedlmair, Marc Streit},
    year            = {2014},
    month           = {11},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {20},
    number          = {12},
    pages           = {1643--1652},
    doi             = {https://doi.org/10.1109/TVCG.2014.2346578},
    venue           = {TVCG},
    abstract        = {An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.}
}
@article{sedlmair2014toi,
    title           = {Visual Parameter Space Analysis: A Conceptual Framework},
    author          = {Michael Sedlmair, Christoph Heinzl, Stefan Bruckner, Harald Piringer, Torsten Möller},
    year            = {2014},
    month           = {11},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {20},
    number          = {12},
    pages           = {2161--2170},
    doi             = {https://doi.org/10.1109/TVCG.2014.2346321},
    venue           = {TVCG},
    abstract        = {Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.}
}
@article{isenberg2014keyvis-tr,
    title           = {Toward a Deeper Understanding of Visualization Through Keyword Analysis},
    author          = {Petra Isenberg, Tobias Isenberg, Michael Sedlmair, Jian Chen, Torsten Möller},
    year            = {2014},
    month           = {08},
    journal         = {CoRR},
    volume          = {abs/1408.3297},
    doi             = {https://doi.org/10.48550/arXiv.1408.3297},
    url             = {http://arxiv.org/abs/1408.3297},
    eprinttype      = {arXiv},
    eprint          = {1408.3297},
    venue           = {arXiv},
    abstract        = {We present the results of a comprehensive analysis of visualization paper keywords supplied for 4366 papers submitted to five main visualization conferences. We describe main keywords, topic areas, and 10-year historic trends from two datasets: (1) the standardized PCS taxonomy keywords in use for paper submissions for IEEE InfoVis, IEEE Vis-SciVis, IEEE VAST, EuroVis, and IEEE PacificVis since 2009 and (2) the author-chosen keywords for papers published in the IEEE Visualization conference series (now called IEEE VIS) since 2004. Our analysis of research topics in visualization can serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an application that allows visualization researchers to easily browse the 2600+ keywords used for IEEE VIS papers during the past 10 years, aiming at more informed and, hence, more effective keyword selections for future visualization publications.}
}
@article{meyer2013nbgm,
    title           = {The Nested Blocks and Guidelines Model},
    author          = {Miriah Meyer, Michael Sedlmair, P Samuel Quinan, Tamara Munzner},
    year            = {2013},
    month           = {12},
    journal         = {Information Visualization},
    publisher       = {SAGE Publications Sage UK: London, England},
    volume          = {14},
    number          = {3},
    pages           = {234--249},
    doi             = {https://doi.org/10.1177%2F1473871613510429},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2013/NBGM/},
    venue           = {Information Visualization},
    abstract        = {We propose the nested blocks and guidelines model for the design and validation of visualization systems. The nested blocks and guidelines model extends the previously proposed four-level nested model by adding finer grained structure within each level, providing explicit mechanisms to capture and discuss design decision rationale. Blocks are the outcomes of the design process at a specific level, and guidelines discuss relationships between these blocks. Blocks at the algorithm and technique levels describe design choices, as do data blocks at the abstraction level, whereas task abstraction blocks and domain situation blocks are identified as the outcome of the designer’s understanding of the requirements. In the nested blocks and guidelines model, there are two types of guidelines: within-level guidelines provide comparisons for blocks within the same level, while between-level guidelines provide mappings between adjacent levels of design. We analyze several recent articles using the nested blocks and guidelines model to provide concrete examples of how a researcher can use blocks and guidelines to describe and evaluate visualization research. We also discuss the nested blocks and guidelines model with respect to other design models to clarify its role in visualization design. Using the nested blocks and guidelines model, we pinpoint two implications for visualization evaluation. First, comparison of blocks at the domain level must occur implicitly downstream at the abstraction level; second, comparison between blocks must take into account both upstream assumptions and downstream requirements. Finally, we use the model to analyze two open problems: the need for mid-level task taxonomies to fill in the task blocks at the abstraction level and the need for more guidelines mapping between the algorithm and technique levels.}
}
@article{sedlmair2013infovis,
    title           = {Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices},
    author          = {Michael Sedlmair, Tamara Munzner, Melanie Tory},
    year            = {2013},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {19},
    number          = {12},
    pages           = {2634--2643},
    doi             = {https://doi.org/10.1109/TVCG.2013.153},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2013/ScatterplotEval/},
    venue           = {TVCG},
    abstract        = {To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.}
}
@article{isenberg2013srp,
    title           = {A Systematic Review on the Practice of Evaluating Visualization},
    author          = {Tobias Isenberg, Petra Isenberg, Jian Chen, Michael Sedlmair, Torsten Möller},
    year            = {2013},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {19},
    number          = {12},
    pages           = {2818--2827},
    doi             = {https://doi.org/10.1109/TVCG.2013.126},
    suppl           = {http://tobias.isenberg.cc/VideosAndDemos/Isenberg2013SRP},
    venue           = {TVCG},
    abstract        = {We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.}
}
@article{bergner2013tvcg,
    title           = {ParaGlide: Interactive Parameter Space Partitioning for Computer Simulations},
    author          = {Steven Bergner, Michael Sedlmair, Torsten Möller, Sareh Nabi Abdolyousefi, Ahmed Saad},
    year            = {2013},
    month           = {03},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {19},
    number          = {9},
    pages           = {1499--1512},
    doi             = {https://doi.org/10.1109/TVCG.2013.61},
    venue           = {TVCG},
    abstract        = {In this paper, we introduce ParaGlide, a visualization system designed for interactive exploration of parameter spaces of multidimensional simulation models. To get the right parameter configuration, model developers frequently have to go back and forth between setting input parameters and qualitatively judging the outcomes of their model. Current state-of-the-art tools and practices, however, fail to provide a systematic way of exploring these parameter spaces, making informed decisions about parameter configurations a tedious and workload-intensive task. ParaGlide endeavors to overcome this shortcoming by guiding data generation using a region-based user interface for parameter sampling and then dividing the model's input parameter space into partitions that represent distinct output behavior. In particular, we found that parameter space partitioning can help model developers to better understand qualitative differences among possibly high-dimensional model outputs. Further, it provides information on parameter sensitivity and facilitates comparison of models. We developed ParaGlide in close collaboration with experts from three different domains, who all were involved in developing new models for their domain. We first analyzed current practices of six domain experts and derived a set of tasks and design requirements, then engaged in a user-centered design process, and finally conducted three longitudinal in-depth case studies underlining the usefulness of our approach.}
}
@inproceedings{meyer2012beliv,
    title           = {The Four-Level Nested Model Revisited: Blocks and Guidelines},
    author          = {Miriah Meyer, Michael Sedlmair, Tamara Munzner},
    year            = {2012},
    month           = {10},
    booktitle       = {Proceedings of the 2012 BELIV Workshop: Beyond Time and Errors - Novel Evaluation Methods for Visualization},
    location        = {Seattle, Washington, USA},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {BELIV '12},
    doi             = {https://doi.org/10.1145/2442576.2442587},
    isbn            = {9781450317917},
    abstract        = {We propose an extension to the four-level nested model of design and validation of visualization system that defines the term 'guidelines' in terms of blocks at each level. Blocks are the outcomes of the design process at a specific level, and guidelines discuss relationships between these blocks. Within-level guidelines provide comparisons for blocks within the same level, while between-level guidelines provide mappings between adjacent levels of design. These guidelines help a designer choose which abstractions, techniques, and algorithms are reasonable to combine when building a visualization system. This definition of guideline allows analysis of how the validation efforts in different kinds of papers typically lead to different kinds of guidelines. Analysis through the lens of blocks and guidelines also led us to identify four major needs: a definition of the meaning of block at the problem level; mid-level task taxonomies to fill in the blocks at the abstraction level; refinement of the model itself at the abstraction level; and a more complete set of mappings up from the algorithm level to the technique level. These gaps in visualization knowledge present rich opportunities for future work.},
    articleno       = {11},
    numpages        = {6},
    keywords        = {visualization, design studies, nested model, validation},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2012/NestedModelExt/},
    venue           = {CHI BELIV}
}
@article{sedlmair2012infovis-1,
    title           = {Design Study Methodology: Reflections from the Trenches and the Stacks},
    author          = {Michael Sedlmair, Miriah Meyer, Tamara Munzner},
    year            = {2012},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {18},
    number          = {12},
    pages           = {2431--2440},
    doi             = {https://doi.org/10.1109/TVCG.2012.213},
    note            = {Received an honorable mention award},
    badge           = {honorablemention},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2012/dsm/},
    venue           = {TVCG},
    abstract        = {Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.}
}
@article{sedlmair2012infovis-2,
    title           = {RelEx: Visualization for Actively Changing Overlay Network Specifications},
    author          = {Michael Sedlmair, Annika Frank, Tamara Munzner, Andreas Butz},
    year            = {2012},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {18},
    number          = {12},
    pages           = {2729--2738},
    doi             = {https://doi.org/10.1109/TVCG.2012.255},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2012/RelEx/},
    venue           = {TVCG},
    abstract        = {We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.}
}
@article{sedlmair2012tr,
    title           = {Dimensionality Reduction in the Wild: Gaps and Guidance},
    author          = {Michael Sedlmair, Matt Brehmer, Stephen Ingram, Tamara Munzner},
    year            = {2012},
    month           = {06},
    journal         = {Dept. Comput. Sci., Univ. British Columbia, Vancouver, BC, Canada, Tech. Rep. TR-2012-03},
    url             = {https://www.cs.ubc.ca/tr/2012/tr-2012-03},
    venue           = {UBC Computer Science Technical Report TR-2012-03},
    abstract        = {Despite an abundance of technical literature on dimension reduction (DR), our understanding of how real data analysts are using DR techniques and what problems they face remains largely incomplete. In this paper, we contribute the first systematic and broad analysis of DR usage by a sample of real data analysts, along with their needs and problems. We present the results of a two-year qualitative research endeavor, in which we iteratively collected and analyzed a rich corpus of data in the spirit of grounded theory. We interviewed 24 data analysts from different domains and surveyed papers depicting applications of DR. The result is a descriptive taxonomy of DR usage, and concrete real-world usage examples summarized in terms of this taxonomy. We also identify seven gaps where user DR needs are unfulfilled by currently available techniques, and three mismatches where the users do not need offered techniques. At the heart of our taxonomy is a task classification that differentiates between abstract tasks related to point clusters and those related to dimensions. The taxonomy and usage examples are intended to provide a better descriptive understanding of real data analysts practices and needs with regards to DR. The gaps are intended as prescriptive pointers to future research directions, with the most important gaps being a lack of support for users without expertise in the mathematics of DR, and an absence of DR techniques for comparing explicit groups of dimensions or for relating non-linear embeddings to original dimensions.}
}
@article{sedlmair2012eurovis,
    title           = {A Taxonomy of Visual Cluster Separation Factors},
    author          = {Michael Sedlmair, Andrada Tatu, Tamara Munzner, Melanie Tory},
    year            = {2012},
    month           = {06},
    journal         = {Computer Graphics Forum},
    volume          = {31},
    number          = {3pt4},
    pages           = {1335--1344},
    doi             = {https://doi.org/10.1111/j.1467-8659.2012.03125.x},
    keywords        = {H.5.0 Information Interfaces and Presentation: General, J.0 Computer Applications: General},
    eprint          = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2012.03125.x},
    abstract        = {We provide two contributions, a taxonomy of visual cluster separation factors in scatterplots, and an in-depth qualitative evaluation of two recently proposed and validated separation measures. We initially intended to use these measures to provide guidance for the use of dimension reduction (DR) techniques and visual encoding (VE) choices, but found that they failed to produce reliable results. To understand why, we conducted a systematic qualitative data study covering a broad collection of 75 real and synthetic high-dimensional datasets, four DR techniques, and three scatterplot-based visual encodings. Two authors visually inspected over 800 plots to determine whether or not the measures created plausible results. We found that they failed in over half the cases overall, and in over two-thirds of the cases involving real datasets. Using open and axial coding of failure reasons and separability characteristics, we generated a taxonomy of visual cluster separability factors. We iteratively refined its explanatory clarity and power by mapping the studied datasets and success and failure ranges of the measures onto the factor axes. Our taxonomy has four categories, ordered by their ability to influence successors: Scale, Point Distance, Shape, and Position. Each category is split into Within-Cluster factors such as density, curvature, isotropy, and clumpiness, and Between-Cluster factors that arise from the variance of these properties, culminating in the overarching factor of class separation. The resulting taxonomy can be used to guide the design and the evaluation of cluster separation measures.},
    suppl           = {http://www.cs.ubc.ca/labs/imager/tr/2012/VisClusterSep/},
    venue           = {CGF}
}
@misc{sedlmair2011auto,
    title           = {Visualisierung von Busdaten – Fehleranalyse im Forschungsprojekt AutobahnVis},
    author          = {Michael Sedlmair, Michael Schraut, Wolfgang Hintermaier},
    year            = {2011},
    month           = {10},
    journal         = {Journal of Automobil Elektronik},
    url             = {https://www.all-electronics.de/automotive-transportation/visualisierung-von-busdaten.html},
    abstract        = {Wie können Methoden der Informationsvisualisierung die explorative Analyse von Busdaten verbessern? Ein Forschungsprojekt mit dem Namen „AutobahnVis“ zeigt beispielhaft, wie Visualisierung neue Einsichten in komplexe Zusammenhänge ermöglicht und zur Fehleranalyse von Busaufzeichnungen beiträgt.},
    venue           = {Journal of Automobil Elektronik}
}
@article{sedlmair2011ivs,
    title           = {Information Visualization Evaluation in Large Companies: Challenges, Experiences and Recommendations},
    author          = {Michael Sedlmair, Petra Isenberg, Dominikus Baur, Andreas Butz},
    year            = {2011},
    month           = {07},
    journal         = {Information Visualization},
    publisher       = {Sage Publications Sage UK: London, England},
    volume          = {10},
    number          = {3},
    pages           = {248--266},
    doi             = {https://doi.org/10.1177%2F1473871611413099},
    venue           = {Information Visualization},
    abstract        = {We examine the implications of evaluating data analysis processes and information visualization tools in a large company setting. While several researchers have addressed the difficulties of evaluating information visualizations with regards to changing data, tasks, and visual encodings, considerably less work has been published on the difficulties of evaluation within specific work contexts. We specifically focus on the challenges, which arise in the context of large companies with several thousand employees. Based on our own experience from a 3.5-year collaboration within a large automotive company, we first present a collection of nine information visualization evaluation challenges. We then discuss these challenges by means of two concrete visualization case studies from our own work. We finally derive a set of 16 recommendations for planning and conducting evaluations in large company settings. The set of challenges and recommendations and the discussion of our experience are meant to provide practical guidance to other researchers and practitioners, who plan to study information visualization in large company settings.}
}
@inproceedings{sedlmair2011chi,
    title           = {Cardiogram: Visual Analytics for Automotive Engineers},
    author          = {Michael Sedlmair, Petra Isenberg, Dominikus Baur, Michael Mauerer, Christian Pigorsch, Andreas Butz},
    year            = {2011},
    month           = {05},
    booktitle       = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
    location        = {Vancouver, BC, Canada},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {CHI '11},
    pages           = {1727–1736},
    doi             = {https://doi.org/10.1145/1978942.1979194},
    isbn            = {9781450302289},
    abstract        = {We present Cardiogram, a visual analytics system that supports automotive engineers in debugging masses of traces each consisting of millions of recorded messages from in-car communication networks. With their increasing complexity, ensuring these safety-critical networks to be error-free has become a major task and challenge for automotive engineers. To overcome shortcomings of current analysis tools, Cardiogram combines visualization techniques with a data preprocessing approach to automatically reduce complexity based on engineers' domain knowledge. In this paper, we provide the findings from an exploratory, three-year field study within a large automotive company, studying current practices of engineers, the challenges they meet and the characteristics for integrating novel visual analytics tools into their work practices. We then introduce Cardiogram, discuss how our field analysis influenced our design decisions, and present a qualitative, long-term, in-depth evaluation. Results of this study showed that our participants successfully used Cardiogram to increase the amount of analyzable information, to externalize domain knowledge, and to provide new insights into trace data. Our design approach finally led to the adoption of Cardiogram into engineers' daily practices.},
    numpages        = {10},
    keywords        = {automotive, visual analytics, visualization, in-car communication, field study},
    venue           = {CHI}
}
@article{baur2010infovis,
    title           = {The Streams of Our Lives: Visualizing Listening Histories in Context},
    author          = {Dominikus Baur, Frederik Seiffert, Michael Sedlmair, Sebastian Boring},
    year            = {2010},
    month           = {10},
    journal         = {IEEE Transactions on Visualization and Computer Graphics},
    volume          = {16},
    number          = {6},
    pages           = {1119--1128},
    doi             = {https://doi.org/10.1109/TVCG.2010.206},
    video           = {https://vimeo.com/9495577},
    venue           = {TVCG},
    abstract        = {The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.}
}
@phdthesis{sedlmair2010dissertation,
    title           = {Visual Analysis of In-Car Communication Networks},
    author          = {Michael Sedlmair},
    year            = {2010},
    month           = {10},
    doi             = {https://doi.org/10.5282/edoc.12448},
    url             = {http://nbn-resolving.de/urn:nbn:de:bvb:19-124488},
    school          = {LMU},
    keywords        = {Visualization, Visual Analytics, Automotive, In-Car Networks},
    venue           = {University of Munich},
    abstract        = {Analyzing, understanding and working with complex systems and large datasets has become a familiar challenge in the information era. The explosion of data worldwide affects nearly every part of society, particularly the science, engineering, health, and financial domains. Looking, for instance at the automotive industry, engineers are confronted with the enormously increased complexity of vehicle electronics. Over the years, a large number of advanced functions, such as ACC (adaptive cruise control), rear seat entertainment systems or automatic start/stop engines, has been integrated into the vehicle. Thereby, the functions have been more and more distributed over the vehicle, leading to the introduction of several communication networks. Overlooking all relevant data facets, understanding dependencies, analyzing the flow of messages and tracking down problems in these networks has become a major challenge for automotive engineers. Promising approaches to overcome information overload and to provide insight into complex data are Information Visualization (InfoVis) and Visual Analytics (VA). Over the last decades, these research communities spent much effort on developing new methods to help users obtain insight into complex data. However, few of these solutions have yet reached end users, and moving research into practice remains one of the great challenges in visual data analysis. This situation is particularly true for large company settings, where very little is known about additional challenges, obstacles and requirements in InfoVis/VA development and evaluation. Users have to be better integrated into our research processes in terms of adequate requirements analysis, understanding practices and challenges, developing well-directed, user-centered technologies and evaluating their value within a realistic context. This dissertation explores a novel InfoVis/VA application area, namely in-car communication networks, and demonstrates how information visualization methods and techniques can help engineers to work with and better understand these networks. Based on a three-year internship with a large automotive company and the close cooperation with domain experts, I grounded a profound understanding of specific challenges, requirements and obstacles for InfoVis/VA application in this area and learned that “designing with not for the people” is highly important for successful solutions. The three main contributions of this dissertation are: (1) An empirical analysis of current working practices of automotive engineers and the derivation of specific design requirements for InfoVis/VA tools; (2) the successful application and evaluation of nine prototypes, including the deployment of five systems; and (3) based on the three-year experience, a set of recommendations for developing and evaluating InfoVis systems in large company settings. I present ethnographic studies with more than 150 automotive engineers. These studies helped us to understand currently used tools, the underlying data, tasks as well as user groups and to categorize the field into application sub-domains. Based on these findings, we propose implications and recommendations for designing tools to support current practices of automotive network engineers with InfoVis/VA technologies. I also present nine InfoVis design studies that we built and evaluated with automotive domain experts and use them to systematically explore the design space of applying InfoVis to in-car communication networks. Each prototype was developed in a user-centered, participatory process, respectively with a focus on a specific sub-domain of target users with specific data and tasks. Experimental results from studies with real users are presented, that show that the visualization prototypes can improve the engineers’ work in terms of working efficiency, better understanding and novel insights. Based on lessons learned from repeatedly designing and evaluating our tools together with domain experts at a large automotive company, I discuss challenges and present recommendations for deploying and evaluating VA/InfoVis tools in large company settings. I hope that these recommendations can guide other InfoVis researchers and practitioners in similar projects by providing them with new insights, such as the necessity for close integration with current tools and given processes, distributed knowledge and high degree of specialization, and the importance of addressing prevailing mental models and time restrictions. In general, I think that large company settings are a promising and fruitful field for novel InfoVis applications and expect our recommendations to be useful tools for other researchers and tool designers.}
}
@inproceedings{sedlmair2010beliv,
    title           = {Evaluating Information Visualization in Large Companies: Challenges, Experiences and Recommendations},
    author          = {Michael Sedlmair, Petra Isenberg, Dominikus Baur, Andreas Butz},
    year            = {2010},
    month           = {04},
    booktitle       = {Proceedings of the 3rd BELIV'10 Workshop: BEyond Time and Errors: Novel EvaLuation Methods for Information Visualization},
    location        = {Atlanta, Georgia},
    publisher       = {Association for Computing Machinery},
    address         = {New York, NY, USA},
    series          = {BELIV '10},
    pages           = {79–86},
    doi             = {https://doi.org/10.1145/2110192.2110204},
    isbn            = {9781450300070},
    note            = {Received a best paper award},
    badge           = {bestpaper},
    abstract        = {We examine the process and some implications of evaluating information visualization in a large company setting. While several researchers have addressed the difficulties of evaluating information visualizations with regards to changing data, tasks, and visual encodings, considerably less work has been published on the difficulties of evaluation within specific work contexts. In this paper, we specifically focus on the challenges arising in the context of large companies with several thousand employees. We present a collection of evaluation challenges, discuss our own experiences conducting information visualization evaluation within the context of a large automotive company, and present a set of recommendations derived from our experiences. The set of challenges and recommendations can aid researchers and practitioners in preparing and conducting evaluations of their products within a large company setting.},
    numpages        = {8},
    keywords        = {information visualization, company setting, evaluation},
    venue           = {CHI BELIV}
}
@techreport{baur2010infovisHS,
    title           = {Trends in Information Visualization},
    author          = {Dominikus Baur, Michael Sedlmair, Raphael Wimmer, Yaxi Chen, Sara Streng, Sebastian Boring, Alexander De Luca, Andreas Butz},
    year            = {2010},
    month           = {04},
    institution     = {LMU},
    venue           = {LMU-MI-2010-1: Media Informatics Advanced Seminar},
    abstract        = {This report provides an overview of current applications and research trends in the field of information visualization. The content ranges from classical information visualization aspects such as network visualization, multivariate data representation and multiple coordinated views to topics beyond the traditional scope such as aesthetics, collaboration or casual aspects in information visualization.}
}
@techreport{isenberg2010covis,
    title           = {Collaborative Visualization on Interactive Surfaces - CoVIS '09},
    author          = {Petra Isenberg, Michael Sedlmair, Dominikus Baur, Tobias Isenberg, Andreas Butz},
    year            = {2010},
    month           = {04},
    institution     = {LMU},
    venue           = {CoVIS '09, Workshop at Visweek},
    abstract        = {The report comprises interdisciplinary aspects form the fields of information visualization, scientific visualization, visual analytics as well as CSCW and HCI. It is meant to help other researchers better understand the role and the growing impact of interactive surfaces as an emerging technology for supporting collaborative visualization and visual analytics settings.}
}
@inproceedings{sedlmair2009iv,
    title           = {MostVis: An Interactive Visualization Supporting Automotive Engineers in MOST Catalog Exploration},
    author          = {Michael Sedlmair, Christian Berhold, Daniel Herrscher, Sebastian Boring, Andreas Butz},
    year            = {2009},
    month           = {08},
    booktitle       = {2009 13th International Conference Information Visualisation},
    pages           = {173--182},
    doi             = {https://doi.org/10.1109/IV.2009.95},
    venue           = {IV},
    abstract        = {The MOST bus is a current bus technology for connecting multimedia components in cars, such as radios, navigation systems, or media players. The bus functionality is described in a large hierarchically structured catalog of some 4psila000 entries. Browsing this catalog has become infeasible on paper as well as with currently used textual database interfaces. An observation of current work practices has revealed many problems and inefficiencies. We describe the (iteratively developed) design of MostVis, a visual tool for exploring MOST function catalogs, as well as an evaluation of our implemented prototype. Our design carefully adapts existing visualization techniques and combines them in a multiple coordinated view (MCV) approach to satisfy the specific needs of our target group. With this paper, we hope to provide a living example of how existing general-purpose techniques can be successfully trimmed and tailored for a very specific audience.}
}
@article{ruhland2009ijac,
    title           = {LibViz: Data Visualisation of the Old Library},
    author          = {Kerstin Ruhland, Michael Sedlmair, Susan Bioletti, Carol O'Sullivan},
    year            = {2009},
    month           = {01},
    journal         = {International Journal of Architectural Computing},
    publisher       = {SAGE Publications Sage UK: London, England},
    volume          = {7},
    number          = {1},
    pages           = {177--192},
    venue           = {International Journal of Architectural Computing},
    abstract        = {The Old Library of Trinity College Dublin, built in 1732, is an internationally renowned research library. In recent decades it has also become a major tourist attraction in Dublin, with the display of the Book of Kells within the Old Library now drawing over half a million visitors per year. The Preservation and Conservation Department of the Library has raised concerns about the impact of the environment on the collection. The location of the building in the city centre, large visitor numbers, and the conditions within the building are putting the collection at risk. In developing a strategic plan to find solutions to these problems, the department has been assessing and documenting the current situation. This paper introduces ongoing work on a system to visualise the collected data, which includes: dust levels and dispersion, internal and external temperature and relative humidity levels, and visitor numbers in the Old Library. We are developing a user interface for which the data, originally stored in various file formats, is consolidated in a database which can be explored using a 3D virtual reconstruction of the Old Library. With this novel technique, it is also possible to compare and assess the relationships between the various datasets in context.}
}
@inproceedings{sedlmair2009sg1,
    title           = {User-centered Development of a Visual Exploration System for In-Car Communication},
    author          = {Michael Sedlmair, Benjamin Kunze, Wolfgang Hintermaier, Andreas Butz},
    year            = {2009},
    month           = {01},
    booktitle       = {Smart Graphics},
    publisher       = {Springer Berlin Heidelberg},
    address         = {Berlin, Heidelberg},
    pages           = {105--116},
    doi             = {https://doi.org/10.1007/978-3-642-02115-2_9},
    isbn            = {978-3-642-02115-2},
    editor          = {Butz, Andreas and Fisher, Brian and Christie, Marc and Krüger, Antonio and Olivier, Patrick and Therón, Roberto},
    abstract        = {Modern premium automobiles are equipped with an increasing number of Electronic Control Units (ECUs). These ECUs are interconnected and form a complex network to provide a wide range of advanced vehicle functionality. Analyzing the flow of messages in this network and tracking down problems has become a major challenge for automotive engineers. By observing their working practices, we found that the tools they currently use are mostly text-based and largely fail to provide correlations among the enormous amount of data. We established requirements for a more appropriate (visual) tool set. We followed a user-centered approach to design several visualizations for in-car communication processes, each with a clear purpose and application scenario. Then we used low-fidelity prototypes to evaluate our ideas and to identify the “working” designs. Based on this selection, we finally implemented a prototype and conducted an expert evaluation which revealed the emergence of a novel mental model for thinking about and discussing in-car communication processes.},
    venue           = {SG}
}
@inproceedings{sedlmair2009sg2,
    title           = {Towards the Big Picture: Enriching 3D Models with Information Visualisation and Vice Versa},
    author          = {Michael Sedlmair, Kerstin Ruhland, Fabian Hennecke, Andreas Butz, Susan Bioletti, Carol O'Sullivan},
    year            = {2009},
    month           = {01},
    booktitle       = {Smart Graphics},
    publisher       = {Springer Berlin Heidelberg},
    address         = {Berlin, Heidelberg},
    pages           = {27--39},
    doi             = {https://doi.org/10.1007/978-3-642-02115-2_3},
    isbn            = {978-3-642-02115-2},
    editor          = {Butz, Andreas and Fisher, Brian and Christie, Marc and Krüger, Antonio and Olivier, Patrick and Therón, Roberto},
    abstract        = {Most information visualisation methods are based on abstract visual representations without any concrete manifestation in the “real world”. However, a variety of abstract datasets can indeed be related to, and hence enriched by, real-world aspects. In these cases an additional virtual representation of the 3D object can help to gain a better insight into the connection between abstract and real-world issues. We demonstrate this approach with two prototype systems that combine information visualisation with 3D models in multiple coordinated views. The first prototype involves the visualisation of in-car communication traces. The 3D model of the car serves as one view among several and provides the user with information about the car’s activities. LibViz, our second prototype, is based on a full screen 3D representation of a library building. Measured data is visualised in overlaid, semi-transparent windows to allow the user interpretation of the data in its spatial context of the library’s 3D model. Based on the two prototypes, we identify the benefits and drawbacks of the approach, investigate aspects of coordination between the 3D model and the abstract visualisations, and discuss principals for a general approach.},
    pdf             = {http://www.medien.ifi.lmu.de/pubdb/publications/pub/sedlmair2009sg2/sedlmair2009sg2.pdf},
    venue           = {SG}
}
@inproceedings{sedlmair2008iv,
    title           = {A Dual-View Visualization of In-Car Communication Processes},
    author          = {Michael Sedlmair, Wolfgang Hintermaier, Konrad Stocker, Thortsen Büring, Andreas Butz},
    year            = {2008},
    month           = {07},
    booktitle       = {2008 12th International Conference Information Visualisation},
    pages           = {157--162},
    doi             = {https://doi.org/10.1109/IV.2008.20},
    venue           = {IV},
    abstract        = {With the increasing complexity of in-car communication architectures, their diagnostics have become essential for automotive development and maintenance. In order to help engineers to detect and analyze the potential sources and consequences of errors, it is crucial to provide both comprehensive and detailed insight into the communication processes and their contexts. Two important aspects of these are the dependencies and correlations between onboard functions. In this paper we present a dual-view visualization for exploring the functional dependency chains of in-car communication processes. One view presents the dependencies of hardware components using a space filling approach similar to a treemap, whereas the other view displays the functional correlations as an interactive sequence chart. The views are coupled via color coding and show the dependencies of an interactively selectable functional unit. In an expert evaluation, we assessed the benefits of using this visualization technique for in-car communication diagnostics with very positive results.}
}
@article{ruhland2008vsmm,
    title           = {LibViz: Data Visualisation of the Old Library},
    author          = {Kerstin Ruhland, Susan Bioletti, Michael Sedlmair, Carol O'Sullivan},
    year            = {2008},
    month           = {01},
    journal         = {International Journal of Architectural Computing},
    volume          = {7},
    number          = {1},
    pages           = {177--192},
    doi             = {https://doi.org/10.1260/147807709788549402},
    note            = {Received a best paper award},
    badge           = {bestpaper},
    abstract        = {The Old Library of Trinity College Dublin, built in 1732, is an internationally renowned research library. In recent decades it has also become a major tourist attraction in Dublin, with the display of the Book of Kells within the Old Library now drawing over half a million visitors per year. The Preservation and Conservation Department of the Library has raised concerns about the impact of the environment on the collection. The location of the building in the city centre, large visitor numbers, and the conditions within the  building are putting the collection at risk. In developing a strategic plan to find solutions to these problems, the department has been assessing and documenting the current situation. This paper introduces ongoing work on a system to visualise the collected data, which includes: dust levels and dispersion, internal and external temperature and relative humidity levels, and visitor numbers in the Old Library. We are developing a user interface for which the data, originally stored in various file formats, is consolidated in a database which can be explored using a 3D virtual reconstruction of the Old Library. With this novel technique, it is also possible to compare and assess the relationships between the various datasets in context.},
    venue           = {VSMM}
}
@inproceedings{sedlmair2008cscw,
    title           = {Requirements for a MDE System to Support Collaborative In-Car Communication Diagnostics},
    author          = {Michael Sedlmair, Dominikus Baur, Sebastian Boring, Petra Isenberg, Marko Jurmu, Andreas Butz},
    year            = {2008},
    month           = {01},
    booktitle       = {CSCW Workshop on Beyond the Laboratory: Supporting Authentic Collaboration with Multiple Displays},
    venue           = {International CSCW Workshop Beyond the Laboratory},
    abstract        = {Modern automobiles come with a high degree of electronicand an enormous amount of in-car communication activi-ties. This leads to an increasing complexity which challengesautomotive engineers in detecting and analyzing erroneouscommunication processes. In this contribution we presentresults of our studies on current working behaviour and envi-ronments of analysis and diagnosis experts in the automotiveindustry. While we found a sufficient hardware and softwaresupport in single user environments, co-located collabora-tive environments are characterized by multiple hardwaredevices but by a lack of specific software to support collabo-rating in these multiple display environment (MDEs). Aftera detailed user analysis and evaluation we derive system re-quirements for this new MDE application area and discussits challenges.}
}
@article{sedlmair2008led,
    title           = {MSCar: Enhancing Message Sequence Charts with Interactivity for Analysing (Automotive) Communication Sequences},
    author          = {Michael Sedlmair},
    year            = {2008},
    month           = {01},
    journal         = {Electronic Communications of the EASST},
    volume          = {13},
    doi             = {https://doi.org/10.14279/tuj.eceasst.13.170},
    venue           = {Workshop on the Layout of (Software) Engineering Diagrams (LED)},
    abstract        = {Message Sequence Charts (MSCs) are a standardized and widespread form to visually describe interactions in distributed systems. Our approach proposes the enrichment of large scaled MSCs with novel interaction and design techniques used in the field of information visualization. Additionally, we show a graphical solution to visualize parallel, multi-directed communication processes in MSCs. Instead of the common application to specify system behaviours our interactive MSCs are aimed at exploring and diagnosing dependencies in network communication in general and, regarding our special requirements, within in-car communication traces. We implemented a prototype called MSCar with Focus and Context techniques, Dynamic Path Highlighting, Details on Demand and Colour Coding to support the users' cognitive abilities. A qualitative user study on MSCar gave us preliminary feedback and disclosed potentials of our approach.}
}
