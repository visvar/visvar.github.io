<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Exploring Visual Prompts: Refining Images with Scribbles and Annotations in Generative AI Image Tools</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Exploring Visual Prompts: Refining Images with Scribbles and Annotations in Generative AI Image Tools</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/park2025exploring.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagepark2025exploring" src="../assets/img/teaser/park2025exploring.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> <a href="../members/hyerim_park.html" target="_blank">Hyerim Park</a>, Malin Eiband, Andre Luckow, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>
                </div>
                  
                <div>
                  <b>Venue.</b> CHI (2025)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1145/3706599.3719802" target="_blank" rel="noreferrer">DOI</a>
                  <a href="https://arxiv.org/abs/2503.03398" target="_blank" rel="noreferrer">link</a>
                  
                  <a href="../assets/pdf/park2025exploring.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Generative AI (GenAI) tools are increasingly integrated into design workflows. While text prompts remain the primary input method for GenAI image tools, designers often struggle to craft effective ones. Moreover, research has primarily focused on input methods for ideation, with limited attention to refinement tasks. This study explores designers' preferences for three input methods - text prompts, annotations, and scribbles - through a preliminary digital paper-based study with seven professional designers. Designers preferred annotations for spatial adjustments and referencing in-image elements, while scribbles were favored for specifying attributes such as shape, size, and position, often combined with other methods. Text prompts excelled at providing detailed descriptions or when designers sought greater GenAI creativity. However, designers expressed concerns about AI misinterpreting annotations and scribbles and the effort needed to create effective text prompts. These insights inform GenAI interface design to better support refinement tasks, align with workflows, and enhance communication with AI systems.</div>
                <div class="bibtex"><textarea>@inproceedings{park2025exploring,
    title         = {Exploring Visual Prompts: Refining Images with Scribbles and Annotations in Generative AI Image Tools},
    author        = {Hyerim Park, Malin Eiband, Andre Luckow, Michael Sedlmair},
    year          = {2025},
    month         = {4},
    booktitle     = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
    publisher     = {Association for Computing Machinery},
    series        = {CHI EA '25},
    doi           = {https://doi.org/10.1145/3706599.3719802},
    isbn          = {9798400713958},
    url           = {https://arxiv.org/abs/2503.03398},
    articleno     = {257},
    numpages      = {10},
    keywords      = {generative AI, text prompts, annotation-based input, scribble-based input, design refinement},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/park2025exploring.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>