<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Mixing and Matching: Instruction Conveyance for Collaborative Tasks Using Asymmetric Augmented Reality Setups</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Mixing and Matching: Instruction Conveyance for Collaborative Tasks Using Asymmetric Augmented Reality Setups</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/aygün2025mixing.png" target="_blank" title="show image full size">
                <img class="teaser" id="imageaygün2025mixing" src="../assets/img/teaser/aygün2025mixing.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Dilara Aygün, <a href="../members/aimee_sousa_calepso.html" target="_blank">Aimée Sousa Calepso</a>, Xiliu Yang, Achim Menges, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>
                </div>
                  
                <div>
                  <b>Venue.</b> VRW (2025)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1109/VRW66409.2025.00215" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/aygün2025mixing.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Augmented Reality (AR) applications can provide support to users with task instructions in-situ. Among different AR display types used for these applications, head-mounted displays (HMDs) and handheld displays (HHDs) are popular solutions. Previous research has examined asymmetrical setups, i.e., two or more people using different types of devices at the same time. However, asymmetrical setups for physical tasks that require collaboration have been little investigated. Our work implements dyadic assembly and sorting tasks supported by simultaneously using an HHD and an HMD. We conducted a user study (N=20) to evaluate this setup. Participants rated both displays’ usability similarly but showed a preference for HMD during both sorting and assembly tasks. While most participants agreed that they collaborated with their partners and the task was easier done in a team, less than half of HMD users in the sorting task agreed with the statement.</div>
                <div class="bibtex"><textarea>@inproceedings{aygün2025mixing,
    title         = {Mixing and Matching: Instruction Conveyance for Collaborative Tasks Using Asymmetric Augmented Reality Setups},
    author        = {Dilara Ayg\"{u}n, Aim\'{e}e Sousa Calepso, Xiliu Yang, Achim Menges, Michael Sedlmair},
    year          = {2025},
    month         = {3},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    pages         = {1072--1078},
    doi           = {https://doi.org/10.1109/VRW66409.2025.00215},
    keywords      = {Three-dimensional displays;Head-mounted displays;Conferences;Collaboration;Data visualization;Resists;Usability;Augmented reality;Assembly;Sorting;Augmented Reality;Collaboration;Data Visualization},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/aygün2025mixing.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>