<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Toward In-Situ Authoring of Situated Visualization with Chorded Keyboards</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Toward In-Situ Authoring of Situated Visualization with Chorded Keyboards</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/dosdall2022toward.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagedosdall2022toward" src="../assets/img/teaser/dosdall2022toward.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Sarah Dosdall, <a href="../members/katrin_angerbauer.html" target="_blank">Katrin Angerbauer</a>, Leonel Merino, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>, Daniel Weiskopf
                </div>
                  
                <div>
                  <b>Venue.</b> VINCI (2022)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1145/3554944.3554970" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3554944.3554970" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Authoring situated visualizations in-situ is challenging due to the need of writing code in a mobile and highly dynamic fashion. To provide better support for that, we define requirements for text input methods that target situated visualization authoring. We identify wearable chorded keyboards as a potentially suitable method that fulfills some of these requirements. To further investigate this approach, we tailored a chorded keyboard device to visualization authoring, developed a learning application, and conducted a pilot user study. Our results confirm that learning a high number of chords is the main barrier for adoption, as in other application areas. Based on that, we discuss ideas on how chorded keyboards with a strongly reduced alphabet, hand gestures, and voice recognition might be used as a viable, multi-modal support for authoring situated visualizations in-situ.</div>
                <div class="bibtex"><textarea>@inproceedings{dosdall2022toward,
    title         = {Toward In-Situ Authoring of Situated Visualization with Chorded Keyboards},
    author        = {Sarah Dosdall, Katrin Angerbauer, Leonel Merino, Michael Sedlmair, Daniel Weiskopf},
    year          = {2022},
    month         = {8},
    booktitle     = {Proceedings of the 15th International Symposium on Visual Information Communication and Interaction},
    publisher     = {ACM},
    series        = {VINCI '22},
    doi           = {https://doi.org/10.1145/3554944.3554970},
    isbn          = {9781450398060},
    articleno     = {14},
    numpages      = {5},
    keywords      = {mixed reality, chorded keyboard, pilot study, Situated visualization},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/dosdall2022toward.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>