<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Making Eye Contact Accessible: Augmenting Gaze in Job Interviews for People with Visual Impairments</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <main>
        
  <div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
        <ul>
          <li><a href="../index.html">home</a></li>
        </ul>
      </nav>
    </div>
  </header>
</div>
        <div>
          <article>
            <h1>Making Eye Contact Accessible: Augmenting Gaze in Job Interviews for People with Visual Impairments</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/wieland2026making.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagewieland2026making" src="../assets/img/teaser/wieland2026making.png"/><span class='sr-only'>(opens in new tab)</span>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> <a href="../members/markus_wieland.html">Markus Wieland</a>, Kathrin Schnizer, Francesco Chiossi, <a href="../members/nina_doerr.html">Nina Doerr</a>, Florian Lang, Thomas Kosch, <a href="../members/michael_sedlmair.html">Michael Sedlmair</a>
                </div>
                  
                <div>
                  <b>Venue.</b> AHs (2026)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://www.doi.org/10.1145/3795011.3795045" target="_blank" rel="noreferrer">DOI<span class='sr-only'>(opens in new tab)</span></a>
                  
                  
                  <a href="../assets/pdf/wieland2026making.pdf" target="_blank" rel="noreferrer">PDF<span class='sr-only'>(opens in new tab)</span></a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Job interviews rely heavily on nonverbal communication, with gaze serving as a central signal of attentiveness and competence. For people with visual impairments, this creates an asymmetry that disadvantages them: they are expected to demonstrate eye contact but cannot access or reciprocate the gaze cues that structure interaction. To investigate these challenges in a high-stakes context, we conducted interviews with eight people with visual impairments, revealing how inaccessible gaze produces uncertainty, social pressure, and reliance on compensatory strategies. Based on these insights, we designed three visual cues, EYES, HALO, and FRAME, and evaluated them in a simulated job interview in virtual reality with 12 people with visual impairments. Our fndings show that spatially anchored cues around the interviewerâ€™s face supported head alignment and improved perception of attentional focus, while peripheral cues were distracting. The study highlights the need for gaze cues that strike a balance between perceptual accessibility and social appropriateness in professional settings.</div>
                <div class="bibtex"><textarea>@inproceedings{wieland2026making,
    title         = {Making Eye Contact Accessible: Augmenting Gaze in Job Interviews for People with Visual Impairments},
    author        = {Markus Wieland, Kathrin Schnizer, Francesco Chiossi, Nina Doerr, Florian Lang, Thomas Kosch, Michael Sedlmair},
    year          = {2026},
    month         = {2},
    booktitle     = {Proc. Augmented Humans International Conference},
    publisher     = {ACM},
    series        = {AHs},
    doi           = {https://www.doi.org/10.1145/3795011.3795045},
    isbn          = {979-8-4007-2351-3/26/03},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/wieland2026making.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>