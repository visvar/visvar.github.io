<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>An implementation and evaluation of large-scale multi-user human-robot collaboration with head-mounted augmented reality</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <main>
        
  <div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
        <ul>
          <li><a href="../index.html">home</a></li>
        </ul>
      </nav>
    </div>
  </header>
</div>
        <div>
          <article>
            <h1>An implementation and evaluation of large-scale multi-user human-robot collaboration with head-mounted augmented reality</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/yang2025implementation.png" target="_blank" title="show image full size">
                <img class="teaser" id="imageyang2025implementation" src="../assets/img/teaser/yang2025implementation.png"/><span class='sr-only'>(opens in new tab)</span>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Xiliu Yang, Felix Amtsberg, Benjamin Kaiser, Lior Skoury, Tim Stark, Simon Treml, Nils Opgenorth, <a href="../members/aimee_sousa_calepso.html">Aim√©e Sousa Calepso</a>, <a href="../members/michael_sedlmair.html">Michael Sedlmair</a>, Thomas Wortmann, Alexander Verl, Achim Menges
                </div>
                  
                <div>
                  <b>Venue.</b> Advanced Engineering Informatics (2025)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1016/j.aei.2025.103475" target="_blank" rel="noreferrer">DOI<span class='sr-only'>(opens in new tab)</span></a>
                  
                  
                  <a href="../assets/pdf/yang2025implementation.pdf" target="_blank" rel="noreferrer">PDF<span class='sr-only'>(opens in new tab)</span></a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Human-robot collaboration (HRC) offers promising potential for more flexible and sustainable production practices in architecture and construction. This requires HRC setups to scale up from light-payload collaborative robots to conform with the scale of building construction while considering the safety and teamwork culture for workers. This research proposes a system for large-scale multi-user HRC using head-mounted augmented reality (AR) devices. To achieve this, we contribute three methods that work in conjunction: (1) an AR system that enables multiple users to share tasks and work together with robots; (2) a dynamic human task allocation engine that reacts to the changing production teams and task types; and (3) a safety zone generation and allocation method to configure human collaboration in shared space with large-scale robots. The system is evaluated using a case study of prefabricated timber cassettes combining discrete event simulations, a user study and a fabrication process demonstrator with an industry partner.</div>
                <div class="bibtex"><textarea>@article{yang2025implementation,
    title         = {An implementation and evaluation of large-scale multi-user human-robot collaboration with head-mounted augmented reality},
    author        = {Xiliu Yang, Felix Amtsberg, Benjamin Kaiser, Lior Skoury, Tim Stark, Simon Treml, Nils Opgenorth, Aim\'{e}e Sousa Calepso, Michael Sedlmair, Thomas Wortmann, Alexander Verl, Achim Menges},
    year          = {2025},
    month         = {9},
    journal       = {Advanced Engineering Informatics},
    volume        = {67},
    pages         = {103475},
    doi           = {https://doi.org/10.1016/j.aei.2025.103475},
    issn          = {1474-0346},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/yang2025implementation.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>