<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>The Joy of Co-Painting: Creative Human-AI Collaboration for Traceable Image-Generation Workflows</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <main>
        
  <div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
        <ul>
          <li><a href="../index.html">home</a></li>
        </ul>
      </nav>
    </div>
  </header>
</div>
        <div>
          <article>
            <h1>The Joy of Co-Painting: Creative Human-AI Collaboration for Traceable Image-Generation Workflows</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/satkunarajan2025joyofcopainting.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagesatkunarajan2025joyofcopainting" src="../assets/img/teaser/satkunarajan2025joyofcopainting.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> <a href="../members/jena_satkunarajan.html" target="_blank">Jena Satkunarajan</a>, Steffen Koch, Kuno Kurzhals
                </div>
                  
                <div>
                  <b>Venue.</b> PacificVis (2025)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1109/PacificVis64226.2025.00038" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/satkunarajan2025joyofcopainting.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Image-generative models have gained popularity over the last years with their ability to create realistic artwork. Realizing complex artworks with specific creative ideas often requires iterative optimization of specialized prompts, but may still result in inadequate images. The inclusion of reference images and adapting modelspecific parameters can help in steering the model and fostering the creative intent of the user. But by providing text prompts, initial images, and adapting model parameters, users face a vast design space for creating images. To navigate through this space, we propose a visualization approach that combines an interactive Provenance Graph, parameter visualizations, and high-dimensional embeddings. Our approach helps pursue multiple parallel creation paths, makes workflows traceable and parameter changes transparent, and facilitates the reporting of image editing steps. In addition to prompt formulation, we focus on targeted generation by probing parameters, image compositions, and editing details. We integrate the generative process into existing image editing software, enabling users to compose artwork in collaboration with the model. The presented approach is evaluated in a user experiment (n=9) for generating artwork. The results show that users with different levels of experience can create targeted artwork but use different strategies when working with the Provenance Graph.</div>
                <div class="bibtex"><textarea>@inproceedings{satkunarajan2025joyofcopainting,
    title         = {The Joy of Co-Painting: Creative Human-AI Collaboration for Traceable Image-Generation Workflows},
    author        = {Jena Satkunarajan, Steffen Koch, Kuno Kurzhals},
    year          = {2025},
    month         = {4},
    booktitle     = {2025 IEEE 18th Pacific Visualization Conference (PacificVis)},
    pages         = {318--328},
    doi           = {https://doi.org/10.1109/PacificVis64226.2025.00038},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/satkunarajan2025joyofcopainting.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>