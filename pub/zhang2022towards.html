<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Towards reducing visual workload in surgical navigation: proof-of-concept of an augmented reality haptic guidance system</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Towards reducing visual workload in surgical navigation: proof-of-concept of an augmented reality haptic guidance system</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/zhang2022towards.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagezhang2022towards" src="../assets/img/teaser/zhang2022towards.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Gesiren Zhang, <a href="../members/jan_ulrich_bartels.html" target="_blank">Jan Ulrich Bartels</a>, Alejandro Martin-Gomez, Mehran Armand
                </div>
                  
                <div>
                  <b>Venue.</b> Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization (2022)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1080/21681163.2022.2152372" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/zhang2022towards.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> The integration of planning and navigation capabilities into the operating room has enabled surgeons take on more precise procedures. Traditionally, planning and navigation information is presented using monitors in the surgical theatre. But the monitors force the surgeon to frequently look away from the surgical area. Augmented reality technologies have enabled surgeons to visualise navigation information in-situ. However, burdening the visual field with additional information can be distracting. We propose integrating haptic feedback into a surgical tool handle to enable surgical guidance capabilities. This property reduces the amount of visual information, freeing surgeons to maintain visual attention over the patient and the surgical site. To investigate the feasibility of this guidance paradigm we conducted a pilot study with six subjects. Participants traced paths, pinpointed locations and matched alignments with a mock surgical tool featuring a novel haptic handle. We collected quantitative data, tracking user’s accuracy and time to completion as well as subjective cognitive load. Our results show that haptic feedback can guide participants using a tool to sub-millimetre and sub-degree accuracy with only little training. Participants were able to match a location with an average error of 0.82mm, desired pivot alignments with an average error of 0.83° and desired rotations to 0.46°.</div>
                <div class="bibtex"><textarea>@article{zhang2022towards,
    title         = {Towards reducing visual workload in surgical navigation: proof-of-concept of an augmented reality haptic guidance system},
    author        = {Gesiren Zhang, Jan Ulrich Bartels, Alejandro Martin-Gomez, Mehran Armand},
    year          = {2022},
    month         = {12},
    journal       = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging \& Visualization},
    publisher     = {Taylor \& Francis},
    volume        = {11},
    number        = {4},
    pages         = {1073--1080},
    doi           = {https://doi.org/10.1080/21681163.2022.2152372},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/zhang2022towards.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>