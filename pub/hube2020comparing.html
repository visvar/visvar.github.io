<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <main>
        
  <div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
        <ul>
          <li><a href="../index.html">home</a></li>
        </ul>
      </nav>
    </div>
  </header>
</div>
        <div>
          <article>
            <h1>Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/hube2020comparing.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagehube2020comparing" src="../assets/img/teaser/hube2020comparing.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> <a href="../members/natalie_hube.html" target="_blank">Natalie Hube</a>, Oliver Lenz, Lars Engeln, Rainer Groh, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>
                </div>
                  
                <div>
                  <b>Venue.</b> ISMAR-Adjunct (2020)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1109/ISMAR-Adjunct51615.2020.00023" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/hube2020comparing.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> We present a user study comparing a pre-evaluated mapping approach with a state-of-the-art direct mapping method of facial expressions for emotion judgment in an immersive setting. At its heart, the pre-evaluated approach leverages semiotics, a theory used in linguistic. In doing so, we want to compare pre-evaluation with an approach that seeks to directly map real facial expressions onto their virtual counterparts. To evaluate both approaches, we conduct a controlled lab study with 22 participants. The results show that users are significantly more accurate in judging virtual facial expressions with pre-evaluated mapping. Additionally, participants were slightly more confident when deciding on a presented emotion. We could not find any differences regarding potential Uncanny Valley effects. However, the pre-evaluated mapping shows potential to be more convenient in a conversational scenario.</div>
                <div class="bibtex"><textarea>@inproceedings{hube2020comparing,
    title         = {Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion},
    author        = {Natalie Hube, Oliver Lenz, Lars Engeln, Rainer Groh, Michael Sedlmair},
    year          = {2020},
    month         = {11},
    booktitle     = {IEEE Int. Symp. Mixed and Augmented Reality Adjunct},
    publisher     = {IEEE},
    pages         = {30--35},
    doi           = {https://doi.org/10.1109/ISMAR-Adjunct51615.2020.00023},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/hube2020comparing.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>