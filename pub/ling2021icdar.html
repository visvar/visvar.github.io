<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Document Domain Randomization for Deep Learning Document Layout Extraction</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Document Domain Randomization for Deep Learning Document Layout Extraction</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/ling2021icdar.png" target="_blank" title="show image full size">
                <img class="teaser" id="imageling2021icdar" src="../assets/img/teaser/ling2021icdar.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Meng Ling, Jian Chen, Torsten MÃ¶ller, Petra Isenberg, Tobias Isenberg, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>, Robert S Laramee, Han-Wei Shen, Jian Wu, C Lee Giles
                </div>
                  
                <div>
                  <b>Venue.</b> ICDAR (2021)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1007/978-3-030-86549-8_32" target="_blank" rel="noreferrer">DOI</a>
                  <a href="https://arxiv.org/abs/2105.14931" target="_blank" rel="noreferrer">link</a>
                  
                  <a href="../assets/pdf/ling2021icdar.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> We present document domain randomization (DDR), the first successful transfer of convolutional neural networks (CNNs) trained only on graphically rendered pseudo-paper pages to real-world document segmentation. DDR renders pseudo-document pages by modeling randomized textual and non-textual contents of interest, with user-defined layout and font styles to support joint learning of fine-grained classes. We demonstrate competitive results using our DDR approach to extract nine document classes from the benchmark CS-150 and papers published in two domains, namely annual meetings of Association for Computational Linguistics (ACL) and IEEE Visualization (VIS). We compare DDR to conditions of style mismatch, fewer or more noisy samples that are more easily obtained in the real world. We show that high-fidelity semantic information is not necessary to label semantic classes but style mismatch between train and test can lower model accuracy. Using smaller training samples had a slightly detrimental effect. Finally, network models still achieved high test accuracy when correct labels are diluted towards confusing labels; this behavior hold across several classes.</div>
                <div class="bibtex"><textarea>@inproceedings{ling2021icdar,
    title         = {Document Domain Randomization for Deep Learning Document Layout Extraction},
    author        = {Meng Ling, Jian Chen, Torsten M\"{o}ller, Petra Isenberg, Tobias Isenberg, Michael Sedlmair, Robert S Laramee, Han-Wei Shen, Jian Wu, C Lee Giles},
    year          = {2021},
    month         = {5},
    booktitle     = {Document Analysis and Recognition},
    publisher     = {Springer},
    pages         = {497--513},
    doi           = {https://doi.org/10.1007/978-3-030-86549-8_32},
    isbn          = {978-3-030-86549-8},
    url           = {https://arxiv.org/abs/2105.14931},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/ling2021icdar.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>