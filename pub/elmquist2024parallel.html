<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Parallel Chords: an audio-visual analytics design for parallel coordinates</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <main>
        
  <div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
        <ul>
          <li><a href="../index.html">home</a></li>
        </ul>
      </nav>
    </div>
  </header>
</div>
        <div>
          <article>
            <h1>Parallel Chords: an audio-visual analytics design for parallel coordinates</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/elmquist2024parallel.png" target="_blank" title="show image full size">
                <img class="teaser" id="imageelmquist2024parallel" src="../assets/img/teaser/elmquist2024parallel.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> <a href="../members/elias_elmquist.html" target="_blank">Elias Elmquist*</a>, Kajetan Enge*, Alexander Rind, Carlo Navarra, Robert Höldrich, Michael Iber, Alexamder Bock, Anders Ynnerman, Wolfgang Aigner, Niklas Rönnberg
                </div>
                  <div>*contributed equally</div>
                <div>
                  <b>Venue.</b> PUC (2024)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1007/s00779-024-01795-8" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="https://link.springer.com/content/pdf/10.1007/s00779-024-01795-8.pdf" target="_blank" rel="noreferrer">PDF [link]</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> One of the commonly used visualization techniques for multivariate data is the parallel coordinates plot. It provides users with a visual overview of multivariate data and the possibility to interactively explore it. While pattern recognition is a strength of the human visual system, it is also a strength of the auditory system. Inspired by the integration of the visual and auditory perception in everyday life, we introduce an audio-visual analytics design named Parallel Chords combining both visual and auditory displays. Parallel Chords lets users explore multivariate data using both visualization and sonification through the interaction with the axes of a parallel coordinates plot. To illustrate the potential of the design, we present (1) prototypical data patterns where the sonification helps with the identification of correlations, clusters, and outliers, (2) a usage scenario showing the sonification of data from non-adjacent axes, and (3) a controlled experiment on the sensitivity thresholds of participants when distinguishing the strength of correlations. During this controlled experiment, 35 participants used three different display types, the visualization, the sonification, and the combination of these, to identify the strongest out of three correlations. The results show that all three display types enabled the participants to identify the strongest correlation — with visualization resulting in the best sensitivity. The sonification resulted in sensitivities that were independent from the type of displayed correlation, and the combination resulted in increased enjoyability during usage.</div>
                <div class="bibtex"><textarea>@article{elmquist2024parallel,
    title         = {Parallel Chords: an audio-visual analytics design for parallel coordinates},
    author        = {Elias Elmquist, Kajetan Enge, Alexander Rind, Carlo Navarra, Robert H\"{o}ldrich, Michael Iber, Alexamder Bock, Anders Ynnerman, Wolfgang Aigner, Niklas R\"{o}nnberg},
    year          = {2024},
    month         = {5},
    journal       = {Springer Personal and Ubiquitous Computing},
    volume        = {28},
    number        = {1},
    pages         = {657--676},
    doi           = {https://doi.org/10.1007/s00779-024-01795-8},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/elmquist2024parallel.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>