<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    
    <title>Evaluating Visual Data Analysis Systems: A Discussion Report</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">

    <!-- OG Metadata -->
    <meta property="og:site_name" content="HCI VISUS" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The HCI Research Group in Stuttgart" />
    <meta property="og:url" content="https://visvar.github.io/" />
    <meta property="og:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta property="og:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
    <meta property="og:locale" content="EN" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title"  content="The HCI Research Group in Stuttgart" />
    <meta name="twitter:description" content="All about the people and their research at the HCI group at VISUS, University of Stuttgart." />
    <meta name="twitter:image" content="https://visvar.github.io/assets/img/misc/hcivisus.png" />
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Evaluating Visual Data Analysis Systems: A Discussion Report</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/ballte2018hilda.png" target="_blank" title="show image full size">
                <img class="teaser" id="imageballte2018hilda" src="../assets/img/teaser/ballte2018hilda.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Leilani Battle, Marco Angelini, Carsten Binnig, Tiziana Catarci, Philipp Eichmann, Jean-Daniel Fekete, Giuseppe Santucci, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>, Wesley Willett
                </div>
                  
                <div>
                  <b>Venue.</b> HILDA (2018)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1145/3209900.3209901" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/ballte2018hilda.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> Visual data analysis is a key tool for helping people to make sense of and interact with massive data sets. However, existing evaluation methods (e.g., database benchmarks, individual user studies) fail to capture the key points that make systems for visual data analysis (or visual data systems) challenging to design. In November 2017, members of both the Database and Visualization communities came together in a Dagstuhl seminar to discuss the grand challenges in the intersection of data analysis and interactive visualization. In this paper, we report on the discussions of the working group on the evaluation of visual data systems, which addressed questions centered around developing better evaluation methods, such as 'How do the different communities evaluate visual data systems?' and 'What we could learn from each other to develop evaluation techniques that cut across areas?'. In their discussions, the group brainstormed initial steps towards new joint evaluation methods and developed a first concrete initiative - a trace repository of various real-world workloads and visual data systems - that enables researchers to derive evaluation setups (e.g., performance benchmarks, user studies) under more realistic assumptions, and enables new evaluation perspectives (e.g., broader meta analysis across analysis contexts, reproducibility and comparability across systems).</div>
                <div class="bibtex"><textarea>@inproceedings{ballte2018hilda,
    title         = {Evaluating Visual Data Analysis Systems: A Discussion Report},
    author        = {Leilani Battle, Marco Angelini, Carsten Binnig, Tiziana Catarci, Philipp Eichmann, Jean-Daniel Fekete, Giuseppe Santucci, Michael Sedlmair, Wesley Willett},
    year          = {2018},
    month         = {6},
    booktitle     = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
    location      = {Houston, TX, USA},
    publisher     = {Association for Computing Machinery},
    series        = {HILDA'18},
    doi           = {https://doi.org/10.1145/3209900.3209901},
    isbn          = {9781450358279},
    articleno     = {4},
    numpages      = {6},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/ballte2018hilda.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>