<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    <title>Eyes on the Task: Gaze Analysis of Situated Visualization for Collaborative Tasks</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Eyes on the Task: Gaze Analysis of Situated Visualization for Collaborative Tasks</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/pathmanathan2024eyes.png" target="_blank" title="show image full size">
                <img class="teaser" id="imagepathmanathan2024eyes" src="../assets/img/teaser/pathmanathan2024eyes.png"/>
              </a>
              <div>
                <div class="authors">
                  <b>Authors.</b> Nelusa Pathmanathan, <a href="../members/tobias_rau.html" target="_blank">Tobias Rau</a>, Xiliu Yang, <a href="../members/aimee_sousa_calepso.html" target="_blank">Aimée Sousa Calepso</a>, Felix Amtsberg, Achim Menges, <a href="../members/michael_sedlmair.html" target="_blank">Michael Sedlmair</a>, Kuno Kurzhals
                </div>
                  
                <div>
                  <b>Venue.</b> VR (2024)
                </div>
                <div class="materials">
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1109/VR58804.2024.00098" target="_blank" rel="noreferrer">DOI</a>
                  
                  
                  <a href="../assets/pdf/pathmanathan2024eyes.pdf" target="_blank" rel="noreferrer">PDF</a>
                  
                  
                  
                </div>
                <div class="abstract"><b>Abstract.</b> The use of augmented reality technology to support humans with situated visualization in complex tasks such as navigation or assembly has gained increasing importance in research and industrial applications. One important line of research regards supporting and understanding collaborative tasks. Analyzing collaboration patterns is usually done by conducting observations and interviews. To expand these methods, we argue that eye tracking can be used to extract further insights and quantify behavior. To this end, we contribute a study that uses eye tracking to investigate participant strategies for solving collaborative sorting and assembly tasks. We compare participants’ visual attention during situated instructions in AR and traditional paper-based instructions as a baseline. By investigating the performance and gaze behavior of the participants, different strategies for solving the provided tasks are revealed. Our results show that with situated visualization, participants focus more on task-relevant areas and require less discussion between collaboration partners to solve the task at hand.</div>
                <div class="bibtex"><textarea>@inproceedings{pathmanathan2024eyes,
    title         = {Eyes on the Task: Gaze Analysis of Situated Visualization for Collaborative Tasks},
    author        = {Nelusa Pathmanathan, Tobias Rau, Xiliu Yang, Aim\'{e}e Sousa Calepso, Felix Amtsberg, Achim Menges, Michael Sedlmair, Kuno Kurzhals},
    year          = {2024},
    month         = {4},
    booktitle     = {2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)},
    publisher     = {IEEE Computer Society},
    pages         = {785--795},
    doi           = {https://doi.org/10.1109/VR58804.2024.00098},
    keywords      = {visualization;three-dimensional displays;collaboration;gaze tracking;user interfaces;user experience;task analysis},
}
</textarea></div>
                
                
                <div class="qrcontainer">
                  <div class="qrtitle">Link to this page:</div>
                  <img class="qrimage" src="../assets/img/qr/pathmanathan2024eyes.png"/>
                </div>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>